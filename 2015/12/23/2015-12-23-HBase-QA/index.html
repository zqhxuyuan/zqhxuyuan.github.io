<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>HBase QA | zqhxuyuan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="HBase Q &amp;amp; A">
<meta name="keywords" content="hbase">
<meta property="og:type" content="article">
<meta property="og:title" content="HBase QA">
<meta property="og:url" content="http://github.com/zqhxuyuan/2015/12/23/2015-12-23-HBase-QA/index.html">
<meta property="og:site_name" content="zqhxuyuan">
<meta property="og:description" content="HBase Q &amp;amp; A">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20151216203616868">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20151217204121235">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20151223170933581">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20151223092901973">
<meta property="og:updated_time" content="2019-02-14T13:42:29.217Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HBase QA">
<meta name="twitter:description" content="HBase Q &amp;amp; A">
<meta name="twitter:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20151216203616868">
  
    <link rel="alternative" href="/atom.xml" title="zqhxuyuan" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">任何忧伤,都抵不过世界的美丽</a></h1>
		</hgroup>

		
				


		
			<div id="switch-btn" class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div id="switch-area" class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives/">归档</a></li>
				        
							<li><a href="/tags/">标签</a></li>
				        
							<li><a href="/about/">关于</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
								<li id="RSS"><a class="RSS" target="_blank" href="/atom.xml" title="RSS"></a></li>
					        
						</ul>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/apex/" style="font-size: 10px;">apex</a> <a href="/tags/bigdata/" style="font-size: 10px;">bigdata</a> <a href="/tags/book/" style="font-size: 10px;">book</a> <a href="/tags/cassandra/" style="font-size: 18.89px;">cassandra</a> <a href="/tags/clojure/" style="font-size: 10px;">clojure</a> <a href="/tags/drill/" style="font-size: 16.67px;">drill</a> <a href="/tags/druid/" style="font-size: 13.33px;">druid</a> <a href="/tags/dubbo/" style="font-size: 10px;">dubbo</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/etl/" style="font-size: 10px;">etl</a> <a href="/tags/geode/" style="font-size: 10px;">geode</a> <a href="/tags/graph/" style="font-size: 12.22px;">graph</a> <a href="/tags/hadoop/" style="font-size: 11.11px;">hadoop</a> <a href="/tags/hbase/" style="font-size: 15.56px;">hbase</a> <a href="/tags/ignite/" style="font-size: 10px;">ignite</a> <a href="/tags/java/" style="font-size: 10px;">java</a> <a href="/tags/jvm/" style="font-size: 10px;">jvm</a> <a href="/tags/kafka/" style="font-size: 20px;">kafka</a> <a href="/tags/midd/" style="font-size: 10px;">midd</a> <a href="/tags/ops/" style="font-size: 12.22px;">ops</a> <a href="/tags/redis/" style="font-size: 11.11px;">redis</a> <a href="/tags/rocketmq/" style="font-size: 10px;">rocketmq</a> <a href="/tags/scala/" style="font-size: 13.33px;">scala</a> <a href="/tags/spark/" style="font-size: 17.78px;">spark</a> <a href="/tags/storm/" style="font-size: 17.78px;">storm</a> <a href="/tags/tcc/" style="font-size: 10px;">tcc</a> <a href="/tags/timeseries/" style="font-size: 12.22px;">timeseries</a> <a href="/tags/work/" style="font-size: 14.44px;">work</a> <a href="/tags/流处理/" style="font-size: 11.11px;">流处理</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">BIG(DATA)</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<a href="/" class="profilepic">
				<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			</a>
			<hgroup>
			  <h1 class="header-author"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives/">归档</a></li>
		        
					<li><a href="/tags/">标签</a></li>
		        
					<li><a href="/about/">关于</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
								<li id="RSS"><a class="RSS" target="_blank" href="/atom.xml" title="RSS"></a></li>
					        
						</ul>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-2015-12-23-HBase-QA" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/12/23/2015-12-23-HBase-QA/" class="article-date">
  	<time datetime="2015-12-22T16:00:00.000Z" itemprop="datePublished">2015-12-23</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      HBase QA
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/bigdata/">bigdata</a>
	</div>


        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hbase/">hbase</a></li></ul>
	</div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <p>HBase Q &amp; A<br><a id="more"></a></p>
<h2 id="INCONSISTENT_status">INCONSISTENT status</h2><h3 id="SYSTEM-FUNCTION表损坏">SYSTEM.FUNCTION表损坏</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">15/12/16 19:16:14 DEBUG client.ConnectionManager$HConnectionImplementation: </span><br><span class="line">locateRegionInMeta parentTable=hbase:meta, metaLocation=, attempt=6 of 35 failed; retrying after sleep of 4039 because: </span><br><span class="line">No server address listed in hbase:meta for region SYSTEM.FUNCTION,,1450264148924.1125a5495cbbf583864609c67a2b804b. containing row</span><br></pre></td></tr></table></figure>
<p>修复元数据,SYSTEM.FUNCTION表在HBase中不一致性</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@spark047213 bin]$ hbase hbck -fixMeta -fixAssignments</span><br><span class="line">Number of empty REGIONINFO_QUALIFIER rows in hbase:meta: 0</span><br><span class="line">Number of Tables: 6</span><br><span class="line">ERROR: There is a hole in the region chain between  and .  You need to create a new .regioninfo and region dir in hdfs to plug the hole.</span><br><span class="line">ERROR: Found inconsistency in table SYSTEM.FUNCTION</span><br><span class="line">Summary:</span><br><span class="line">  hbase:meta is okay.</span><br><span class="line">    Number of regions: 1</span><br><span class="line">    Deployed on:  spark047245,16020,1450263724611</span><br><span class="line">  SYSTEM.CATALOG is okay.</span><br><span class="line">    Number of regions: 1</span><br><span class="line">    Deployed on:  spark047243,16020,1450263724657</span><br><span class="line">  table is okay.</span><br><span class="line">    Number of regions: 1</span><br><span class="line">    Deployed on:  spark047244,16020,1450263724611</span><br><span class="line">  hbase:namespace is okay.</span><br><span class="line">    Number of regions: 1</span><br><span class="line">    Deployed on:  spark047244,16020,1450263724611</span><br><span class="line">  SYSTEM.SEQUENCE is okay.</span><br><span class="line">    Number of regions: 256</span><br><span class="line">    Deployed on:  spark047241,16020,1450263725671 spark047242,16020,1450263724591 spark047243,16020,1450263724657 spark047244,16020,1450263724611 spark047245,16020,1450263724611</span><br><span class="line">  SYSTEM.FUNCTION is okay.</span><br><span class="line">    Number of regions: 0</span><br><span class="line">    Deployed on:</span><br><span class="line">  SYSTEM.STATS is okay.</span><br><span class="line">    Number of regions: 1</span><br><span class="line">    Deployed on:  spark047242,16020,1450263724591</span><br><span class="line">1 inconsistencies detected.</span><br><span class="line">Status: INCONSISTENT</span><br></pre></td></tr></table></figure>
<blockquote>
<p>HBase启动的时候, 用hbase shell的list是看不到任何table的. 启动sqlline后, phoenix会创建上面的四张系统表.<br>下面的第一行SYSTEM.FUNCTION标记为红色的. 正常的话如果表没有损坏,是不会出现Regions in Transition</p>
</blockquote>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20151216203616868" alt="hbase_function"></p>
<p>解决方式: 删除ZooKeeper中的/hbase文件夹, 并重启HBase集群.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@spark047213 ~]$ hbase zkcli</span><br><span class="line">[zk: 192.168.47.84:2181,192.168.47.83:2181,192.168.47.86:2181(CONNECTED) 10] rmr /hbase</span><br></pre></td></tr></table></figure>
<p>注意只是删除FUNCTION表貌似不起作用. <code>delete /hbase/table/SYSTEM.FUNCTION</code>, 要删除整个目录.  </p>
<h3 id="节点假死">节点假死</h3><p>检测到一个节点当掉了,但是在master页面看这个RS是没有问题的.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):003:0&gt; scan &apos;hbase:meta&apos;</span><br><span class="line">ROW                                                COLUMN+CELL</span><br><span class="line"></span><br><span class="line">ERROR: org.apache.hadoop.hbase.regionserver.RegionServerStoppedException: Server spark047217,16020,1450843709048 not running, aborting</span><br><span class="line">  at org.apache.hadoop.hbase.regionserver.RSRpcServices.checkOpen(RSRpcServices.java:903)</span><br><span class="line">  at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:2003)</span><br><span class="line">  at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:31443)</span><br><span class="line">  at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2033)</span><br><span class="line">  at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:107)</span><br><span class="line">  at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)</span><br><span class="line">  at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)</span><br></pre></td></tr></table></figure>
<p><code>hbase hbck</code>检查:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ERROR: RegionServer: spark047209,16020,1450843709733 Unable to fetch region information. org.apache.hadoop.hbase.regionserver.RegionServerStoppedException: org.apache.hadoop.hbase.regionserver.RegionServerStoppedException: Server spark047209,16020,1450843709733 not running, aborting</span><br><span class="line">  at org.apache.hadoop.hbase.regionserver.RSRpcServices.checkOpen(RSRpcServices.java:903)</span><br><span class="line">  at org.apache.hadoop.hbase.regionserver.RSRpcServices.getOnlineRegion(RSRpcServices.java:1132)</span><br><span class="line">  at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:21110)</span><br><span class="line">  at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2033)</span><br><span class="line">  at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:107)</span><br><span class="line">  at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:130)</span><br><span class="line">  at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:107)</span><br><span class="line">  at java.lang.Thread.run(Thread.java:744)</span><br><span class="line"></span><br><span class="line">ERROR: hbase:meta is not found on any region.</span><br><span class="line">ERROR: hbase:meta table is not consistent. Run HBCK with proper fix options to fix hbase:meta inconsistency. Exiting...</span><br></pre></td></tr></table></figure>
<p>修复<code>hbase hbck -fix</code>失败:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ERROR: Region &#123; meta =&gt; data.md5_id2,e4f02e929cd2c7bf53d63e6645904dcf,1450579287871.01431d11f5dfb2c318209ac2bb397340., hdfs =&gt; hdfs://tdhdfs/hbase/data/default/data.md5_id2/01431d11f5dfb2c318209ac2bb397340, deployed =&gt;  &#125; not deployed on any region server.</span><br><span class="line">Trying to fix unassigned region...</span><br><span class="line">Exception in thread &quot;main&quot; java.io.IOException: Region &#123;ENCODED =&gt; 01431d11f5dfb2c318209ac2bb397340, NAME =&gt; &apos;data.md5_id2,e4f02e929cd2c7bf53d63e6645904dcf,1450579287871.01431d11f5dfb2c318209ac2bb397340.&apos;, STARTKEY =&gt; &apos;e4f02e929cd2c7bf53d63e6645904dcf&apos;, ENDKEY =&gt; &apos;e559899b9&apos;&#125; failed to move out of transition within timeout 120000ms</span><br></pre></td></tr></table></figure>
<p>解决方式: 还是rm /hbase并重启集群.   </p>
<h3 id="建表失败">建表失败</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):001:0&gt; create &apos;data.md5_id2&apos;, &apos;id&apos;, &#123;NUMREGIONS =&gt; 16, SPLITALGO =&gt; &apos;HexStringSplit&apos;&#125;</span><br><span class="line">ERROR: Only 2 of 16 regions are online; retries exhausted.</span><br><span class="line"></span><br><span class="line">hbase(main):005:0&gt; scan &quot;data.md5_id2&quot;</span><br><span class="line">ROW                                                COLUMN+CELL</span><br><span class="line">ERROR: No server address listed in hbase:meta for region data.md5_id2,,1450350723788.d22366cc7199a7a524c910f35e5fe06b. containing row</span><br></pre></td></tr></table></figure>
<p>后台RegionServer报错(跟这么应该没关系,因为所有RegionServer节点都报这个错误):  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">0    [ReplicationExecutor-0] ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper  - ZooKeeper multi failed after 4 attempts</span><br><span class="line">99   [PriorityRpcServer.handler=9,queue=1,port=16020] ERROR org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper  - ZooKeeper getData failed after 4 attempts</span><br><span class="line">101  [PriorityRpcServer.handler=9,queue=1,port=16020] ERROR org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher  - </span><br><span class="line">  regionserver:16020-0x1515d5299ea3b15, quorum=192.168.47.84:2181,192.168.47.83:2181,192.168.47.86:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception</span><br><span class="line">org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/recovering-regions/aab33827b7f8a9a006fd49059728d900</span><br><span class="line">        at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)</span><br><span class="line">        at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.getData(RecoverableZooKeeper.java:359)</span><br><span class="line">        at org.apache.hadoop.hbase.zookeeper.ZKSplitLog.isRegionMarkedRecoveringInZK(ZKSplitLog.java:159)</span><br><span class="line">        at org.apache.hadoop.hbase.regionserver.RSRpcServices.openRegion(RSRpcServices.java:1411)</span><br><span class="line">102  [PriorityRpcServer.handler=9,queue=1,port=16020] ERROR org.apache.hadoop.hbase.regionserver.RSRpcServices  - Can&apos;t retrieve recovering state from zookeeper</span><br><span class="line">org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/recovering-regions/aab33827b7f8a9a006fd49059728d900</span><br></pre></td></tr></table></figure>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20151217204121235" alt="hbase-create-err"></p>
<blockquote>
<p>解决方式: 还是rm /hbase并重启集群. 最后每个节点都会deployed.<br>因为集群只有14个RegionServer,而Region数量是16个,所以会有两个节点的Region数为2.  </p>
</blockquote>
<h3 id="hdfs_fsck_/hbase">hdfs fsck /hbase</h3><p>由于hdfs的块损坏,在启动hbase的时候, 会出现<code>Region in transition...failed open</code>.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@spark047213 ~]$ hbase hbck -fixMeta -fixAssignments</span><br><span class="line">Number of live region servers: 14</span><br><span class="line">Number of dead region servers: 0</span><br><span class="line">Master: spark047213,16020,1454292347429</span><br><span class="line">Number of backup masters: 0</span><br><span class="line">Average load: 151.14285714285714</span><br><span class="line">Number of requests: 0</span><br><span class="line">Number of regions: 2116</span><br><span class="line">Number of regions in transition: 6</span><br><span class="line">...</span><br><span class="line">Number of empty REGIONINFO_QUALIFIER rows in hbase:meta: 0</span><br><span class="line">Number of Tables: 4</span><br><span class="line">ERROR: Region &#123; meta =&gt; data.md5_mob2,1c00182ae,1450693138672.30d0ca1e3c34e95d029e8a9abf877c85., hdfs =&gt; hdfs://tdhdfs/hbase/data/default/data.md5_mob2/30d0ca1e3c34e95d029e8a9abf877c85, deployed =&gt;  &#125; not deployed on any region server.</span><br><span class="line">Trying to fix unassigned region...</span><br><span class="line">ERROR: Region &#123; meta =&gt; data.md5_mob2,f40010ac,1450686032580.61d1c4a83ebc953d35fc819c698a8b0f., hdfs =&gt; hdfs://tdhdfs/hbase/data/default/data.md5_mob2/61d1c4a83ebc953d35fc819c698a8b0f, deployed =&gt;  &#125; not deployed on any region server.</span><br><span class="line">Trying to fix unassigned region...</span><br><span class="line">ERROR: Region &#123; meta =&gt; data.md5_mob2,1800067f2,1450693138672.680e340c757929c0d5befb690106d562., hdfs =&gt; hdfs://tdhdfs/hbase/data/default/data.md5_mob2/680e340c757929c0d5befb690106d562, deployed =&gt;  &#125; not deployed on any region server.</span><br><span class="line">Trying to fix unassigned region...</span><br><span class="line">ERROR: Region &#123; meta =&gt; data.md5_mob2,55ffe6f3b,1450697992540.8b00ce8e47d8cce2fced405665cada13., hdfs =&gt; hdfs://tdhdfs/hbase/data/default/data.md5_mob2/8b00ce8e47d8cce2fced405665cada13, deployed =&gt;  &#125; not deployed on any region server.</span><br><span class="line">Trying to fix unassigned region...</span><br><span class="line">ERROR: Region &#123; meta =&gt; data.md5_mob2,fbffd2a37,1450688301202.b6732381185758ec64af441618cf120c., hdfs =&gt; hdfs://tdhdfs/hbase/data/default/data.md5_mob2/b6732381185758ec64af441618cf120c, deployed =&gt;  &#125; not deployed on any region server.</span><br><span class="line">Trying to fix unassigned region...</span><br><span class="line">ERROR: Region &#123; meta =&gt; data.md5_mob2,23fff727,1450695213674.e2e9b928571072f2d71d12fdc32ed0b3., hdfs =&gt; hdfs://tdhdfs/hbase/data/default/data.md5_mob2/e2e9b928571072f2d71d12fdc32ed0b3, deployed =&gt;  &#125; not deployed on any region server.</span><br><span class="line">Trying to fix unassigned region...</span><br><span class="line">ERROR: There is a hole in the region chain between 1800067f2 and 20000000.  You need to create a new .regioninfo and region dir in hdfs to plug the hole.</span><br><span class="line">ERROR: There is a hole in the region chain between 23fff727 and 280000:.  You need to create a new .regioninfo and region dir in hdfs to plug the hole.</span><br><span class="line">ERROR: There is a hole in the region chain between 55ffe6f3b and 57ffdc07.  You need to create a new .regioninfo and region dir in hdfs to plug the hole.</span><br><span class="line">ERROR: There is a hole in the region chain between f40010ac and f7ffeaab.  You need to create a new .regioninfo and region dir in hdfs to plug the hole.</span><br><span class="line">ERROR: Last region should end with an empty key. You need to create a new region and regioninfo in HDFS to plug the hole.</span><br><span class="line">ERROR: Found inconsistency in table data.md5_mob2</span><br><span class="line">Summary:</span><br><span class="line">  hbase:meta is okay.</span><br><span class="line">    Number of regions: 1</span><br><span class="line">    Deployed on:  spark047244,16020,1454292349019</span><br><span class="line">Table data.md5_mob2 is inconsistent.</span><br><span class="line">    Number of regions: 64</span><br><span class="line">    Deployed on:  spark047207,16020,1454292350149 spark047209,16020,1454292350575 spark047212,16020,1454292350624 spark047215,16020,1454292349389 spark047216,16020,1454292349182 spark047217,16020,1454292348998 spark047218,16020,1454292348642 spark047219,16020,1454292349586 spark047223,16020,1454292348854 spark047241,16020,1454292349570 spark047242,16020,1454292349743 spark047243,16020,1454292349509 spark047244,16020,1454292349019 spark047245,16020,1454292350582</span><br><span class="line">  data.md5_id2 is okay.</span><br><span class="line">    Number of regions: 2049</span><br><span class="line">    Deployed on:  spark047207,16020,1454292350149 spark047209,16020,1454292350575 spark047212,16020,1454292350624 spark047215,16020,1454292349389 spark047216,16020,1454292349182 spark047217,16020,1454292348998 spark047218,16020,1454292348642 spark047219,16020,1454292349586 spark047223,16020,1454292348854 spark047241,16020,1454292349570 spark047242,16020,1454292349743 spark047243,16020,1454292349509 spark047244,16020,1454292349019 spark047245,16020,1454292350582</span><br><span class="line">  data.md5_mob is okay.</span><br><span class="line">    Number of regions: 1</span><br><span class="line">    Deployed on:  spark047245,16020,1454292350582</span><br><span class="line">  hbase:namespace is okay.</span><br><span class="line">    Number of regions: 1</span><br><span class="line">    Deployed on:  spark047241,16020,1454292349570</span><br><span class="line">11 inconsistencies detected.</span><br><span class="line">Status: INCONSISTENT</span><br><span class="line">Version: 1.0.2</span><br><span class="line">Number of live region servers: 14</span><br><span class="line">Number of dead region servers: 0</span><br><span class="line">Master: spark047213,16020,1454292347429</span><br><span class="line">Number of backup masters: 0</span><br><span class="line">Average load: 151.14285714285714</span><br><span class="line">Number of requests: 0</span><br><span class="line">Number of regions: 2116</span><br><span class="line">Number of regions in transition: 6</span><br><span class="line">...</span><br><span class="line">Number of empty REGIONINFO_QUALIFIER rows in hbase:meta: 0</span><br><span class="line">Number of Tables: 4</span><br><span class="line">Summary:</span><br><span class="line">  hbase:meta is okay.</span><br><span class="line">    Number of regions: 1</span><br><span class="line">    Deployed on:  spark047244,16020,1454292349019</span><br><span class="line">  data.md5_mob2 is okay.</span><br><span class="line">    Number of regions: 70</span><br><span class="line">    Deployed on:  spark047207,16020,1454292350149 spark047209,16020,1454292350575 spark047212,16020,1454292350624 spark047215,16020,1454292349389 spark047216,16020,1454292349182 spark047217,16020,1454292348998 spark047218,16020,1454292348642 spark047219,16020,1454292349586 spark047223,16020,1454292348854 spark047241,16020,1454292349570 spark047242,16020,1454292349743 spark047243,16020,1454292349509 spark047244,16020,1454292349019 spark047245,16020,1454292350582</span><br><span class="line">  data.md5_id2 is okay.</span><br><span class="line">    Number of regions: 2049</span><br><span class="line">    Deployed on:  spark047207,16020,1454292350149 spark047209,16020,1454292350575 spark047212,16020,1454292350624 spark047215,16020,1454292349389 spark047216,16020,1454292349182 spark047217,16020,1454292348998 spark047218,16020,1454292348642 spark047219,16020,1454292349586 spark047223,16020,1454292348854 spark047241,16020,1454292349570 spark047242,16020,1454292349743 spark047243,16020,1454292349509 spark047244,16020,1454292349019 spark047245,16020,1454292350582</span><br><span class="line">  data.md5_mob is okay.</span><br><span class="line">    Number of regions: 1</span><br><span class="line">    Deployed on:  spark047245,16020,1454292350582</span><br><span class="line">  hbase:namespace is okay.</span><br><span class="line">    Number of regions: 1</span><br><span class="line">    Deployed on:  spark047241,16020,1454292349570</span><br><span class="line">0 inconsistencies detected.</span><br><span class="line">Status: OK</span><br></pre></td></tr></table></figure>
<h2 id="RegionSplit">RegionSplit</h2><p>第一次导入了一部分数据, 虽然建表时指定了16个Region, 在导入HTable后, Region数量增加了.  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20151223170933581" alt="region_incr"></p>
<h3 id="BulkLoad没有移动而是复制和Split文件">BulkLoad没有移动而是复制和Split文件</h3><p><a href="http://chxt6896.github.io/hbase/2013/06/06/hbase-bulkload.html" target="_blank" rel="noopener">http://chxt6896.github.io/hbase/2013/06/06/hbase-bulkload.html</a><br>BulkLoad只是移动文件, 会很快. 但是实际中在第一次导入一个文件夹很快, 导入第二个文件夹时,就出问题了:  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20151223092901973" alt="hbase_copy"></p>
<h4 id="不同集群会复制">不同集群会复制</h4><p><a href="http://blackwing.iteye.com/blog/1991901" target="_blank" rel="noopener">http://blackwing.iteye.com/blog/1991901</a>这里说到没有使用同一个集群,会被认为不同的文件系统,就会拷贝,而不是移动.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_CLASSPATH=`hbase-1.0.2/bin/hbase classpath` /usr/install/hadoop/bin/hadoop jar hbase-1.0.2/lib/hbase-server-1.0.2.jar completebulkload hdfs://tdhdfs/user/tongdun/id_hbase/id_hbase2_7 data.md5_id2</span><br><span class="line">hbase org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles hdfs://tdhdfs/user/tongdun/id_hbase/id_hbase2_7 data.md5_id2 </span><br><span class="line"></span><br><span class="line">hbase org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles /user/tongdun/id_hbase/id_hbase3_11 data.md5_id2 </span><br><span class="line">HADOOP_CLASSPATH=`hbase classpath` hadoop jar hbase-1.0.2/lib/hbase-server-1.0.2.jar completebulkload /user/tongdun/id_hbase/1 data.md5_id2</span><br></pre></td></tr></table></figure>
<p>虽然添加了完整的前缀,但是还是会在_tmp下出现文件,说明还是在拷贝.但是这个时候是属于同一个HDFS集群的.    </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testSameHDFS</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">    Configuration hdfsConfig = <span class="keyword">new</span> Configuration();</span><br><span class="line">    hdfsConfig.addResource(<span class="string">"core-site.xml"</span>);</span><br><span class="line">    hdfsConfig.addResource(<span class="string">"hdfs-site.xml"</span>);</span><br><span class="line">    FileSystem hdfsFS = FileSystem.get(hdfsConfig);</span><br><span class="line">    System.out.println(hdfsFS.getCanonicalServiceName());</span><br><span class="line"></span><br><span class="line">    Configuration config = <span class="keyword">new</span> Configuration();</span><br><span class="line">    config.set(<span class="string">"hbase.zookeeper.quorum"</span>,<span class="string">"192.168.6.55,192.168.6.56,192.168.6.57"</span>);</span><br><span class="line">    config.set(<span class="string">"hbase.zookeeper.property.clientPort"</span>, <span class="string">"2181"</span>);</span><br><span class="line">    HTable table = <span class="keyword">new</span> HTable(config, <span class="string">"data.md5_id"</span>);</span><br><span class="line"></span><br><span class="line">    FileSystem fs = FileSystem.get(config);</span><br><span class="line">    FileSystem desFs = fs <span class="keyword">instanceof</span> HFileSystem ? ((HFileSystem)fs).getBackingFs() : fs;</span><br><span class="line">    String destName = desFs.getCanonicalServiceName();</span><br><span class="line">    System.out.println(destName); <span class="comment">//ha-hdfs:tdhdfs</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">boolean</span> sameHDFS = FSHDFSUtils.isSameHdfs(config, hdfsFS, desFs);</span><br><span class="line">    System.out.println(sameHDFS); <span class="comment">//true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在运行上面命令的时候并没有打印日志信息,因为slf4j冲突.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:/usr/install/hadoop-2.4.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/home/qihuang.zheng/hbase-1.0.2/lib/phoenix-4.6.0-HBase-1.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/home/qihuang.zheng/hbase-1.0.2/lib/slf4j-log4j12-1.7.7.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/home/qihuang.zheng/hbase-1.0.2/lib/phoenix-server-4.6.0-HBase-1.0-runnable.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span><br><span class="line">SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]</span><br></pre></td></tr></table></figure>
<p>把hbase的slf4j和phoenix暂时移出去. 日志就出来了. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">15/12/23 11:00:58 WARN mapreduce.LoadIncrementalHFiles: Skipping non-directory hdfs://tdhdfs/user/tongdun/id_hbase/id_hbase2_7/_SUCCESS</span><br><span class="line">15/12/23 11:00:58 WARN mapreduce.LoadIncrementalHFiles: Trying to bulk load hfile hdfs://tdhdfs/user/tongdun/id_hbase/id_hbase2_7/id/131aa70ab69548dfab88666fb165cc61 with size: 10992654874 bytes can be problematic as it may lead to oversplitting.</span><br><span class="line"></span><br><span class="line">15/12/23 11:01:01 INFO mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/id_hbase2_7/id/131aa70ab69548dfab88666fb165cc61 first=b000000144f06b8bd0249cf57659354e last=b85372dde886be24a5745dd5cbcd7cd6</span><br><span class="line">15/12/23 11:01:01 INFO mapreduce.LoadIncrementalHFiles: HFile at hdfs://tdhdfs/user/tongdun/id_hbase/id_hbase2_7/id/131aa70ab69548dfab88666fb165cc61 no longer fits inside a single region. Splitting...</span><br></pre></td></tr></table></figure>
<p>这就导致了上面我看到的_tmp下的文件是以128M递增, 因为有些文件很大,不能放入一个Region中,所以就要进行split.<br>hbase.hregion.max.filesize默认的大小是10G(107374182400),而我们的HFile有些超过10G,为了不Split,可以设置为50G=53687091200.  </p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.hregion.max.filesize<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>53687091200<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="Split_Retry_Many_Times">Split Retry Many Times</h4><p>But Still Not Work!!!  Ask for help…</p>
<p>I Have a HFile generate by importtsv, the file is really large, from 100mb to 10G.<br>I have changed hbase.hregion.max.filesize to 50GB(53687091200). also specify src CanonicalServiceName same with hbase.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles hdfs://tdhdfs/user/tongdun/id_hbase/1 data.md5_id2 </span><br><span class="line">HADOOP_CLASSPATH=`hbase classpath` hadoop jar hbase-1.0.2/lib/hbase-server-1.0.2.jar completebulkload /user/tongdun/id_hbase/1 data.md5_id2</span><br></pre></td></tr></table></figure>
<p>But both completebulkload and LoadIncrementalHFiles did’t just mv/rename hfile expected.<br>but instead copy and split hfile happening, which take long time.   </p>
<p>the log <code>Split occured while grouping HFiles, retry attempt XXX</code> will create child _tmp dir one by one level.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">2015-12-23 15:52:04,909 INFO  [LoadIncrementalHFiles-0] hfile.CacheConfig: CacheConfig:disabled</span><br><span class="line">2015-12-23 15:52:05,006 INFO  [LoadIncrementalHFiles-0] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/01114a58782b4c369819673e4b3678ae first=f6eb30074a52ebb8c5f52ed1c85c2f0d last=f93061a29e9458fada2521ffe45ca385</span><br><span class="line">2015-12-23 15:52:05,007 INFO  [LoadIncrementalHFiles-0] mapreduce.LoadIncrementalHFiles: HFile at hdfs://tdhdfs/user/tongdun/id_hbase/1/id/01114a58782b4c369819673e4b3678ae no longer fits inside a single region. Splitting...</span><br><span class="line">2015-12-23 15:53:38,639 INFO  [LoadIncrementalHFiles-0] mapreduce.LoadIncrementalHFiles: Successfully split into new HFiles hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/9f6fe2d28ddc4f209be62757ace8611b.bottom and hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/9f6fe2d28ddc4f209be62757ace8611b.top</span><br><span class="line">2015-12-23 15:53:39,173 INFO  [main] mapreduce.LoadIncrementalHFiles: Split occured while grouping HFiles, retry attempt 1 with 2 files remaining to group or split</span><br><span class="line">2015-12-23 15:53:39,186 INFO  [LoadIncrementalHFiles-1] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/9f6fe2d28ddc4f209be62757ace8611b.bottom first=f6eb30074a52ebb8c5f52ed1c85c2f0d last=f733d2c504f22f71b191014d72e4d124</span><br><span class="line">2015-12-23 15:53:39,188 INFO  [LoadIncrementalHFiles-2] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/9f6fe2d28ddc4f209be62757ace8611b.top first=f733d2c6407f5758e860195b6d2c10c1 last=f93061a29e9458fada2521ffe45ca385</span><br><span class="line">2015-12-23 15:53:39,189 INFO  [LoadIncrementalHFiles-2] mapreduce.LoadIncrementalHFiles: HFile at hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/9f6fe2d28ddc4f209be62757ace8611b.top no longer fits inside a single region. Splitting...</span><br><span class="line">2015-12-23 15:54:27,722 INFO  [LoadIncrementalHFiles-2] mapreduce.LoadIncrementalHFiles: Successfully split into new HFiles hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/17ba0f42c4934f4c96218c784d3c3bb0.bottom and hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/17ba0f42c4934f4c96218c784d3c3bb0.top</span><br><span class="line">2015-12-23 15:54:28,557 INFO  [main] mapreduce.LoadIncrementalHFiles: Split occured while grouping HFiles, retry attempt 2 with 2 files remaining to group or split</span><br><span class="line">2015-12-23 15:54:28,568 INFO  [LoadIncrementalHFiles-4] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/17ba0f42c4934f4c96218c784d3c3bb0.bottom first=f733d2c6407f5758e860195b6d2c10c1 last=f77c7d357a76ff92bb16ec1ef79f31fb</span><br><span class="line">2015-12-23 15:54:28,568 INFO  [LoadIncrementalHFiles-5] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/17ba0f42c4934f4c96218c784d3c3bb0.top first=f77c7d3915c9a8b71c83c414aabd587d last=f93061a29e9458fada2521ffe45ca385</span><br><span class="line">2015-12-23 15:54:28,568 INFO  [LoadIncrementalHFiles-5] mapreduce.LoadIncrementalHFiles: HFile at hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/17ba0f42c4934f4c96218c784d3c3bb0.top no longer fits inside a single region. Splitting...</span><br><span class="line">2015-12-23 15:55:08,992 INFO  [LoadIncrementalHFiles-5] mapreduce.LoadIncrementalHFiles: Successfully split into new HFiles hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/f7162cec4e404eabbea479b2a5446294.bottom and hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/f7162cec4e404eabbea479b2a5446294.top</span><br><span class="line">2015-12-23 15:55:09,424 INFO  [main] mapreduce.LoadIncrementalHFiles: Split occured while grouping HFiles, retry attempt 3 with 2 files remaining to group or split</span><br><span class="line">2015-12-23 15:55:09,431 INFO  [LoadIncrementalHFiles-7] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/f7162cec4e404eabbea479b2a5446294.bottom first=f77c7d3915c9a8b71c83c414aabd587d last=f7c525a83ee19ea166414e972c5d5541</span><br><span class="line">2015-12-23 15:55:09,433 INFO  [LoadIncrementalHFiles-8] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/f7162cec4e404eabbea479b2a5446294.top first=f7c525aa2ec661c1c0707b02d1c4b4b3 last=f93061a29e9458fada2521ffe45ca385</span><br><span class="line">2015-12-23 15:55:09,433 INFO  [LoadIncrementalHFiles-8] mapreduce.LoadIncrementalHFiles: HFile at hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/f7162cec4e404eabbea479b2a5446294.top no longer fits inside a single region. Splitting...</span><br><span class="line">2015-12-23 15:55:42,165 INFO  [LoadIncrementalHFiles-8] mapreduce.LoadIncrementalHFiles: Successfully split into new HFiles hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/6610bd5d178e423fbe02db1865f834f0.bottom and hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/6610bd5d178e423fbe02db1865f834f0.top</span><br><span class="line">2015-12-23 15:55:42,490 INFO  [main] mapreduce.LoadIncrementalHFiles: Split occured while grouping HFiles, retry attempt 4 with 2 files remaining to group or split</span><br><span class="line">2015-12-23 15:55:42,498 INFO  [LoadIncrementalHFiles-10] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/6610bd5d178e423fbe02db1865f834f0.bottom first=f7c525aa2ec661c1c0707b02d1c4b4b3 last=f80dcce8a4a14be406ddd1bdebc2eda2</span><br><span class="line">2015-12-23 15:55:42,502 INFO  [LoadIncrementalHFiles-11] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/6610bd5d178e423fbe02db1865f834f0.top first=f80dccecf159d4999cb8e17446103d72 last=f93061a29e9458fada2521ffe45ca385</span><br><span class="line">2015-12-23 15:55:42,502 INFO  [LoadIncrementalHFiles-11] mapreduce.LoadIncrementalHFiles: HFile at hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/6610bd5d178e423fbe02db1865f834f0.top no longer fits inside a single region. Splitting...</span><br><span class="line">2015-12-23 15:56:09,560 INFO  [LoadIncrementalHFiles-11] mapreduce.LoadIncrementalHFiles: Successfully split into new HFiles hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/8f07441d8b7c4d3ba37b6b0917860f68.bottom and hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/8f07441d8b7c4d3ba37b6b0917860f68.top</span><br><span class="line">2015-12-23 15:56:09,933 INFO  [main] mapreduce.LoadIncrementalHFiles: Split occured while grouping HFiles, retry attempt 5 with 2 files remaining to group or split</span><br><span class="line">2015-12-23 15:56:09,942 INFO  [LoadIncrementalHFiles-13] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/8f07441d8b7c4d3ba37b6b0917860f68.bottom first=f80dccecf159d4999cb8e17446103d72 last=f85673f473ead63c89e96c83b2058ca7</span><br><span class="line">2015-12-23 15:56:09,943 INFO  [LoadIncrementalHFiles-14] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/8f07441d8b7c4d3ba37b6b0917860f68.top first=f85673fde3138dac07ce08881c9d0ccc last=f93061a29e9458fada2521ffe45ca385</span><br><span class="line">2015-12-23 15:56:09,944 INFO  [LoadIncrementalHFiles-14] mapreduce.LoadIncrementalHFiles: HFile at hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/8f07441d8b7c4d3ba37b6b0917860f68.top no longer fits inside a single region. Splitting...</span><br><span class="line">2015-12-23 15:56:30,890 INFO  [LoadIncrementalHFiles-14] mapreduce.LoadIncrementalHFiles: Successfully split into new HFiles hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/_tmp/feaa0a6428f24a5294c87dd87c6bc5a6.bottom and hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/_tmp/feaa0a6428f24a5294c87dd87c6bc5a6.top</span><br><span class="line">2015-12-23 15:56:31,145 INFO  [main] mapreduce.LoadIncrementalHFiles: Split occured while grouping HFiles, retry attempt 6 with 2 files remaining to group or split</span><br><span class="line">2015-12-23 15:56:31,151 INFO  [LoadIncrementalHFiles-16] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/_tmp/feaa0a6428f24a5294c87dd87c6bc5a6.bottom first=f85673fde3138dac07ce08881c9d0ccc last=f89f12a56b5af206188639f736877563</span><br><span class="line">2015-12-23 15:56:31,151 INFO  [LoadIncrementalHFiles-17] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/_tmp/feaa0a6428f24a5294c87dd87c6bc5a6.top first=f89f12a59e4a9c9bcbb42d0504318e25 last=f93061a29e9458fada2521ffe45ca385</span><br><span class="line">2015-12-23 15:56:31,151 INFO  [LoadIncrementalHFiles-17] mapreduce.LoadIncrementalHFiles: HFile at hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/_tmp/feaa0a6428f24a5294c87dd87c6bc5a6.top no longer fits inside a single region. Splitting...</span><br><span class="line">2015-12-23 15:56:44,959 INFO  [LoadIncrementalHFiles-17] mapreduce.LoadIncrementalHFiles: Successfully split into new HFiles hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/_tmp/_tmp/3886569dba4041deb4487f49d0417ca6.bottom and hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/_tmp/_tmp/3886569dba4041deb4487f49d0417ca6.top</span><br><span class="line">2015-12-23 15:56:46,826 INFO  [main] mapreduce.LoadIncrementalHFiles: Split occured while grouping HFiles, retry attempt 7 with 2 files remaining to group or split</span><br><span class="line">2015-12-23 15:56:46,832 INFO  [LoadIncrementalHFiles-19] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/_tmp/_tmp/3886569dba4041deb4487f49d0417ca6.bottom first=f89f12a59e4a9c9bcbb42d0504318e25 last=f8e7bc423ca4799459898439bf0f68b2</span><br><span class="line">2015-12-23 15:56:46,833 INFO  [LoadIncrementalHFiles-20] mapreduce.LoadIncrementalHFiles: Trying to load hfile=hdfs://tdhdfs/user/tongdun/id_hbase/1/id/_tmp/_tmp/_tmp/_tmp/_tmp/_tmp/_tmp/3886569dba4041deb4487f49d0417ca6.top first=f8e7bc4bc8c2e7eac7f7e31bc116f8e0 last=f93061a29e9458fada2521ffe45ca385</span><br><span class="line">2015-12-23 15:56:46,930 INFO  [main] client.ConnectionManager$HConnectionImplementation: Closing master protocol: MasterService</span><br><span class="line">2015-12-23 15:56:46,931 INFO  [main] client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x3515d529acedbaa</span><br><span class="line">2015-12-23 15:56:46,960 INFO  [main] zookeeper.ZooKeeper: Session: 0x3515d529acedbaa closed</span><br><span class="line">2015-12-23 15:56:46,960 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down</span><br></pre></td></tr></table></figure>
<p>even though the process finished, original hfile did’t delete.  I was wondering why mv/rename command not happend.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@spark047213 ~]$ hadoop fs -du -h /user/tongdun/id_hbase/1/id/</span><br><span class="line">3.3 G  /user/tongdun/id_hbase/1/id/01114a58782b4c369819673e4b3678ae</span><br><span class="line">6.0 G  /user/tongdun/id_hbase/1/id/_tmp</span><br></pre></td></tr></table></figure>
<blockquote>
<p>A:This is because the table region changes, not match with the regions when you get the HFiles</p>
</blockquote>
<h4 id="Why_Split">Why Split</h4><p><a href="http://chengjianxiaoxue.iteye.com/blog/2229591" target="_blank" rel="noopener">http://chengjianxiaoxue.iteye.com/blog/2229591</a><br><a href="http://koven2049.iteye.com/blog/982831" target="_blank" rel="noopener">http://koven2049.iteye.com/blog/982831</a><br><a href="http://www.cnblogs.com/shitouer/archive/2013/02/20/hbase-hfile-bulk-load.html" target="_blank" rel="noopener">http://www.cnblogs.com/shitouer/archive/2013/02/20/hbase-hfile-bulk-load.html</a></p>
<p>If the region boundaries have changed during the course of bulk load preparation, or between the preparation and completion steps, the completebulkload utility will automatically split the data files into pieces corresponding to the new boundaries. This process is not optimally efficient, so users should take care to minimize the delay between preparing a bulk load and importing it into the cluster, especially if other clients are simultaneously loading data through other means.</p>
<p>BulkLoad的限制条件: 仅适合初次数据导入，即表内数据为空，或者每次入库表内都无数据的情况  </p>
<p>Hfile批量入Hbase，LoadIncrementalHFiles会检查HFILE的目录（结构是主目录-&gt;列族目录-&gt;hfile），把需要批量导入的Hfile放到一个列表中，依次执行。导入每一个Hfile，系统会判断hfile是否再某个region中还是跨了region（通过前面说的startkey，endkey进行判断）。如果在一个region中，就是进行导入，系统会通过rpc调用regionserver的方法，先把HFILE复制Region所在的文件系统中（如果处于不同的FS），然后直接将HFILE直接改名为Region的一个StoreFile，并更新该Region的Storefile列表，这样该HFILE就入库。如果在HFILE跨的region，那么需要对Hfile进行split（分成.top和.bottom两个文件，每个文件单属于一个region，也是Hfile格式的，放在_tmp下，），接下来把split之后的文件进行入库</p>
<p>如果数据特别大，而表中原来就有region，那么会执行切分工作，查找数据对应的region并装载</p>
<p>回到我们的场景中, 因为我们原始文件有多个, 所以每次MR生成的HFile虽然都是有序的.<br>但是最后所有文件夹都导入时(每个文件夹是由一个MR作业生成),也需要保证每个HFile有序, 就会发生Split!!<br>如果一开始只读取一个文件夹内的所有文件, 虽然reduce会慢点,但是能保证输出的HFile是全局有序的!  </p>
<blockquote>
<p>问：HFILE为什么需要排序？<br>答：那是应为REGION中的storefile是有序的，只有hfile有序，才能通过简单的拆分和rename来转换为storefile，而实现入库。</p>
</blockquote>
<blockquote>
<p>问：有时Hfile入库成功后，原Hfile会被移除，有时又不是？<br>答：如果Hfile的key属于单个region时，直接通过rename导入的，所以原文件不见了。而如果key跨了region，那么需要split到_tmp下，最终入库的的split后的文件，原hfile没有动，所以需要人工去删它。</p>
</blockquote>
<blockquote>
<p>问：如果HFILE跨域多个region，会不会有问题？<br>答：每次split都是分成两个文件，前一个文件肯定是属于单个region的，后一个文件就不一定了，所以，处理split后的文件时会做同样的判断，确保跨region的hfile不断的split。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):008:0&gt; truncate &quot;data.md5_id2&quot;</span><br><span class="line">Truncating &apos;data.md5_id2&apos; table (it may take a while):</span><br><span class="line"> - Disabling table...</span><br><span class="line"> - Truncating table...</span><br><span class="line">0 row(s) in 54.3080 seconds</span><br><span class="line"></span><br><span class="line">hbase(main):009:0&gt; scan &quot;data.md5_id2&quot;</span><br><span class="line">ROW                                                COLUMN+CELL</span><br><span class="line">0 row(s) in 0.0540 seconds</span><br></pre></td></tr></table></figure>
<p>清空表之后, Region只剩一个了. 所以最好要删掉表, 并重建表. </p>
<h2 id="Ref">Ref</h2><ul>
<li><a href="http://grokbase.com/t/cloudera/cdh-user/131rb0a65v/region-stuck-in-transition-due-to-missing-region-directory" target="_blank" rel="noopener">http://grokbase.com/t/cloudera/cdh-user/131rb0a65v/region-stuck-in-transition-due-to-missing-region-directory</a></li>
</ul>

      
    </div>
    
  </div>
  
    
<div class="copyright">
  <p><span>本文标题:</span><a href="/2015/12/23/2015-12-23-HBase-QA/">HBase QA</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 任何忧伤,都抵不过世界的美丽 的个人博客">任何忧伤,都抵不过世界的美丽</a></p>
  <p><span>发布时间:</span>2015年12月23日 - 00时00分</p>
  <p><span>最后更新:</span>2019年02月14日 - 21时42分</p>
  <p>
    <span>原始链接:</span><a href="/2015/12/23/2015-12-23-HBase-QA/" title="HBase QA">http://github.com/zqhxuyuan/2015/12/23/2015-12-23-HBase-QA/</a>
    <span class="btn" data-clipboard-text="原文: http://github.com/zqhxuyuan/2015/12/23/2015-12-23-HBase-QA/　　作者: 任何忧伤,都抵不过世界的美丽" title="点击复制文章链接">
        <i class="fa fa-clipboard"></i>
    </span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" title="中国大陆 (CC BY-NC-SA 3.0 CN)">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。</p>
  <script src="/js/clipboard.min.js"></script>
  <script> var clipboard = new Clipboard('.btn'); </script>
</div>
<style type="text/css">
  .copyright p .btn {
    margin-left: 1em;
  }
  .copyright:hover p .btn::after {
    content: "复制"
  }
  .copyright p .btn:hover {
      color: gray;
      cursor: pointer;
    };
</style>



<nav id="article-nav">
  
    <div id="article-nav-newer" class="article-nav-title">
      <a href="/2015/12/24/2015-12-23-TSDB-Kairosdb/">
        时间序列数据库之Kairosdb
      </a>
    </div>
  
  
    <div id="article-nav-older" class="article-nav-title">
      <a href="/2015/12/21/2015-12-21-HBase-Query/">
        HBase多线程Query优化查询速度
      </a>
    </div>
  
</nav>

  
  
    <div class="post-donate">
	<br>
	<p>
    <div id="donate_board" class="donate_bar center">
        <a id="btn_donate" class="btn_donate" href="javascript:;" title="打赏"></a>
        <span class="donate_txt">
           &uarr;<br>
		   招人广告：对蚂蚁金服中间件感兴趣的可以发邮件到：qihuang.zqh at antfin.com
        </span>
        <br>
    </div>  
	<div id="donate_guide" class="donate_bar center hidden">
		<img src="/img/zhifubao.png" alt="支付宝打赏"> 
		<img src="/img/weixin.png" alt="微信打赏">  
    </div>
	<script type="text/javascript">
		document.getElementById('btn_donate').onclick = function(){
			$('#donate_board').addClass('hidden');
			$('#donate_guide').removeClass('hidden');
		}
	</script>
</p></div>
  
</article>

<!-- 默认显示文章目录，在文章---前输入toc: false关闭目录 -->
<!-- Show TOC and tocButton in default, Hide TOC via putting "toc: false" before "---" at [post].md -->
<div id="toc" class="toc-article">
<strong class="toc-title">文章目录</strong>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#INCONSISTENT_status"><span class="toc-number">1.</span> <span class="toc-text">INCONSISTENT status</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SYSTEM-FUNCTION表损坏"><span class="toc-number">1.1.</span> <span class="toc-text">SYSTEM.FUNCTION表损坏</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#节点假死"><span class="toc-number">1.2.</span> <span class="toc-text">节点假死</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#建表失败"><span class="toc-number">1.3.</span> <span class="toc-text">建表失败</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hdfs_fsck_/hbase"><span class="toc-number">1.4.</span> <span class="toc-text">hdfs fsck /hbase</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RegionSplit"><span class="toc-number">2.</span> <span class="toc-text">RegionSplit</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#BulkLoad没有移动而是复制和Split文件"><span class="toc-number">2.1.</span> <span class="toc-text">BulkLoad没有移动而是复制和Split文件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#不同集群会复制"><span class="toc-number">2.1.1.</span> <span class="toc-text">不同集群会复制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Split_Retry_Many_Times"><span class="toc-number">2.1.2.</span> <span class="toc-text">Split Retry Many Times</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Why_Split"><span class="toc-number">2.1.3.</span> <span class="toc-text">Why Split</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ref"><span class="toc-number">3.</span> <span class="toc-text">Ref</span></a></li></ol>
</div>
<style type="text/css">
  .left-col .switch-btn {
    display: none;
  }
  .left-col .switch-area {
    display: none;
  }
</style>

<input type="button" id="tocButton" value="隐藏目录" title="点击按钮隐藏或者显示文章目录">
<script type="text/javascript">
  var toc_button= document.getElementById("tocButton");
  var toc_div= document.getElementById("toc");
  /* Show or hide toc when click on tocButton.
  通过点击设置的按钮显示或者隐藏文章目录.*/
  toc_button.onclick=function(){
  if(toc_div.style.display=="none"){
  toc_div.style.display="block";
  toc_button.value="隐藏目录";
  document.getElementById("switch-btn").style.display="none";
  document.getElementById("switch-area").style.display="none";
  }
  else{
  toc_div.style.display="none";
  toc_button.value="显示目录";
  document.getElementById("switch-btn").style.display="block";
  document.getElementById("switch-area").style.display="block";
  }
  }
    if ($(".toc").length < 1) {
        $("#toc").css("display","none");
        $("#tocButton").css("display","none");
        $(".switch-btn").css("display","block");
        $(".switch-area").css("display","block");
    }
</script>


    <style>
        .toc {
            white-space: nowrap;
            overflow-x: hidden;
        }
    </style>

    <script>
        $(document).ready(function() {
            $(".toc li a").mouseover(function() {
                var title = $(this).attr('href');
                $(this).attr("title", title);
            });
        })
    </script>




<div class="share">
	<div class="bdsharebuttonbox">
	<a href="#" class="bds_more" data-cmd="more"></a>
	<a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
	<a href="#" class="bds_copy" data-cmd="copy" title="复制网址"></a>
	<a href="#" class="bds_mail" data-cmd="mail" title="通过邮件分享"></a>
	<a href="#" class="bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
	</div>
	<script>
	window._bd_share_config={
		"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
	</script>
</div>



<div class="duoshuo" id="comments">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="2015/12/23/2015-12-23-HBase-QA/" data-title="HBase QA" data-url="http://github.com/zqhxuyuan/2015/12/23/2015-12-23-HBase-QA/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"zqhxuyuan"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>






    <style type="text/css">
    #scroll {
      display: none;
    }
    </style>
    <div class="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
    </div>


  
  
    
    <div class="post-nav-button">
    <a href="/2015/12/24/2015-12-23-TSDB-Kairosdb/" title="上一篇: 时间序列数据库之Kairosdb">
    <i class="fa fa-angle-left"></i>
    </a>
    <a href="/2015/12/21/2015-12-21-HBase-Query/" title="下一篇: HBase多线程Query优化查询速度">
    <i class="fa fa-angle-right"></i>
    </a>
    </div>
  



    
        <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
        <script>
        var yiliaConfig = {
        fancybox: true,
        mathjax: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        open_in_new: false
        }
        </script>
        
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2019 任何忧伤,都抵不过世界的美丽
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的静态博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减双栏 Hexo 博客主题">Yelee</a> by MOxFIVE
        </div>
    </div>
    <div class="visit">
      <span id="busuanzi_container_site_pv" style="display:none">
        <span id="site-visit">本站到访数: 
        <span id="busuanzi_value_site_uv"></span>
        </span>
      </span>
      <span id="busuanzi_container_page_pv" style="display:none">
        <span id="page-visit">, 本页阅读量: 
        <span id="busuanzi_value_page_pv"></span>
        </span>
      </span>
    </div>
  </div>
</footer>
    </div>
    

<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>

<script>
  var backgroundnum = 5;
  var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));

  $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
</script>


<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-80646710-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
<a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
<a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>