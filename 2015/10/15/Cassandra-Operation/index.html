<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>Cassandra操作 | zqhxuyuan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="优雅关闭节点 不同集群数据同步 增量备份 准备工作：新集群搭建和建表 开始：先测试一张表的迁移 整个集群做一次完整的快照迁移 增量备份（需要多次执行） 机房迁移 直接从当前集群同步到上海集群 新集群安装  表结构    数据迁移    增量数据迁移    数据验证       nodetool工具 集群状态: nodetool decribecluster 删除节点: removenode 替">
<meta name="keywords" content="cassandra">
<meta property="og:type" content="article">
<meta property="og:title" content="Cassandra操作">
<meta property="og:url" content="http://github.com/zqhxuyuan/2015/10/15/Cassandra-Operation/index.html">
<meta property="og:site_name" content="zqhxuyuan">
<meta property="og:description" content="优雅关闭节点 不同集群数据同步 增量备份 准备工作：新集群搭建和建表 开始：先测试一张表的迁移 整个集群做一次完整的快照迁移 增量备份（需要多次执行） 机房迁移 直接从当前集群同步到上海集群 新集群安装  表结构    数据迁移    增量数据迁移    数据验证       nodetool工具 集群状态: nodetool decribecluster 删除节点: removenode 替">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20151030101713671">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160317181038372">
<meta property="og:updated_time" content="2019-02-14T13:42:29.300Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Cassandra操作">
<meta name="twitter:description" content="优雅关闭节点 不同集群数据同步 增量备份 准备工作：新集群搭建和建表 开始：先测试一张表的迁移 整个集群做一次完整的快照迁移 增量备份（需要多次执行） 机房迁移 直接从当前集群同步到上海集群 新集群安装  表结构    数据迁移    增量数据迁移    数据验证       nodetool工具 集群状态: nodetool decribecluster 删除节点: removenode 替">
<meta name="twitter:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20151030101713671">
  
    <link rel="alternative" href="/atom.xml" title="zqhxuyuan" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">任何忧伤,都抵不过世界的美丽</a></h1>
		</hgroup>

		
				


		
			<div id="switch-btn" class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div id="switch-area" class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives/">归档</a></li>
				        
							<li><a href="/tags/">标签</a></li>
				        
							<li><a href="/about/">关于</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
								<li id="RSS"><a class="RSS" target="_blank" href="/atom.xml" title="RSS"></a></li>
					        
						</ul>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/apex/" style="font-size: 10px;">apex</a> <a href="/tags/bigdata/" style="font-size: 10px;">bigdata</a> <a href="/tags/book/" style="font-size: 10px;">book</a> <a href="/tags/cassandra/" style="font-size: 18.89px;">cassandra</a> <a href="/tags/clojure/" style="font-size: 10px;">clojure</a> <a href="/tags/drill/" style="font-size: 16.67px;">drill</a> <a href="/tags/druid/" style="font-size: 13.33px;">druid</a> <a href="/tags/dubbo/" style="font-size: 10px;">dubbo</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/etl/" style="font-size: 10px;">etl</a> <a href="/tags/geode/" style="font-size: 10px;">geode</a> <a href="/tags/graph/" style="font-size: 12.22px;">graph</a> <a href="/tags/hadoop/" style="font-size: 11.11px;">hadoop</a> <a href="/tags/hbase/" style="font-size: 15.56px;">hbase</a> <a href="/tags/ignite/" style="font-size: 10px;">ignite</a> <a href="/tags/java/" style="font-size: 10px;">java</a> <a href="/tags/jvm/" style="font-size: 10px;">jvm</a> <a href="/tags/kafka/" style="font-size: 20px;">kafka</a> <a href="/tags/midd/" style="font-size: 10px;">midd</a> <a href="/tags/ops/" style="font-size: 12.22px;">ops</a> <a href="/tags/redis/" style="font-size: 11.11px;">redis</a> <a href="/tags/rocketmq/" style="font-size: 10px;">rocketmq</a> <a href="/tags/scala/" style="font-size: 13.33px;">scala</a> <a href="/tags/spark/" style="font-size: 17.78px;">spark</a> <a href="/tags/storm/" style="font-size: 17.78px;">storm</a> <a href="/tags/tcc/" style="font-size: 10px;">tcc</a> <a href="/tags/timeseries/" style="font-size: 12.22px;">timeseries</a> <a href="/tags/work/" style="font-size: 14.44px;">work</a> <a href="/tags/流处理/" style="font-size: 11.11px;">流处理</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">BIG(DATA)</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<a href="/" class="profilepic">
				<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			</a>
			<hgroup>
			  <h1 class="header-author"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives/">归档</a></li>
		        
					<li><a href="/tags/">标签</a></li>
		        
					<li><a href="/about/">关于</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
								<li id="RSS"><a class="RSS" target="_blank" href="/atom.xml" title="RSS"></a></li>
					        
						</ul>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-Cassandra-Operation" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/10/15/Cassandra-Operation/" class="article-date">
  	<time datetime="2015-10-14T16:00:00.000Z" itemprop="datePublished">2015-10-15</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Cassandra操作
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/work/">work</a>
	</div>


        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cassandra/">cassandra</a></li></ul>
	</div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <!-- MarkdownTOC -->
<ul>
<li>优雅关闭节点</li>
<li>不同集群数据同步<ul>
<li>增量备份</li>
<li>准备工作：新集群搭建和建表</li>
<li>开始：先测试一张表的迁移</li>
<li>整个集群做一次完整的快照迁移</li>
<li>增量备份（需要多次执行）</li>
<li>机房迁移<ul>
<li>直接从当前集群同步到上海集群</li>
<li>新集群安装</li>
<li><ol>
<li>表结构</li>
</ol>
</li>
<li><ol start="2">
<li>数据迁移</li>
</ol>
</li>
<li><ol start="3">
<li>增量数据迁移</li>
</ol>
</li>
<li><ol start="4">
<li>数据验证</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li>nodetool工具<ul>
<li>集群状态: nodetool decribecluster</li>
<li>删除节点: removenode</li>
<li>替换节点: replace_address</li>
<li>重新加入</li>
<li>网络状态netstats: 显示一个节点的Active Stream</li>
<li>节点信息: nodetool info</li>
<li>Gossip信息: nodetool gossipinfo</li>
<li>表相关的信息:nodetool cfstats forseti.velocity</li>
<li>compactionhistory</li>
<li>节点sstable数量异常</li>
</ul>
</li>
<li>tpstats</li>
<li>sstable writer<ul>
<li>文件数过多</li>
<li>导入数据后，用refresh</li>
<li>通过增大内存来增大sstable大小（内存不足）</li>
<li>分表？</li>
</ul>
</li>
<li>sstableloader</li>
<li>jHiccup</li>
</ul>
<!-- /MarkdownTOC -->
<a id="more"></a>
<h2 id="优雅关闭节点">优雅关闭节点</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">[admin@cass048169 ~]$ /usr/install/cassandra/bin/nodetool stopdaemon</span><br><span class="line">Cassandra has shutdown.</span><br><span class="line">error: 拒绝连接</span><br><span class="line">-- StackTrace --</span><br><span class="line">java.net.ConnectException: 拒绝连接</span><br><span class="line">  at java.net.PlainSocketImpl.socketConnect(Native Method)</span><br><span class="line">  at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)</span><br><span class="line">  at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)</span><br><span class="line">  at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)</span><br><span class="line">  at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)</span><br><span class="line">  at java.net.Socket.connect(Socket.java:579)</span><br><span class="line">  at java.net.Socket.connect(Socket.java:528)</span><br><span class="line">  at java.net.Socket.&lt;init&gt;(Socket.java:425)</span><br><span class="line">  at java.net.Socket.&lt;init&gt;(Socket.java:208)</span><br><span class="line">  at sun.rmi.transport.proxy.RMIDirectSocketFactory.createSocket(RMIDirectSocketFactory.java:40)</span><br><span class="line">  at sun.rmi.transport.proxy.RMIMasterSocketFactory.createSocket(RMIMasterSocketFactory.java:147)</span><br><span class="line">  at sun.rmi.transport.tcp.TCPEndpoint.newSocket(TCPEndpoint.java:613)</span><br><span class="line">  at sun.rmi.transport.tcp.TCPChannel.createConnection(TCPChannel.java:216)</span><br><span class="line">  at sun.rmi.transport.tcp.TCPChannel.newConnection(TCPChannel.java:202)</span><br><span class="line">  at sun.rmi.server.UnicastRef.invoke(UnicastRef.java:129)</span><br><span class="line">  at com.sun.jmx.remote.internal.PRef.invoke(Unknown Source)</span><br><span class="line">  at javax.management.remote.rmi.RMIConnectionImpl_Stub.close(Unknown Source)</span><br><span class="line">  at javax.management.remote.rmi.RMIConnector.close(RMIConnector.java:512)</span><br><span class="line">  at javax.management.remote.rmi.RMIConnector.close(RMIConnector.java:452)</span><br><span class="line">  at org.apache.cassandra.tools.NodeProbe.close(NodeProbe.java:237)</span><br><span class="line">  at org.apache.cassandra.tools.NodeTool$NodeToolCmd.run(NodeTool.java:295)</span><br><span class="line">  at org.apache.cassandra.tools.NodeTool.main(NodeTool.java:206)</span><br><span class="line"></span><br><span class="line">[admin@cass048169 ~]$</span><br><span class="line">[admin@cass048169 ~]$</span><br><span class="line">[admin@cass048169 ~]$ ps -ef|grep cassandra</span><br><span class="line">admin    40084 37927  0 09:46 pts/0    00:00:00 grep cassandra</span><br></pre></td></tr></table></figure>
<h2 id="不同集群数据同步">不同集群数据同步</h2><p>1.sstableloader的文件夹必须是keyspace/table格式,否则空指针异常:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@dp0652 ~]$ /usr/install/cassandra/bin/sstableloader -d localhost 1445938244634</span><br><span class="line">Exception in thread &quot;main&quot; java.lang.NullPointerException</span><br><span class="line">  at org.apache.cassandra.io.sstable.SSTableLoader.&lt;init&gt;(SSTableLoader.java:59)</span><br><span class="line">  at org.apache.cassandra.tools.BulkLoader.main(BulkLoader.java:80)</span><br><span class="line"></span><br><span class="line">$ cd /home/admin/data/cassandra/data/forseti/velocity/snapshots</span><br><span class="line">$ /usr/install/cassandra/bin/sstableloader -d 192.168.6.52 1445938244634</span><br><span class="line">Exception in thread &quot;main&quot; java.lang.NullPointerException</span><br><span class="line">  at org.apache.cassandra.io.sstable.SSTableLoader.&lt;init&gt;(SSTableLoader.java:59)</span><br><span class="line">  at org.apache.cassandra.tools.BulkLoader.main(BulkLoader.java:80)</span><br></pre></td></tr></table></figure>
<p>2.做快照后会在表目录生成snapshots文件夹, 不能直接在表目录上使用sstableloader:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ /usr/install/cassandra/bin/sstableloader -d 192.168.6.52 /home/admin/data/cassandra/data/forseti/velocity/snapshots/1445938244634</span><br><span class="line">Could not retrieve endpoint ranges:</span><br><span class="line">InvalidRequestException(why:No such keyspace: snapshots)</span><br><span class="line">Run with --debug to get full stack trace or --help to get help.</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@mysql006070 ~]$ /usr/install/cassandra/bin/sstableloader -d 192.168.6.52 /home/admin/data/cassandra/data/forseti/velocity</span><br><span class="line">Established connection to initial hosts</span><br><span class="line">Opening sstables and calculating sections to stream</span><br><span class="line">Exception in thread &quot;main&quot; FSWriteError in /home/admin/data/cassandra/data/forseti/velocity/forseti-velocity-jb-414-Summary.db</span><br><span class="line">  at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:122)</span><br><span class="line">  at org.apache.cassandra.io.sstable.SSTableReader.loadSummary(SSTableReader.java:546)</span><br><span class="line">  at org.apache.cassandra.io.sstable.SSTableReader.openForBatch(SSTableReader.java:173)</span><br><span class="line">  at org.apache.cassandra.io.sstable.SSTableLoader$1.accept(SSTableLoader.java:107)</span><br><span class="line">  at java.io.File.list(File.java:1155)</span><br><span class="line">  at org.apache.cassandra.io.sstable.SSTableLoader.openSSTables(SSTableLoader.java:68)</span><br><span class="line">  at org.apache.cassandra.io.sstable.SSTableLoader.stream(SSTableLoader.java:150)</span><br><span class="line">  at org.apache.cassandra.tools.BulkLoader.main(BulkLoader.java:95)</span><br><span class="line">Caused by: java.nio.file.AccessDeniedException: /home/admin/data/cassandra/data/forseti/velocity/forseti-velocity-jb-414-Summary.db</span><br><span class="line">  at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:118)</span><br><span class="line">  ... 7 more</span><br><span class="line">[qihuang.zheng@mysql006070 ~]$ sudo -u admin /usr/install/cassandra/bin/sstableloader -d 192.168.6.52 /home/admin/data/cassandra/data/forseti/velocity</span><br><span class="line">Caused by: java.net.UnknownHostException: mysql006070: 未知的名称或服务</span><br><span class="line">  at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)</span><br><span class="line">  at java.net.InetAddress$1.lookupAllHostAddr(InetAddress.java:901)</span><br><span class="line">  at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1293)</span><br><span class="line">  at java.net.InetAddress.getLocalHost(InetAddress.java:1469)</span><br><span class="line">  ... 11 more</span><br></pre></td></tr></table></figure>
<p>3.使用sstableloader时, 在表目录下不能存在snapshots目录.  <a href="http://tonywutao.github.io/2013/10/17/SSS-Table-Loader-in-Cassandra/" target="_blank" rel="noopener">http://tonywutao.github.io/2013/10/17/SSS-Table-Loader-in-Cassandra/</a><br>但是做快照时, snapshots目录又是生成在表目录下, 所以不能直接用sstableloader, 解决办法是将快照文件夹拷贝到别的地方,并按照keyspace/table格式.<br>如果运行sstableloader的机器的内存不足, 会报OOM, 可以加大内存, 但是如果机器本身内存不足, 最好的办法只能是scp到一台比较大内存的机器.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space</span><br><span class="line">  at java.util.TreeMap.put(TreeMap.java:569)</span><br><span class="line">  at java.util.TreeSet.add(TreeSet.java:255)</span><br><span class="line">  at org.apache.cassandra.io.compress.CompressionMetadata.getChunksForSections(CompressionMetadata.java:226)</span><br><span class="line">  at org.apache.cassandra.streaming.messages.OutgoingFileMessage.&lt;init&gt;(OutgoingFileMessage.java:76)</span><br><span class="line">  at org.apache.cassandra.streaming.StreamTransferTask.addTransferFile(StreamTransferTask.java:56)</span><br><span class="line">  at org.apache.cassandra.streaming.StreamSession.addTransferFiles(StreamSession.java:340)</span><br><span class="line">  at org.apache.cassandra.streaming.StreamPlan.transferFiles(StreamPlan.java:138)</span><br><span class="line">  at org.apache.cassandra.io.sstable.SSTableLoader.stream(SSTableLoader.java:178)</span><br><span class="line">  at org.apache.cassandra.tools.BulkLoader.main(BulkLoader.java:95)</span><br><span class="line">ERROR 13:32:10,104 Error in ThreadPoolExecutor</span><br><span class="line">java.lang.OutOfMemoryError: Java heap space</span><br><span class="line">  at org.apache.cassandra.utils.BackgroundActivityMonitor.readAndCompute(BackgroundActivityMonitor.java:84)</span><br><span class="line">  at org.apache.cassandra.utils.BackgroundActivityMonitor.getIOWait(BackgroundActivityMonitor.java:125)</span><br><span class="line">  at org.apache.cassandra.utils.BackgroundActivityMonitor$BackgroundActivityReporter.run(BackgroundActivityMonitor.java:153)</span><br><span class="line">  at org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor$UncomplainingRunnable.run(DebuggableScheduledThreadPoolExecutor.java:80)</span><br><span class="line">  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)</span><br><span class="line">  at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)</span><br><span class="line">  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)</span><br><span class="line">  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)</span><br><span class="line">  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)</span><br><span class="line">  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)</span><br><span class="line">  at java.lang.Thread.run(Thread.java:744)</span><br><span class="line"></span><br><span class="line">Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: GC overhead limit exceeded</span><br><span class="line">  at org.apache.cassandra.io.compress.CompressionMetadata.getChunksForSections(CompressionMetadata.java:226)</span><br><span class="line">  at org.apache.cassandra.streaming.messages.OutgoingFileMessage.&lt;init&gt;(OutgoingFileMessage.java:76)</span><br><span class="line">  at org.apache.cassandra.streaming.StreamTransferTask.addTransferFile(StreamTransferTask.java:56)</span><br><span class="line">  at org.apache.cassandra.streaming.StreamSession.addTransferFiles(StreamSession.java:340)</span><br><span class="line">  at org.apache.cassandra.streaming.StreamPlan.transferFiles(StreamPlan.java:138)</span><br><span class="line">  at org.apache.cassandra.io.sstable.SSTableLoader.stream(SSTableLoader.java:178)</span><br><span class="line">  at org.apache.cassandra.tools.BulkLoader.main(BulkLoader.java:95)</span><br></pre></td></tr></table></figure>
<p><a href="http://stackoverflow.com/questions/32715401/cassandra-migrate-keyspace-data-from-multinode-cluster-to-singlenode-cluster" target="_blank" rel="noopener">http://stackoverflow.com/questions/32715401/cassandra-migrate-keyspace-data-from-multinode-cluster-to-singlenode-cluster</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">ERROR [StreamReceiveTask:124] 2016-06-10 18:09:31,717 StreamReceiveTask.java:183 - Error applying streamed data:</span><br><span class="line">org.apache.cassandra.io.FSReadError: java.io.IOException: Map failed</span><br><span class="line">        at org.apache.cassandra.io.util.MmappedSegmentedFile$Builder.createSegments(MmappedSegmentedFile.java:399) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.util.MmappedSegmentedFile$Builder.complete(MmappedSegmentedFile.java:365) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.util.SegmentedFile$Builder.complete(SegmentedFile.java:174) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.sstable.SSTableWriter.finish(SSTableWriter.java:463) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SSTableWriter.java:447) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SSTableWriter.java:442) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.streaming.StreamReceiveTask$OnCompletionRunnable.run(StreamReceiveTask.java:141) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_51]</span><br><span class="line">        at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_51]</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_51]</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_51]</span><br><span class="line">        at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]</span><br><span class="line">Caused by: java.io.IOException: Map failed</span><br><span class="line">        at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:888) ~[na:1.7.0_51]</span><br><span class="line">        at org.apache.cassandra.io.util.MmappedSegmentedFile$Builder.createSegments(MmappedSegmentedFile.java:392) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        ... 11 common frames omitted</span><br><span class="line">Caused by: java.lang.OutOfMemoryError: Map failed</span><br><span class="line">        at sun.nio.ch.FileChannelImpl.map0(Native Method) ~[na:1.7.0_51]</span><br><span class="line">        at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:885) ~[na:1.7.0_51]</span><br><span class="line">        ... 12 common frames omitted</span><br><span class="line">ERROR [StreamReceiveTask:124] 2016-06-10 18:09:31,717 JVMStabilityInspector.java:117 - JVM state determined to be unstable.  Exiting forcefully due to:</span><br><span class="line">java.lang.OutOfMemoryError: Map failed</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ERROR [CompactionExecutor:10060] 2016-07-10 15:29:45,520 CassandraDaemon.java:229 - Exception in thread Thread[CompactionExecutor:10060,1,main]</span><br><span class="line">java.lang.RuntimeException: Out of native memory occured, You can avoid it by increasing the system ram space or by increasing bloom_filter_fp_chance.</span><br><span class="line">        at org.apache.cassandra.utils.obs.OffHeapBitSet.&lt;init&gt;(OffHeapBitSet.java:48) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.utils.FilterFactory.createFilter(FilterFactory.java:84) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.utils.FilterFactory.getFilter(FilterFactory.java:78) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.sstable.SSTableWriter$IndexWriter.&lt;init&gt;(SSTableWriter.java:592) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.sstable.SSTableWriter.&lt;init&gt;(SSTableWriter.java:141) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.db.compaction.CompactionTask.createCompactionWriter(CompactionTask.java:308) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:190) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:73) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:59) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:263) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_51]</span><br><span class="line">        at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_51]</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_51]</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_51]</span><br><span class="line">        at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]</span><br></pre></td></tr></table></figure>
<h3 id="增量备份">增量备份</h3><p>先做snaptshot，然后修改配置，并重启集群</p>
<blockquote>
<p>在新版的Cassandra中有nodetool enablebackup选项可以直接修改，而不用重启！</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">host=`ifconfig | grep &quot;192.168.4&quot; | awk &apos;/inet addr/&#123;sub(&quot;addr:&quot;,&quot;&quot;); print $2&#125;&apos;`</span><br><span class="line">sed -i -e &quot;s/incremental_backups: false/incremental_backups: true/g&quot; /usr/install/cassandra/conf/cassandra.yaml</span><br><span class="line">cat /usr/install/cassandra/conf/cassandra.yaml | grep incremental_backups</span><br><span class="line">/usr/install/cassandra/bin/nodetool -h $host snapshot forseti_fp</span><br><span class="line">/usr/install/cassandra/bin/nodetool flush</span><br><span class="line">kill -9 `/usr/install/java/bin/jps | grep CassandraDaemon |awk &apos;&#123;print $1&#125;&apos;`</span><br><span class="line">ps -ef | grep cassandra</span><br><span class="line">sleep 10s</span><br><span class="line">/usr/install/cassandra/bin/cassandra</span><br><span class="line"></span><br><span class="line">ll /home/admin/cassandra/data/forseti_fp/android_device_session/snapshots</span><br><span class="line">ll /home/admin/cassandra/data/forseti_fp/android_device_session/backups</span><br><span class="line">du -sh /home/admin/cassandra/data/forseti_fp/android_device_session/snapshots</span><br><span class="line">du -sh /home/admin/cassandra/data/forseti_fp/android_device_session/backups</span><br></pre></td></tr></table></figure>
<p>After a system-wide snapshot is performed, you can enable incremental backups on each node to backup data that has changed<br>since the last snapshot: each time an SSTable is flushed, a hard link is copied into a /backups subdirectory of the data directory</p>
<p>是先做全局的快照（每个节点都做），然后再开启增量备份：修改配置，重启每个节点。<br>如果没有先做全局快照，而是每个节点做完快照后，立即修改配置，然后重启，接着处理下一个节点，有没有影响？<br>不过可以通过制定nodetool的-h选项一次性在一个节点上就做完全的快照，而不用登陆每个节点一个一个做快照！根本不用pssh！</p>
<p>快照后生成的文件在：data_directory_location/keyspace_name/table_name/snapshots/UUID/<br>增量备份后文件生成在：data_directory_location/keyspace_name/table_name/backups/</p>
<p>incremental backups combine with snapshots to provide a dependable, up-to-date backup mechanism.<br>增量备份依赖于快照中的内容，提供可靠的、最新的备份机制。</p>
<p>问题：如果把快照删除了，增量备份还可以正常工作吗？</p>
<h3 id="准备工作：新集群搭建和建表">准备工作：新集群搭建和建表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cluster_name: fp_back</span><br><span class="line">data_file_directories: [/data01,/data02,/data03,/data04,/data05,/data06,/data07,/data08,/data09,/data10,/data11,/data12]</span><br><span class="line">saved_caches_directory: /home/admin/cassandra/saved_caches</span><br><span class="line">commitlog_directory: /home/admin/cassandra/commitlog</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget http://192.168.47.211:8000/apache-cassandra-2.1.13.tar.gz</span><br><span class="line">tar zxf apache-cassandra-2.1.13.tar.gz</span><br><span class="line">host=`ifconfig | grep &quot;192.168.50&quot; | awk &apos;/inet addr/&#123;sub(&quot;addr:&quot;,&quot;&quot;); print $2&#125;&apos;`</span><br><span class="line">sed -i -e &quot;s#192.168.47.211#$host#g&quot; apache-cassandra-2.1.13/conf/cassandra.yaml</span><br><span class="line">sed -i -e &quot;s#192.168.47.211#$host#g&quot; apache-cassandra-2.1.13/conf/cassandra-env.sh</span><br><span class="line">mkdir /home/admin/cassandra</span><br><span class="line">apache-cassandra-2.1.13/bin/cassandra</span><br></pre></td></tr></table></figure>
<p>将原集群的脚本导成cql文件，并连接目标集群，导入数据库，可以修改副本数。 不需要登录目标集群操作！  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/usr/install/cassandra/bin/cqlsh 192.168.48.159 -e &apos;desc keyspace forseti_fp&apos; &gt; forseti_fp.cql</span><br><span class="line">/usr/install/cassandra/bin/cqlsh 192.168.50.20 -f forseti_fp.cql</span><br><span class="line">CREATE KEYSPACE forseti_fp WITH replication = &#123;</span><br><span class="line">  &apos;class&apos;: &apos;NetworkTopologyStrategy&apos;,</span><br><span class="line">  &apos;DC2&apos;: &apos;1&apos;,</span><br><span class="line">  &apos;DC1&apos;: &apos;1&apos;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="开始：先测试一张表的迁移">开始：先测试一张表的迁移</h3><p>快照文件不能直接用sstableloader操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ ll /home/admin/cassandra/data/forseti_fp/android_device_session/snapshots</span><br><span class="line">1464167616242</span><br><span class="line">$ /usr/install/cassandra/bin/sstableloader -d 192.168.50.20 /home/admin/cassandra/data/forseti_fp/android_device_session/snapshots</span><br><span class="line">Could not retrieve endpoint ranges:</span><br><span class="line">InvalidRequestException(why:No such keyspace: android_device_session)</span><br><span class="line">$ /usr/install/cassandra/bin/sstableloader -d 192.168.50.20 /home/admin/cassandra/data/forseti_fp/android_device_session/snapshots/1464167616242</span><br><span class="line">Could not retrieve endpoint ranges:</span><br><span class="line">InvalidRequestException(why:No such keyspace: snapshots)</span><br><span class="line"></span><br><span class="line">snap=`ls /home/admin/cassandra/data/forseti_fp/android_device_session/snapshots`</span><br><span class="line">mv /home/admin/cassandra/data/forseti_fp/android_device_session/snapshots/$snap /home/admin/cassandra/ &amp;&amp; cd /home/admin/cassandra &amp;&amp; mkdir forseti_fp</span><br><span class="line">mv $snap android_device_session &amp;&amp; mv android_device_session forseti_fp</span><br><span class="line">nohup /usr/install/cassandra/bin/sstableloader -d 192.168.50.20,192.168.50.21,192.168.50.22,192.168.50.23,192.168.50.24 /home/admin/cassandra/forseti_fp/android_device_session &amp;</span><br></pre></td></tr></table></figure>
<p>默认sstableloader的内存只有512M，修改为<strong>3072M</strong>后，可以成功导入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[admin@spark015010 ~]$ du -sh /data*/forseti_fp/android_device_session-*</span><br><span class="line">4.0K    /data01/forseti_fp/android_device_session-980e940023af11e6a5ea87f007ccb41c</span><br><span class="line">4.0K    /data02/forseti_fp/android_device_session-980e940023af11e6a5ea87f007ccb41c</span><br><span class="line">4.0K    /data03/forseti_fp/android_device_session-980e940023af11e6a5ea87f007ccb41c</span><br><span class="line">4.0K    /data04/forseti_fp/android_device_session-980e940023af11e6a5ea87f007ccb41c</span><br><span class="line">4.0K    /data05/forseti_fp/android_device_session-980e940023af11e6a5ea87f007ccb41c</span><br><span class="line">4.0K    /data06/forseti_fp/android_device_session-980e940023af11e6a5ea87f007ccb41c</span><br><span class="line">4.0K    /data07/forseti_fp/android_device_session-980e940023af11e6a5ea87f007ccb41c</span><br><span class="line">4.0K    /data08/forseti_fp/android_device_session-980e940023af11e6a5ea87f007ccb41c</span><br><span class="line">4.0K    /data09/forseti_fp/android_device_session-980e940023af11e6a5ea87f007ccb41c</span><br><span class="line">3.5G    /data10/forseti_fp/android_device_session-980e940023af11e6a5ea87f007ccb41c</span><br><span class="line">4.0K    /data11/forseti_fp/android_device_session-980e940023af11e6a5ea87f007ccb41c</span><br><span class="line">4.0K    /data12/forseti_fp/android_device_session-980e940023af11e6a5ea87f007ccb41c</span><br></pre></td></tr></table></figure>
<p>内存不足时报错：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ERROR 03:58:12 [Stream #4f0fadf0-23b1-11e6-bbf2-2592342d3b2e] Streaming error occurred</span><br><span class="line">java.lang.OutOfMemoryError: GC overhead limit exceeded</span><br><span class="line">    at java.util.TreeMap.put(TreeMap.java:569) ~[na:1.7.0_51]</span><br><span class="line">    at java.util.TreeSet.add(TreeSet.java:255) ~[na:1.7.0_51]</span><br><span class="line">    at org.apache.cassandra.io.compress.CompressionMetadata.getChunksForSections(CompressionMetadata.java:287) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">    at org.apache.cassandra.streaming.messages.FileMessageHeader$FileMessageHeaderSerializer.serialize(FileMessageHeader.java:172) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">    at org.apache.cassandra.streaming.messages.OutgoingFileMessage.serialize(OutgoingFileMessage.java:82) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">    at org.apache.cassandra.streaming.messages.OutgoingFileMessage$1.serialize(OutgoingFileMessage.java:49) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">    at org.apache.cassandra.streaming.messages.OutgoingFileMessage$1.serialize(OutgoingFileMessage.java:41) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">    at org.apache.cassandra.streaming.messages.StreamMessage.serialize(StreamMessage.java:45) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">    at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.sendMessage(ConnectionHandler.java:351) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">    at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.run(ConnectionHandler.java:323) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">    at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]</span><br><span class="line">progress: [/192.168.50.24]0:0/19 0  % [/192.168.50.21]0:1/19 0  % [/192.168.50.20]0:0/19 0  % [/192.168.50.23]0:2/19 0  % [/192.168.50.22]0:1/19 0  % total: 0% 0  MB/s(avg: 0 MB/s)</span><br><span class="line">ERROR 03:58:12 [Stream #4f0fadf0-23b1-11e6-bbf2-2592342d3b2e] Remote peer 192.168.50.23 failed stream session.</span><br><span class="line">progress: [/192.168.50.24]0:0/19 0  % [/192.168.50.21]0:1/19 0  % [/192.168.50.20]0:0/19 0  % [/192.168.50.23]0:2/19 0  % [/192.168.50.22]0:3/19 0  % total: 0% 0  MB/s(avg: 0 MB/s)</span><br><span class="line">/usr/install/cassandra/bin/sstableloader: line 53: </span><br><span class="line">15459 已杀死               &quot;$JAVA&quot; $JAVA_AGENT -ea -cp &quot;$CLASSPATH&quot; $JVM_OPTS -Xmx$MAX_HEAP_SIZE -Dcassandra.storagedir=&quot;$cassandra_storagedir&quot; -Dlogback.configurationFile=logback-tools.xml org.apache.cassandra.tools.BulkLoader &quot;$@&quot;</span><br></pre></td></tr></table></figure>
<p>sstableloader完成后的日志：  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Established connection to initial hosts</span><br><span class="line">Opening sstables and calculating sections to stream</span><br><span class="line">....</span><br><span class="line">100% total: 100% 0  MB/s(avg: 24 MB/s)</span><br><span class="line">Summary statistics:</span><br><span class="line">   Connections per host:         : 1</span><br><span class="line">   Total files transferred:      : 85</span><br><span class="line">   Total bytes transferred:      : 2291137192904</span><br><span class="line">   Total duration (ms):          : 87700111  --&gt; 24小时！</span><br><span class="line">   Average transfer rate (MB/s): : 24</span><br><span class="line">   Peak transfer rate (MB/s):    : 24</span><br></pre></td></tr></table></figure>
<p>一次完整的snapshot，android_device_session表在每个节点的耗时统计</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">节点             Load       耗时(ms)   传输量(bytes)   大小/实际大小</span><br><span class="line">192.168.48.228  2.51 TB    69222991  1808724189277   80G/1.7T</span><br><span class="line">192.168.48.227  2.67 TB    24897246  590477418187    284G/1.9T</span><br><span class="line">192.168.48.226  2.58 TB    73820237  1928301531978   249G/1.8T </span><br><span class="line">192.168.48.176  5.9 TB     77773491  2032068642522   1018G/1.9T   </span><br><span class="line">192.168.48.161  4.28 TB    78947850  2060434319116   46G/?</span><br><span class="line">192.168.48.160  4.34 TB    87700111  2291137192904   ?/1.1T</span><br><span class="line">192.168.48.175  3.01 TB    68711040  1794574379750   178G/?</span><br><span class="line">192.168.48.159  4.46 TB    88088722  2299781089484   ?/1.4T</span><br></pre></td></tr></table></figure>
<h3 id="整个集群做一次完整的快照迁移">整个集群做一次完整的快照迁移</h3><p>准备目录结构(只需执行一次)：<code>sh table.sh</code><br>在<code>/home/admin/cassandra/forseti_fp</code>下创建表目录</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/admin/cassandra/forseti_fp</span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> /home/admin/cassandra/data/forseti_fp/*</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">test</span> -d <span class="variable">$file</span></span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        table=`basename <span class="variable">$file</span>`</span><br><span class="line">        snap=`ls <span class="variable">$file</span>/snapshots`</span><br><span class="line">        <span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$snap</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="variable">$table</span> <span class="variable">$snap</span></span><br><span class="line">            mkdir <span class="variable">$table</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p>执行一次snapshot全量数据迁移(只需执行一次): <code>nohup sh snap.sh &gt; snap_alltable.log &amp;</code><br>拷贝<code>/home/admin/cassandra/data/forseti_fp/$table/snapshots/$snap/*</code> 到<code>/home/admin/cassandra/forseti_fp/$table</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> /home/admin/cassandra/data/forseti_fp/*</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">test</span> -d <span class="variable">$file</span></span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        table=`basename <span class="variable">$file</span>`</span><br><span class="line">        snap=`ls <span class="variable">$file</span>/snapshots`</span><br><span class="line">        <span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$snap</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">            mv <span class="variable">$file</span>/snapshots/<span class="variable">$snap</span>/* /home/admin/cassandra/forseti_fp/<span class="variable">$table</span></span><br><span class="line">            <span class="keyword">if</span> [ <span class="string">"smart_device_map"</span> == <span class="variable">$table</span> ]||[ <span class="string">"android_device_session_temp"</span> == <span class="variable">$table</span> ]||[ <span class="string">"android_device_session"</span> == <span class="variable">$table</span> ]||[ <span class="string">"android_device"</span> == <span class="variable">$table</span> ]||[ <span class="string">"analysis"</span> == <span class="variable">$table</span> ]||[ <span class="string">"device_session"</span> == <span class="variable">$table</span> ]; <span class="keyword">then</span></span><br><span class="line">              <span class="built_in">echo</span> <span class="string">" "</span></span><br><span class="line">            <span class="keyword">else</span> </span><br><span class="line">                <span class="built_in">echo</span> <span class="variable">$table</span> <span class="variable">$snap</span></span><br><span class="line">                /usr/install/cassandra/bin/sstableloader -d 192.168.50.20,192.168.50.21,192.168.50.22,192.168.50.23,192.168.50.24 /home/admin/cassandra/forseti_fp/<span class="variable">$table</span></span><br><span class="line">            <span class="keyword">fi</span>        </span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：android_device_session表已经同步过了，所以不需要再次同步</p>
</blockquote>
<h3 id="增量备份（需要多次执行）">增量备份（需要多次执行）</h3><p>执行增量迁移: nohup sh increment.sh  &gt; increment0616.log 2&gt;&amp;1 &amp;<br>把<code>/home/admin/cassandra/forseti_fp/$table/backups/*</code> 拷贝到 <code>/home/admin/cassandra/forseti_fp/$table</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> /home/admin/cassandra/data/forseti_fp/*</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">test</span> -d <span class="variable">$file</span></span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        table=`basename <span class="variable">$file</span>`</span><br><span class="line">        <span class="keyword">if</span> [ -d <span class="string">"<span class="variable">$file</span>/backups"</span> ]; <span class="keyword">then</span></span><br><span class="line">            rm /home/admin/cassandra/forseti_fp/<span class="variable">$table</span>/*</span><br><span class="line">            <span class="built_in">cd</span> <span class="variable">$file</span>/backups</span><br><span class="line">            ls | xargs -t -I &#123;&#125; mv &#123;&#125; /home/admin/cassandra/forseti_fp/<span class="variable">$table</span>/</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> [ <span class="string">"smart_device_map"</span> == <span class="variable">$table</span> ]||[ <span class="string">"android_device_session_temp"</span> == <span class="variable">$table</span> ]||[ <span class="string">"android_device"</span> == <span class="variable">$table</span> ]||[ <span class="string">"analysis"</span> == <span class="variable">$table</span> ]||[ <span class="string">"device_session"</span> == <span class="variable">$table</span> ]; <span class="keyword">then</span></span><br><span class="line">              <span class="built_in">echo</span> <span class="string">" "</span></span><br><span class="line">            <span class="keyword">else</span> </span><br><span class="line">                <span class="built_in">echo</span> <span class="variable">$table</span></span><br><span class="line">                /usr/install/cassandra/bin/sstableloader -d 192.168.50.20,192.168.50.21,192.168.50.22,192.168.50.23,192.168.50.24 /home/admin/cassandra/forseti_fp/<span class="variable">$table</span></span><br><span class="line">            <span class="keyword">fi</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：要把android_device_session表加上，backups都必须同步</p>
</blockquote>
<p>vi increment_timer.sh</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ps -fe|grep BulkLoader |grep -v grep</span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">start=$(date +%s)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"可以开始处理。。。"</span></span><br><span class="line">sh increment.sh</span><br><span class="line">end=$(date +%s)</span><br><span class="line">timeT=$(( <span class="variable">$end</span> - <span class="variable">$start</span> ))</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"COST:<span class="variable">$timeT</span>, start:<span class="variable">$start</span>, end: <span class="variable">$end</span>"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"BulkLoader正在运行，请稍等"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>定时任务脚本：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">0 */2 * * * sh /home/admin/cassandra/increment_timer.sh</span><br><span class="line">tail -f /var/spool/mail/admin</span><br><span class="line">crontab -e</span><br></pre></td></tr></table></figure>
<p>228一个节点所有表的耗时(一次backups), 大概1G花费1min</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[admin@192-168-48-228 cassandra]$ cat nohup.out  | grep &quot;Total duration&quot;</span><br><span class="line">50M     android_device_index        Total duration (s):          : 26</span><br><span class="line">525G    android_device_session      Total duration (s):          : 25291(7h=420m)</span><br><span class="line">71M     android_device_time         Total duration (s):          : 30</span><br><span class="line">5.3G    api_invoke_result           Total duration (s):          : 561</span><br><span class="line">1.6G    device                      Total duration (s):          : 288</span><br><span class="line">3.9G    devicedbmap                 Total duration (s):          : 316</span><br><span class="line">66G     device_session_map          Total duration (s):          : 4563(76min)</span><br><span class="line">2.1G    ios_device_index            Total duration (s):          : 151</span><br><span class="line">4.5G    ios_device_info             Total duration (s):          : 342</span><br><span class="line">4.8G    ios_device_session          Total duration (s):          : 353</span><br><span class="line">373M    ip_device_id                Total duration (s):          : 53</span><br><span class="line">7.3G    page_info                   Total duration (s):          : 536</span><br><span class="line">3.3G    tcp_stack_ua                Total duration (s):          : 276</span><br><span class="line">9.6G    tcp_syn_data                Total duration (s):          : 686</span><br></pre></td></tr></table></figure>
<h3 id="机房迁移">机房迁移</h3><p>准备工作：</p>
<ol>
<li>老集群的snapshot和backups同步到新集群</li>
<li>？？</li>
</ol>
<h4 id="直接从当前集群同步到上海集群">直接从当前集群同步到上海集群</h4><p><strong>有节点挂掉</strong>  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[admin@192-168-48-228 ~]$ /usr/install/cassandra/bin/sstableloader -d 10.21.21.20 -t 50 /home/admin/cassandra/forseti_fp/device</span><br><span class="line">ERROR 11:11:56 Error creating pool to /10.21.21.22:9042</span><br><span class="line">com.datastax.driver.core.TransportException: [/10.21.21.22:9042] Cannot connect</span><br><span class="line">  at com.datastax.driver.core.Connection$1.operationComplete(Connection.java:156) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at com.datastax.driver.core.Connection$1.operationComplete(Connection.java:139) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:680) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:603) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:563) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at com.datastax.shaded.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:424) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:268) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:284) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at com.datastax.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at com.datastax.shaded.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]</span><br><span class="line">Caused by: java.net.ConnectException: 拒绝连接: /10.21.21.22:9042</span><br><span class="line">  at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.7.0_51]</span><br><span class="line">  at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739) ~[na:1.7.0_51]</span><br><span class="line">  at com.datastax.shaded.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224) ~[cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  at com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:281) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]</span><br><span class="line">  ... 6 common frames omitted</span><br><span class="line">Established connection to initial hosts</span><br><span class="line">Opening sstables and calculating sections to stream</span><br><span class="line">...Streaming relevant part of /home/admin/cassan</span><br></pre></td></tr></table></figure>
<p><strong>版本不一样,拒绝连接</strong>  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[admin@fp-cass048159 device]$ /usr/install/cassandra/bin/sstableloader -d 10.21.21.20 -t 50 /home/admin/cassandra/forseti_fp/$table</span><br><span class="line">Could not retrieve endpoint ranges:</span><br><span class="line">org.apache.thrift.transport.TTransportException: java.net.ConnectException: 拒绝连接</span><br><span class="line">java.lang.RuntimeException: Could not retrieve endpoint ranges:</span><br><span class="line">  at org.apache.cassandra.tools.BulkLoader$ExternalClient.init(BulkLoader.java:342)</span><br><span class="line">  at org.apache.cassandra.io.sstable.SSTableLoader.stream(SSTableLoader.java:156)</span><br><span class="line">  at org.apache.cassandra.tools.BulkLoader.main(BulkLoader.java:109)</span><br><span class="line">Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: 拒绝连接</span><br><span class="line">  at org.apache.thrift.transport.TSocket.open(TSocket.java:187)</span><br><span class="line">  at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)</span><br><span class="line">  at org.apache.cassandra.thrift.TFramedTransportFactory.openTransport(TFramedTransportFactory.java:41)</span><br><span class="line">  at org.apache.cassandra.tools.BulkLoader$ExternalClient.createThriftClient(BulkLoader.java:380)</span><br><span class="line">  at org.apache.cassandra.tools.BulkLoader$ExternalClient.init(BulkLoader.java:302)</span><br><span class="line">  ... 2 more</span><br><span class="line">Caused by: java.net.ConnectException: 拒绝连接</span><br><span class="line">  at java.net.PlainSocketImpl.socketConnect(Native Method)</span><br><span class="line">  at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)</span><br><span class="line">  at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)</span><br><span class="line">  at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)</span><br><span class="line">  at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)</span><br><span class="line">  at java.net.Socket.connect(Socket.java:579)</span><br><span class="line">  at org.apache.thrift.transport.TSocket.open(TSocket.java:182)</span><br><span class="line">  ... 6 more</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[admin@fp-cass048159 ~]$ /usr/install/cassandra/bin/cqlsh 10.21.21.20</span><br><span class="line">Connection error: (&apos;Unable to connect to any servers&apos;, &#123;&apos;10.21.21.20&apos;: </span><br><span class="line">ProtocolError(&quot;cql_version &apos;3.2.1&apos; is not supported by remote (w/ native protocol). Supported versions: [u&apos;3.3.1&apos;]&quot;,)&#125;)</span><br></pre></td></tr></table></figure>
<p><strong>sstableloader 100%后卡住</strong>  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[admin@192-168-48-228 ~]$ tail -c 500 nohup.out</span><br><span class="line">progress: [/10.21.21.23]0:60/60 100% [/10.21.21.21]0:65/65 100% [/10.21.21.20]0:63/63 100% [/10.21.21.19]0:60/60 100% </span><br><span class="line">[/10.21.21.26]0:60/60 100% [/10.21.21.25]0:63/63 100% [/10.21.21.24]0:64/64 100%</span><br><span class="line">progress: [/10.21.21.23]0:60/60 100% [/10.21.21.21]0:65/65 100% [/10.21.21.20]0:63/63 100% [/10.21.21.19]0:60/60 100% </span><br><span class="line">[/10.21.21.26]0:60/60 100% [/10.21.21.25]0:63/63 100% [/10.21.21.24]0:64/64 100% total: 100% 0  MB/s(avg: 2 MB/s)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> S0C    S1C     S0U     S1U      EC       EU        OC         OU       PC     PU         YGC    YGCT    FGC    FGCT     GCT</span><br><span class="line">11264.0 11264.0 3525.9  0.0   1032704.0 346823.5  342016.0    9527.1   21504.0 21335.9     24    0.466   0      0.000    0.466</span><br><span class="line">11264.0 11264.0 3525.9  0.0   1032704.0 346823.5  342016.0    9527.1   21504.0 21335.9     24    0.466   0      0.000    0.466</span><br><span class="line">11264.0 11264.0 3525.9  0.0   1032704.0 346823.5  342016.0    9527.1   21504.0 21335.9     24    0.466   0      0.000    0.466</span><br><span class="line">11264.0 11264.0 3525.9  0.0   1032704.0 346823.5  342016.0    9527.1   21504.0 21335.9     24    0.466   0      0.000    0.466</span><br></pre></td></tr></table></figure>
<p><strong>FP主要的表迁移：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">device</span><br><span class="line">android_device_index</span><br><span class="line">android_device_time</span><br><span class="line">ios_device_index</span><br><span class="line">ios_device_info</span><br></pre></td></tr></table></figure>
<p>查看数据量：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ cd /home/admin/cassandra/data/forseti_fp</span><br><span class="line">$ du -sh * | egrep &apos;android_device_index|android_device_time|ios_device_index|ios_device_info&apos;</span><br><span class="line">869M  android_device_index</span><br><span class="line">1023M android_device_time</span><br><span class="line">23G ios_device_index</span><br><span class="line">54G ios_device_info</span><br></pre></td></tr></table></figure>
<p>48.228: 还剩device和ios_device_info<br>227: 升级完，7-7 9<br>226: 升级完，7-8 2<br>159：升级完，7-8 6</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#####先测试一个表</span><br><span class="line">ll /home/admin/cassandra/data/forseti_fp/android_device_index/snapshots/$snapTime</span><br><span class="line">mkdir -p /home/admin/cassandra/forseti_fp/device</span><br><span class="line">cd /home/admin/cassandra/data/forseti_fp/device/snapshots/$snapTime</span><br><span class="line">ls | xargs -t -I &#123;&#125; mv &#123;&#125; /home/admin/cassandra/forseti_fp/device/</span><br><span class="line">/usr/install/cassandra/bin/sstableloader -d 10.21.21.20 -t 50 /home/admin/cassandra/forseti_fp/device</span><br><span class="line"></span><br><span class="line">####脚本循环方式 load.sh</span><br><span class="line">rm -rf /home/admin/cassandra/forseti_fp/</span><br><span class="line">/usr/install/cassandra/bin/nodetool snapshot forseti_fp &gt; snap.log</span><br><span class="line">snapTime=`cat snap.log | grep directory | awk &apos;&#123;print $3&#125;&apos;`</span><br><span class="line">nums=(&apos;device&apos; &apos;android_device_index&apos; &apos;android_device_time&apos; &apos;ios_device_index&apos; &apos;ios_device_info&apos;)</span><br><span class="line">for table in $&#123;nums[@]&#125;;</span><br><span class="line">do</span><br><span class="line">  mkdir -p /home/admin/cassandra/forseti_fp/$table</span><br><span class="line">  cd /home/admin/cassandra/data/forseti_fp/$table/snapshots/$snapTime</span><br><span class="line">  ls | xargs -t -I &#123;&#125; mv &#123;&#125; /home/admin/cassandra/forseti_fp/$table/</span><br><span class="line">  /usr/install/cassandra/bin/sstableloader -d 10.21.21.20 -t 100 /home/admin/cassandra/forseti_fp/$table</span><br><span class="line">done</span><br><span class="line">echo &quot;end.&quot;</span><br><span class="line"></span><br><span class="line">crontab -e</span><br><span class="line">00 6 8 7 * sh /home/admin/load.sh &gt; load.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure>
<p>多个节点做快照</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">nodetool status |grep RAC|awk &apos;&#123;print $2&#125;&apos; | while read ip; do echo $ip; nodetool -h $ip snapshot forseti_fp; done</span><br><span class="line">192.168.48.227</span><br><span class="line">Snapshot directory: 1467716730094</span><br><span class="line">192.168.48.226</span><br><span class="line">Snapshot directory: 1467716742257</span><br><span class="line">192.168.48.176</span><br><span class="line">Snapshot directory: 1467716753938</span><br><span class="line">192.168.48.161</span><br><span class="line">Requested creating snapshot(s) for [forseti_fp] with snapshot name [1467716770566]</span><br><span class="line">192.168.48.228</span><br><span class="line">Snapshot directory: 1467716780650</span><br><span class="line">192.168.48.160</span><br><span class="line">Requested creating snapshot(s) for [forseti_fp] with snapshot name [1467716792487]</span><br><span class="line">192.168.48.175</span><br><span class="line">Requested creating snapshot(s) for [forseti_fp] with snapshot name [1467716802910]</span><br><span class="line">192.168.48.159</span><br><span class="line">Requested creating snapshot(s) for [forseti_fp] with snapshot name [1467716815575]</span><br><span class="line"></span><br><span class="line">以159为例：</span><br><span class="line">[admin@fp-cass048159 ~]$ ll /home/admin/cassandra/data/forseti_fp/android_device_session/snapshots/</span><br><span class="line">总用量 4</span><br><span class="line">drwxr-xr-x. 2 admin admin 4096 7月   5 19:07 1467716815575</span><br><span class="line"></span><br><span class="line">declare -A map=([&quot;192.168.48.227&quot;]=&quot;1467716730094&quot; [&quot;192.168.48.226&quot;]=&quot;1467716742257&quot; </span><br><span class="line">[&quot;192.168.48.176&quot;]=&quot;1467716753938&quot; [&quot;192.168.48.161&quot;]=&quot;1467716770566&quot; </span><br><span class="line">[&quot;192.168.48.228&quot;]=&quot;1467716780650&quot; [&quot;192.168.48.160&quot;]=&quot;1467716792487&quot; </span><br><span class="line">[&quot;192.168.48.175&quot;]=&quot;1467716802910&quot; [&quot;192.168.48.159&quot;]=&quot;1467716815575&quot;)</span><br><span class="line">host=`ifconfig | grep &quot;192.168.4&quot; | awk &apos;/inet addr/&#123;sub(&quot;addr:&quot;,&quot;&quot;); print $2&#125;&apos;`</span><br><span class="line">snapshot=$&#123;map[&quot;$host&quot;]&#125;</span><br><span class="line">snapshotAbs=&quot;/home/admin/cassandra/data/forseti_fp/android_device_session/snapshots/$snapshot&quot;</span><br><span class="line"></span><br><span class="line">#rm -rf /home/admin/cassandra/forseti_fp/</span><br><span class="line">#mkdir -p /home/admin/cassandra/forseti_fp/</span><br><span class="line">table=&quot;device&quot;</span><br><span class="line">mkdir -p /home/admin/cassandra/forseti_fp/$table</span><br><span class="line">cd $snapshotAbs</span><br><span class="line">ls | xargs -t -I &#123;&#125; mv &#123;&#125; /home/admin/cassandra/forseti_fp/$table/</span><br><span class="line">/usr/install/cassandra/bin/sstableloader -t 50 -d 10.21.21.20 /home/admin/cassandra/forseti_fp/$table</span><br></pre></td></tr></table></figure>
<h4 id="新集群安装">新集群安装</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">#rm -rf apache-cassandra-2.2.6 &amp; rm apache-cassandra-2.2.6-bin.tar.gz &amp; rm -rf test</span><br><span class="line">wget http://192.168.47.211:8000/apache-cassandra-2.2.6-bin.tar.gz</span><br><span class="line">tar zxf apache-cassandra-2.2.6-bin.tar.gz</span><br><span class="line"></span><br><span class="line">#cluster=sh_velocity</span><br><span class="line">#seeds=10.21.21.11,10.21.21.12,10.21.21.13</span><br><span class="line"></span><br><span class="line">#cluster=sh_fp</span><br><span class="line">#seeds=10.21.21.19,10.21.21.20,10.21.21.21</span><br><span class="line"></span><br><span class="line">cluster=sh_galaxy</span><br><span class="line">seeds=10.21.21.131,10.21.21.132</span><br><span class="line"></span><br><span class="line">mkdir data</span><br><span class="line">host=`ifconfig | grep &quot;10.21.21.&quot; | awk &apos;/inet addr/&#123;sub(&quot;addr:&quot;,&quot;&quot;); print $2&#125;&apos;`</span><br><span class="line">sed -i -e &quot;s/localhost/$host/g&quot; apache-cassandra-2.2.6/conf/cassandra.yaml</span><br><span class="line">sed -i -e &quot;s#localhost#$host#g&quot; apache-cassandra-2.2.6/conf/cassandra-env.sh</span><br><span class="line">sed -i -e &quot;s/127.0.0.1/$seeds/g&quot; apache-cassandra-2.2.6/conf/cassandra.yaml</span><br><span class="line">sed -i -e &quot;s/Test Cluster/$cluster/g&quot; apache-cassandra-2.2.6/conf/cassandra.yaml</span><br><span class="line">ln -s apache-cassandra-2.2.6 cassandra</span><br><span class="line"></span><br><span class="line">cassandra/bin/cassandra</span><br><span class="line">cassandra/bin/nodetool status</span><br><span class="line">cassandra/bin/nodetool -h 10.21.21.10 status</span><br><span class="line">cassandra/bin/nodetool -h 10.21.21.19 status</span><br><span class="line">cassandra/bin/nodetool -h 10.21.21.131 status</span><br></pre></td></tr></table></figure>
<h4 id="1-_表结构">1. 表结构</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">/usr/install/cassandra/bin/cqlsh -e &apos;desc keyspace forseti&apos; 192.168.47.202 &gt; forseti_api.cql</span><br><span class="line">/usr/install/cassandra/bin/cqlsh -e &apos;desc keyspace forseti&apos; 192.168.48.162 &gt; forseti.cql</span><br><span class="line">/usr/install/cassandra/bin/cqlsh -e &apos;desc keyspace forseti_fp&apos; 192.168.48.159 &gt; forseti_fp.cql</span><br><span class="line">/usr/install/cassandra/bin/cqlsh -e &apos;desc keyspace realtime&apos; 192.168.49.56 &gt; forseti_galaxy.cql</span><br><span class="line"></span><br><span class="line">wget http://192.168.48.162:8000/forseti.cql</span><br><span class="line">wget http://192.168.48.162:8000/forseti_fp.cql</span><br><span class="line">wget http://192.168.48.162:8000/forseti_galaxy.cql</span><br><span class="line">cassandra/bin/cqlsh 10.21.21.11 -f forseti.cql</span><br><span class="line">cassandra/bin/cqlsh 10.21.21.19 -f forseti_fp.cql</span><br><span class="line">cassandra/bin/cqlsh 10.21.21.131 -f forseti_galaxy.cql</span><br></pre></td></tr></table></figure>
<h4 id="2-_数据迁移">2. 数据迁移</h4><h4 id="3-_增量数据迁移">3. 增量数据迁移</h4><h4 id="4-_数据验证">4. 数据验证</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/usr/install/hadoop/bin/hadoop fs -cat /user/tongdun/velocity/raw/2016-6-9/part-00000 | head</span><br><span class="line"> 115.55.206|sdo|sdo_client|ip3|1465401548233|1465401548238838F30790E445243217|&#123;&quot;state&quot;:&quot;0&quot;,&quot;ipAddressProvince&quot;:&quot;河南省&quot;,&quot;ipAddressCity&quot;:&quot;鹤壁市&quot;,&quot;ipAddress&quot;:&quot;115.55.206.177&quot;,&quot;ext_is_gplus_login&quot;:&quot;0&quot;,&quot;ext_is_bingding_mobile&quot;:&quot;0&quot;,&quot;eventType&quot;:&quot;Login&quot;,&quot;eventOccurTime&quot;:&quot;1465401548233&quot;,&quot;deviceId&quot;:&quot;00-0C-29-BC-62-D1&quot;,&quot;accountLogin&quot;:&quot;166f751ebf90b9fbb38977d75b1265f6&quot;,&quot;eventId&quot;:&quot;login_client&quot;,&quot;partnerCode&quot;:&quot;sdo&quot;,&quot;ip3&quot;:&quot;115.55.206&quot;,&quot;location&quot;:&quot;鹤壁市&quot;,&quot;status&quot;:&quot;Review&quot;&#125;</span><br><span class="line"></span><br><span class="line">select * from velocity_app where attribute=&apos;115.55.206&apos; and type=&apos;ip3&apos; and partner_code=&apos;sdo&apos; and app_name=&apos;sdo_client&apos; and sequence_id &gt; &apos;1465401548238838F30790E445243210&apos; and sequence_id &lt; &apos;1465401548238838F30790E445243220&apos;;</span><br><span class="line"></span><br><span class="line"> 115.55.206 |          sdo | sdo_client |  ip3 | 1465401548238838F30790E445243217 | &#123;&quot;state&quot;:&quot;0&quot;,&quot;ipAddressProvince&quot;:&quot;河南省&quot;,&quot;ipAddressCity&quot;:&quot;鹤壁市&quot;,&quot;ipAddress&quot;:&quot;115.55.206.177&quot;,&quot;ext_is_gplus_login&quot;:&quot;0&quot;,&quot;ext_is_bingding_mobile&quot;:&quot;0&quot;,&quot;eventType&quot;:&quot;Login&quot;,&quot;eventOccurTime&quot;:&quot;1465401548233&quot;,&quot;deviceId&quot;:&quot;00-0C-29-BC-62-D1&quot;,&quot;accountLogin&quot;:&quot;166f751ebf90b9fbb38977d75b1265f6&quot;,&quot;eventId&quot;:&quot;login_client&quot;,&quot;partnerCode&quot;:&quot;sdo&quot;,&quot;ip3&quot;:&quot;115.55.206&quot;,&quot;location&quot;:&quot;鹤壁市&quot;,&quot;status&quot;:&quot;Review&quot;&#125; | 1465401548233</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="nodetool工具">nodetool工具</h2><h3 id="集群状态:_nodetool_decribecluster">集群状态: nodetool decribecluster</h3><p>启动OpsCenter后, 在8888上新建Cluster时报异常:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">2015-10-31 13:46:07+0800 [forseti_cluster]  WARN: Node 192.168.47.206 is reporting a schema disagreement: </span><br><span class="line">&#123;UUID(&apos;bc083db4-b544-38d1-a37c-be3e78db1df1&apos;): [&apos;192.168.47.229&apos;], </span><br><span class="line">UUID(&apos;67462d4d-a9c9-38a1-afd8-1a3917232b8a&apos;): [&apos;192.168.47.203&apos;, &apos;192.168.47.228&apos;, &apos;192.168.47.227&apos;, &apos;192.168.47.202&apos;, &apos;192.168.47.225&apos;, &apos;192.168.47.204&apos;, &apos;192.168.47.205&apos;, &apos;192.168.47.206&apos;, &apos;192.168.47.221&apos;, &apos;192.168.47.222&apos;, &apos;192.168.47.224&apos;]&#125;</span><br><span class="line">2015-10-31 13:46:07+0800 []  WARN: [control connection] No schema built on connect; retrying without wait for schema agreement</span><br><span class="line">2015-10-31 13:46:13+0800 []  WARN: Host 192.168.47.229 has been marked down</span><br><span class="line">2015-10-31 13:46:14+0800 []  WARN: Failed to create connection pool for new host 192.168.47.229: errors=Timed out creating connection, last_host=None</span><br><span class="line">2015-10-31 13:47:07+0800 []  INFO: Host 192.168.47.229 may be up; will prepare queries and open connection pool</span><br></pre></td></tr></table></figure>
<p>按照这里的方式, 如果状态为UNREACHABLE,则重启后再观察.<br><a href="http://docs.datastax.com/en/cassandra/2.1/cassandra/troubleshooting/trblshootSchemaDisagree.html" target="_blank" rel="noopener">http://docs.datastax.com/en/cassandra/2.1/cassandra/troubleshooting/trblshootSchemaDisagree.html</a>  </p>
<p>果然有一个状态是UNREACHABLE的:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047202 ~]$ nodetool describecluster</span><br><span class="line">Cluster Information:</span><br><span class="line">    Name: forseti_cluster</span><br><span class="line">    Snitch: org.apache.cassandra.locator.DynamicEndpointSnitch</span><br><span class="line">    Partitioner: org.apache.cassandra.dht.Murmur3Partitioner</span><br><span class="line">    Schema versions:</span><br><span class="line">        3e4c6580-3d3c-327b-986c-63086e93e94f: [192.168.47.206, 192.168.47.222, 192.168.47.221, 192.168.47.204, 192.168.47.205, 192.168.47.202, 192.168.47.203, 192.168.47.228, 192.168.47.224, 192.168.47.225, 192.168.47.227]</span><br><span class="line">        UNREACHABLE: [192.168.47.229]</span><br></pre></td></tr></table></figure>
<p>发现229当掉, 重启后, 版本不一致:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047202 ~]$ nodetool describecluster</span><br><span class="line">Cluster Information:</span><br><span class="line">    Name: forseti_cluster</span><br><span class="line">    Snitch: org.apache.cassandra.locator.DynamicEndpointSnitch</span><br><span class="line">    Partitioner: org.apache.cassandra.dht.Murmur3Partitioner</span><br><span class="line">    Schema versions:</span><br><span class="line">        3e4c6580-3d3c-327b-986c-63086e93e94f: [192.168.47.206, 192.168.47.222, 192.168.47.221, 192.168.47.204, 192.168.47.205, 192.168.47.202, 192.168.47.203, 192.168.47.228, 192.168.47.224, 192.168.47.225, 192.168.47.227]</span><br><span class="line"></span><br><span class="line">        d2601534-c7ff-394d-a656-33d9da3dc574: [192.168.47.229]</span><br></pre></td></tr></table></figure>
<p>但是在229上查看到所有节点都不可达:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@192-168-47-229 ~]$ nodetool describecluster</span><br><span class="line">Cluster Information:</span><br><span class="line">    Name: forseti_cluster</span><br><span class="line">    Snitch: org.apache.cassandra.locator.DynamicEndpointSnitch</span><br><span class="line">    Partitioner: org.apache.cassandra.dht.Murmur3Partitioner</span><br><span class="line">    Schema versions:</span><br><span class="line">        UNREACHABLE: [192.168.47.206, 192.168.47.222, 192.168.47.221, 192.168.47.204, 192.168.47.205, 192.168.47.202, 192.168.47.203, 192.168.47.228, 192.168.47.229, 192.168.47.224, 192.168.47.225, 192.168.47.227]</span><br></pre></td></tr></table></figure>
<p>229过了段时间因为GC, 再次重启, 再次查看, 版本一样了:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@192-168-47-229 ~]$ nodetool describecluster</span><br><span class="line">Cluster Information:</span><br><span class="line">  Name: forseti_cluster</span><br><span class="line">  Snitch: org.apache.cassandra.locator.DynamicEndpointSnitch</span><br><span class="line">  Partitioner: org.apache.cassandra.dht.Murmur3Partitioner</span><br><span class="line">  Schema versions:</span><br><span class="line">    977ca50d-70ab-3f45-a1e6-ca18560b0c29: [192.168.47.206, 192.168.47.222, 192.168.47.221, 192.168.47.204, 192.168.47.205, 192.168.47.202, 192.168.47.203, 192.168.47.228, 192.168.47.229, 192.168.47.224, 192.168.47.225, 192.168.47.227]</span><br></pre></td></tr></table></figure>
<h3 id="删除节点:_removenode">删除节点: removenode</h3><p><a href="http://zhaoyanblog.com/archives/533.html" target="_blank" rel="noopener">http://zhaoyanblog.com/archives/533.html</a></p>
<p><code>A</code>.对正在运行Cassandra进程的节点下线,或者在其他节点-h指定要下线的目标节点. 运行命令的节点会有NodeCmd进程.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/install/apache-cassandra-2.0.16/bin/nodetool decommission</span><br><span class="line">/usr/install/apache-cassandra-2.0.16/bin/nodetool decommission -h 192.168.47.226</span><br></pre></td></tr></table></figure>
<p><code>B</code>.如果节点已经下线,比如进程被杀死, 则在正常的节点上删除节点:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/install/apache-cassandra-2.0.16/bin/nodetool status 获取宕机节点的host-id</span><br><span class="line">/usr/install/apache-cassandra-2.0.16/bin/nodetool removenode  2591cec9-42f9-4f60-a622-00d463910994</span><br></pre></td></tr></table></figure>
<p><code>C</code>.进程挂住的解决办法:<br>1).线上采用decommission后, 发现执行了很久都没有完成. 后来发现是streamming的一个bug:<br>nodetool removenode hangs: <a href="https://issues.apache.org/jira/browse/CASSANDRA-6542" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/CASSANDRA-6542</a>,<br><a href="http://stackoverflow.com/questions/25943261/nodetool-removenode-stuck-during-removal" target="_blank" rel="noopener">http://stackoverflow.com/questions/25943261/nodetool-removenode-stuck-during-removal</a><br>Streams hang in repair: <a href="https://issues.apache.org/jira/browse/CASSANDRA-8472" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/CASSANDRA-8472</a></p>
<blockquote>
<p>Streaming hanging is a familiar trouble in my cluster (2.0/2.1). In my experience,<br>the node that being restarted recently won’t hang the streaming.<br>So each time when I want to add or remove a node, I will restart all nodes one by one.<br>这种方式在线上是不可行的, 需要重启线上的每个节点. 于是尝试使用force直接中断.  </p>
</blockquote>
<p>2).杀掉226的Cassandra进程, 在202上使用B方式removenode删除226. 不过removenode也存在hang的情况.   </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047202 ~]$ nodetool removenode status</span><br><span class="line">RemovalStatus: Removing token (-9184682133698409841). Waiting for replication confirmation from [/192.168.47.206,/192.168.47.222,/192.168.47.221,/192.168.47.204,/192.168.47.205,/192.168.47.202,/192.168.47.224,/192.168.47.225].</span><br></pre></td></tr></table></figure>
<p>3).由于nodetool命令都是调用JMX方法,所以尽管kill掉进程,命令对应的进程实际是还存在的.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047202 ~]$ jps</span><br><span class="line">8596 NodeCmd</span><br><span class="line">[qihuang.zheng@cass047202 ~]$ kill -9 8596</span><br><span class="line">[qihuang.zheng@cass047202 ~]$ nodetool removenode status</span><br><span class="line">RemovalStatus: Removing token (-9184682133698409841). Waiting for replication confirmation from [/192.168.47.206,/192.168.47.222,/192.168.47.221,/192.168.47.204,/192.168.47.205,/192.168.47.202,/192.168.47.224,/192.168.47.225].</span><br></pre></td></tr></table></figure>
<p>4).删除操作正在进行,不能重复执行removenode命令,不过提示信息给了我们另一种解决方案.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047202 ~]$ /usr/install/cassandra/bin/nodetool status</span><br><span class="line">UN  192.168.47.202  612.13 GB  256     7.4%   abaa0cbc-09d3-4990-8698-ff4d2f2bb4f7  RAC1</span><br><span class="line">DL  192.168.47.226  406.34 GB  256     7.6%   2591cec9-42f9-4f60-a622-00d463910994  RAC1</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@cass047202 ~]$ nodetool removenode 2591cec9-42f9-4f60-a622-00d463910994</span><br><span class="line">Exception in thread &quot;main&quot; java.lang.UnsupportedOperationException: This node is already processing a removal. Wait for it to complete, or use &apos;removenode force&apos; if this has failed.</span><br><span class="line">  at org.apache.cassandra.service.StorageService.removeNode(StorageService.java:3342)</span><br><span class="line">  ...</span><br><span class="line">  at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:819)</span><br><span class="line">  at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:801)</span><br></pre></td></tr></table></figure>
<p>5).如果removenode失败, 则强制删除, 使用<code>nodetool removenode force</code>命令,不需要跟上host-id.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047202 ~]$ nodetool removenode force 2591cec9-42f9-4f60-a622-00d463910994</span><br><span class="line">Missing an argument for removenode (either status, force, or an ID)</span><br><span class="line">usage: java org.apache.cassandra.tools.NodeCmd --host &lt;arg&gt; &lt;command&gt;</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@cass047202 ~]$ nodetool removenode force</span><br><span class="line">RemovalStatus: Removing token (-9184682133698409841). Waiting for replication confirmation from [/192.168.47.206,/192.168.47.222,/192.168.47.221,/192.168.47.204,/192.168.47.205,/192.168.47.202,/192.168.47.224,/192.168.47.225].</span><br></pre></td></tr></table></figure>
<p>6).成功删除后, 下线的226节点不会出现在状态列表中, 并且集群的Owns也发生了变化. gossipinfo可以查看状态为removed.   </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047202 ~]$ nodetool removenode status</span><br><span class="line">RemovalStatus: No token removals in process.</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@cass047202 ~]$ /usr/install/cassandra/bin/nodetool status</span><br><span class="line">UN  192.168.47.202  612.13 GB  256     8.1%   abaa0cbc-09d3-4990-8698-ff4d2f2bb4f7  RAC1</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@cass047204 ~]$ nodetool gossipinfo</span><br><span class="line">/192.168.47.226</span><br><span class="line">  STATUS:removed,2591cec9-42f9-4f60-a622-00d463910994,1446339305944</span><br><span class="line">  REMOVAL_COORDINATOR:REMOVER,abaa0cbc-09d3-4990-8698-ff4d2f2bb4f7</span><br></pre></td></tr></table></figure>
<p><code>D</code>.Active Streams:  </p>
<p>下图是对225进行decommission,225的数据通过streams转移到其他节点:  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20151030101713671" alt="streams"></p>
<h3 id="替换节点:_replace_address">替换节点: replace_address</h3><p><a href="http://zhaoyanblog.com/archives/591.html" target="_blank" rel="noopener">http://zhaoyanblog.com/archives/591.html</a><br><a href="http://docs.datastax.com/en/cassandra/2.0/cassandra/operations/ops_replace_node_t.html" target="_blank" rel="noopener">http://docs.datastax.com/en/cassandra/2.0/cassandra/operations/ops_replace_node_t.html</a></p>
<blockquote>
<p>CAUTION:<br>1.Wait at least 72 hours to ensure that old node information is removed from gossip.<br>If removed from the property file too soon, problems may result.<br>2.auto_bootstrap不能设置为false:<br>java.lang.RuntimeException: Trying to replace_address with auto_bootstrap disabled will not work, check your configuration</p>
</blockquote>
<p>要被替换的节点状态为DN, 新启动的节点启动时加上-Dcassandra.replace_address选项:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo -u admin /usr/install/cassandra/bin/cassandra -Dcassandra.replace_address=192.168.47.229</span><br><span class="line"></span><br><span class="line"> WARN 13:49:37,423 Token -3920394820366823756 changing ownership from /192.168.47.229 to /192.168.48.160</span><br><span class="line"> INFO 13:50:40,122 Node /192.168.47.229 is now part of the cluster</span><br><span class="line"> WARN 13:50:40,127 Not updating token metadata for /192.168.47.229 because I am replacing it</span><br><span class="line"> INFO 13:50:40,127 Nodes /192.168.47.229 and /192.168.48.160 have the same token -1001533036333769848.  Ignoring /192.168.47.229 </span><br><span class="line"> INFO 13:51:10,272 FatClient /192.168.47.229 has been silent for 30000ms, removing from gossip</span><br></pre></td></tr></table></figure>
<p>查看节点的状态:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@fp-cass048160 ~]$ nodetool status</span><br><span class="line">--  Address         Load       Tokens  Owns   Host ID                               Rack</span><br><span class="line">UN  192.168.48.161  460.9 GB   256     20.1%  54b3a7e0-f778-4087-98c3-ac84e56f77e6  RAC1</span><br><span class="line">UN  192.168.48.160  6.02 MB    256     21.2%  18a87c56-dcba-4614-adba-804aa7761a06  RAC1</span><br><span class="line">UN  192.168.47.228  5.4 TB     256     19.2%  f3d26148-d2da-479c-ae9e-ae41aced1be9  RAC1</span><br><span class="line">UN  192.168.48.159  483.48 GB  256     19.5%  df9a693b-efc1-41bc-9a42-cf868ea75e65  RAC1</span><br><span class="line">UN  192.168.47.227  686.97 GB  256     20.0%  02575631-6ccb-4803-81fd-5bf7a978726d  RAC1</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@192-168-47-227 ~]$ nodetool status</span><br><span class="line">--  Address         Load       Tokens  Owns   Host ID                               Rack</span><br><span class="line">UN  192.168.48.161  460.78 GB  256     20.1%  54b3a7e0-f778-4087-98c3-ac84e56f77e6  RAC1</span><br><span class="line">UN  192.168.47.228  5.4 TB     256     19.2%  f3d26148-d2da-479c-ae9e-ae41aced1be9  RAC1</span><br><span class="line">DN  192.168.47.229  937.05 GB  256     21.2%  18a87c56-dcba-4614-adba-804aa7761a06  RAC1</span><br><span class="line">UN  192.168.48.159  483.41 GB  256     19.5%  df9a693b-efc1-41bc-9a42-cf868ea75e65  RAC1</span><br><span class="line">UN  192.168.47.227  686.93 GB  256     20.0%  02575631-6ccb-4803-81fd-5bf7a978726d  RAC1</span><br></pre></td></tr></table></figure>
<blockquote>
<p>1.上面发现一个奇怪的现象就是229和160的HostID都是一样的, 所以日志中会有<code>have the same token ignoring</code><br>2.227并不认识160, 而是认为229状态为DN<br>3.160上能看到其他节点, 但是看不到229.  </p>
</blockquote>
<p>过了有一周, 再次查看发现还是上面的状况, 而且160的日志还是经常打印Ignoring…</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@fp-cass048160 ~]$ nodetool status</span><br><span class="line">--  Address         Load       Tokens  Owns   Host ID                               Rack</span><br><span class="line">UN  192.168.48.161  972.25 GB  256     20.1%  54b3a7e0-f778-4087-98c3-ac84e56f77e6  RAC1</span><br><span class="line">UN  192.168.48.160  250.64 GB  256     21.2%  18a87c56-dcba-4614-adba-804aa7761a06  RAC1</span><br><span class="line">UN  192.168.47.228  5.89 TB    256     19.2%  f3d26148-d2da-479c-ae9e-ae41aced1be9  RAC1</span><br><span class="line">UN  192.168.48.159  1 TB       256     19.5%  df9a693b-efc1-41bc-9a42-cf868ea75e65  RAC1</span><br><span class="line">UN  192.168.47.227  1.15 TB    256     20.0%  02575631-6ccb-4803-81fd-5bf7a978726d  RAC1</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@192-168-47-227 ~]$ nodetool status</span><br><span class="line">--  Address         Load       Tokens  Owns   Host ID                               Rack</span><br><span class="line">UN  192.168.48.161  972.16 GB  256     20.1%  54b3a7e0-f778-4087-98c3-ac84e56f77e6  RAC1</span><br><span class="line">UN  192.168.47.228  5.89 TB    256     19.2%  f3d26148-d2da-479c-ae9e-ae41aced1be9  RAC1</span><br><span class="line">DN  192.168.47.229  937.05 GB  256     21.2%  18a87c56-dcba-4614-adba-804aa7761a06  RAC1</span><br><span class="line">UN  192.168.48.159  1 TB       256     19.5%  df9a693b-efc1-41bc-9a42-cf868ea75e65  RAC1</span><br><span class="line">UN  192.168.47.227  1.15 TB    256     20.0%  02575631-6ccb-4803-81fd-5bf7a978726d  RAC1</span><br></pre></td></tr></table></figure>
<p>索性把160停掉重启(注意要加上auto_bootstrap:false), 现在227上能观察到160了. 但是160上还是看不到229.<br>不过更加奇怪的是229的HostID变成了null(因为出现160就不能同时再出现229了).这样子没办法removenode了.<br>其实也不能removenode了, 因为229和160的HostID之前是一样的!如果根据hostId删除,会把160也都删除掉了.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@192-168-47-227 ~]$ nodetool status</span><br><span class="line">--  Address         Load       Tokens  Owns   Host ID                               Rack</span><br><span class="line">UN  192.168.48.161  973.32 GB  256     17.4%  54b3a7e0-f778-4087-98c3-ac84e56f77e6  RAC1</span><br><span class="line">UN  192.168.48.160  250.93 GB  256     15.4%  18a87c56-dcba-4614-adba-804aa7761a06  RAC1</span><br><span class="line">UN  192.168.47.228  5.89 TB    256     16.5%  f3d26148-d2da-479c-ae9e-ae41aced1be9  RAC1</span><br><span class="line">DN  192.168.47.229  937.05 GB  256     17.8%  null                                  RAC1</span><br><span class="line">UN  192.168.48.159  1 TB       256     16.4%  df9a693b-efc1-41bc-9a42-cf868ea75e65  RAC1</span><br><span class="line">UN  192.168.47.227  1.15 TB    256     16.5%  02575631-6ccb-4803-81fd-5bf7a978726d  RAC1</span><br></pre></td></tr></table></figure>
<p>不能根据hostId来removenode 229, 那怎么删除229节点?  </p>
<p>下面采用JMX的方式也不行: <a href="https://gist.github.com/justenwalker/8338334" target="_blank" rel="noopener">https://gist.github.com/justenwalker/8338334</a>  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@192-168-47-227 ~]$ java -jar ./jmxterm.jar</span><br><span class="line">Welcome to JMX terminal. Type &quot;help&quot; for available commands.</span><br><span class="line">$&gt;open localhost:7199</span><br><span class="line">#Connection to localhost:7199 is opened</span><br><span class="line">$&gt;bean org.apache.cassandra.net:type=Gossiper</span><br><span class="line">#bean is set to org.apache.cassandra.net:type=Gossiper</span><br><span class="line">$&gt;run unsafeAssassinateEndpoint 192.168.47.229</span><br><span class="line">#calling operation unsafeAssassinateEndpoint of mbean org.apache.cassandra.net:type=Gossiper</span><br><span class="line">#RuntimeMBeanException: java.lang.NullPointerException</span><br></pre></td></tr></table></figure>
<p><a href="https://gist.github.com/nstielau/3373649" target="_blank" rel="noopener">https://gist.github.com/nstielau/3373649</a>  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">java -jar jmxsh-R*.jar -h 192.168.47.227 -p 7199</span><br><span class="line"></span><br><span class="line">% [Hit Enter to go into Browse Mode]</span><br><span class="line">Select a domain: [Enter number for org.apache.cassandra.net]</span><br><span class="line">Select an mbean: [Enter number for org.apache.cassandra.net:type=Gossiper]</span><br><span class="line">Select an attribute or operation: [Enter number for unsafeAssassinateEndpoint(String  p1)]</span><br><span class="line">p1 (String): 192.168.47.229</span><br><span class="line"></span><br><span class="line">It may also be possible to run it directly (untested):</span><br><span class="line">% jmx_invoke -m org.apache.cassandra.net:type=Gossiper unsafeAssassinateEndpoint &lt;STALE-IP-ADDRESS&gt;</span><br></pre></td></tr></table></figure>
<p>但最后还是报错NPE:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">%</span><br><span class="line">Entering browse mode.</span><br><span class="line">====================================================</span><br><span class="line"> Available Domains:</span><br><span class="line">       1. org.apache.cassandra.internal</span><br><span class="line">       2. org.apache.cassandra.metrics</span><br><span class="line">       6. org.apache.cassandra.request</span><br><span class="line">       7. org.apache.cassandra.net      ⬅️</span><br><span class="line">      10. org.apache.cassandra.db</span><br><span class="line">  SERVER: service:jmx:rmi:///jndi/rmi://192.168.47.227:7199/jmxrmi</span><br><span class="line"></span><br><span class="line">Exception caught: java.lang.NullPointerException</span><br></pre></td></tr></table></figure>
<p>查看每个节点自己的peers, 发现229和160的host_id一样:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@192-168-47-227 ~]$ cqlsh -e &quot;select peer, host_id from system.peers;&quot; 192.168.47.227</span><br><span class="line"> peer           | host_id</span><br><span class="line">----------------+--------------------------------------</span><br><span class="line"> 192.168.47.228 | f3d26148-d2da-479c-ae9e-ae41aced1be9</span><br><span class="line"> 192.168.47.229 | 18a87c56-dcba-4614-adba-804aa7761a06</span><br><span class="line"> 192.168.48.160 | 18a87c56-dcba-4614-adba-804aa7761a06</span><br><span class="line"> 192.168.48.161 | 54b3a7e0-f778-4087-98c3-ac84e56f77e6</span><br><span class="line"> 192.168.48.159 | df9a693b-efc1-41bc-9a42-cf868ea75e65</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@192-168-47-227 ~]$ cqlsh -e &quot;select peer, host_id from system.peers;&quot; 192.168.48.159</span><br><span class="line"></span><br><span class="line"> peer           | host_id</span><br><span class="line">----------------+--------------------------------------</span><br><span class="line"> 192.168.47.228 | f3d26148-d2da-479c-ae9e-ae41aced1be9</span><br><span class="line"> 192.168.47.227 | 02575631-6ccb-4803-81fd-5bf7a978726d</span><br><span class="line"> 192.168.47.229 | 18a87c56-dcba-4614-adba-804aa7761a06</span><br><span class="line"> 192.168.48.160 | 18a87c56-dcba-4614-adba-804aa7761a06</span><br><span class="line"> 192.168.48.161 | 54b3a7e0-f778-4087-98c3-ac84e56f77e6</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@192-168-47-227 ~]$ nodetool status -h 192.168.48.159</span><br><span class="line">--  Address         Load       Tokens  Owns   Host ID                               Rack</span><br><span class="line">UN  192.168.48.161  1.15 TB    256     17.4%  54b3a7e0-f778-4087-98c3-ac84e56f77e6  RAC1</span><br><span class="line">UN  192.168.48.160  461.6 GB   256     15.4%  18a87c56-dcba-4614-adba-804aa7761a06  RAC1</span><br><span class="line">UN  192.168.47.228  6.09 TB    256     16.5%  f3d26148-d2da-479c-ae9e-ae41aced1be9  RAC1</span><br><span class="line">DN  192.168.47.229  937.05 GB  256     17.8%  null                                  RAC1</span><br><span class="line">UN  192.168.48.159  1.2 TB     256     16.4%  df9a693b-efc1-41bc-9a42-cf868ea75e65  RAC1</span><br><span class="line">UN  192.168.47.227  1.34 TB    256     16.5%  02575631-6ccb-4803-81fd-5bf7a978726d  RAC1</span><br></pre></td></tr></table></figure>
<p>因为peers表的主键是peer, 所以可以根据peer删除一条记录:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cqlsh -e &quot;delete from system.peers where peer=&apos;192.168.47.229&apos;;&quot; 192.168.47.227</span><br><span class="line">cqlsh -e &quot;delete from system.peers where peer=&apos;192.168.47.229&apos;;&quot; 192.168.47.228</span><br><span class="line">cqlsh -e &quot;delete from system.peers where peer=&apos;192.168.47.229&apos;;&quot; 192.168.48.159</span><br><span class="line">cqlsh -e &quot;delete from system.peers where peer=&apos;192.168.47.229&apos;;&quot; 192.168.48.161</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@192-168-47-227 ~]$ cqlsh -e &quot;select peer, host_id from system.peers;&quot; 192.168.48.159</span><br><span class="line"> peer           | host_id</span><br><span class="line">----------------+--------------------------------------</span><br><span class="line"> 192.168.47.228 | f3d26148-d2da-479c-ae9e-ae41aced1be9</span><br><span class="line"> 192.168.47.227 | 02575631-6ccb-4803-81fd-5bf7a978726d</span><br><span class="line"> 192.168.48.160 | 18a87c56-dcba-4614-adba-804aa7761a06</span><br><span class="line"> 192.168.48.161 | 54b3a7e0-f778-4087-98c3-ac84e56f77e6</span><br><span class="line"></span><br><span class="line">nodetool status -h 192.168.48.159</span><br><span class="line">虽然peers中已经把229移除了, 但是staus还是能看到229为null</span><br><span class="line">UN  192.168.48.160  467.14 GB  256     15.4%  18a87c56-dcba-4614-adba-804aa7761a06  RAC1</span><br><span class="line">DN  192.168.47.229  937.05 GB  256     17.8%  null                                  RAC1</span><br></pre></td></tr></table></figure>
<p><a href="http://stackoverflow.com/questions/20549284/cassandra-how-to-remove-a-dead-node" target="_blank" rel="noopener">http://stackoverflow.com/questions/20549284/cassandra-how-to-remove-a-dead-node</a></p>
<p>另一种方式: 重启229, 这时候会分配一个新的HostID, 然后停掉, 再用removenode移除229.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@192-168-47-227 ~]$ nodetool status</span><br><span class="line">--  Address         Load       Tokens  Owns   Host ID                               Rack</span><br><span class="line">UN  192.168.48.161  1.16 TB    256     17.1%  54b3a7e0-f778-4087-98c3-ac84e56f77e6  RAC1</span><br><span class="line">UN  192.168.48.160  473.62 GB  256     16.1%  18a87c56-dcba-4614-adba-804aa7761a06  RAC1</span><br><span class="line">UN  192.168.47.228  6.1 TB     256     16.8%  f3d26148-d2da-479c-ae9e-ae41aced1be9  RAC1</span><br><span class="line">UN  192.168.47.229  44.07 KB   256     16.7%  41211503-27cd-47b0-b7c0-e5a7a4074d34  RAC1    ⬅️</span><br><span class="line">UN  192.168.48.159  1.22 TB    256     17.8%  df9a693b-efc1-41bc-9a42-cf868ea75e65  RAC1</span><br><span class="line">UN  192.168.47.227  1.35 TB    256     15.4%  02575631-6ccb-4803-81fd-5bf7a978726d  RAC1</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@192-168-47-227 ~]$ nodetool removenode status</span><br><span class="line">RemovalStatus: Removing token (-9189073978895940412). Waiting for replication confirmation from [/192.168.48.161,/192.168.48.160,/192.168.47.228,/192.168.48.159,/192.168.47.227].</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@192-168-47-227 ~]$ nodetool ring | grep 9189073978895940412</span><br><span class="line">192.168.47.229  RAC1        Down   Leaving 44.07 KB        16.73%              -9189073978895940412</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@192-168-47-227 ~]$ nodetool removenode force</span><br><span class="line">RemovalStatus: Removing token (-9189073978895940412). Waiting for replication confirmation from [/192.168.48.161,/192.168.48.160,/192.168.47.228,/192.168.48.159,/192.168.47.227].</span><br><span class="line">[qihuang.zheng@192-168-47-227 ~]$ nodetool status</span><br><span class="line">--  Address         Load       Tokens  Owns   Host ID                               Rack</span><br><span class="line">UN  192.168.48.161  1.16 TB    256     20.6%  54b3a7e0-f778-4087-98c3-ac84e56f77e6  RAC1</span><br><span class="line">UN  192.168.48.160  474.38 GB  256     20.2%  18a87c56-dcba-4614-adba-804aa7761a06  RAC1</span><br><span class="line">UN  192.168.47.228  6.1 TB     256     20.4%  f3d26148-d2da-479c-ae9e-ae41aced1be9  RAC1</span><br><span class="line">UN  192.168.48.159  1.22 TB    256     20.1%  df9a693b-efc1-41bc-9a42-cf868ea75e65  RAC1</span><br><span class="line">UN  192.168.47.227  1.35 TB    256     18.8%  02575631-6ccb-4803-81fd-5bf7a978726d  RAC1</span><br></pre></td></tr></table></figure>
<h3 id="重新加入">重新加入</h3><p>228节点正在sstablelader，它实际上没有挂，但是其他节点确认为228挂了。 手动removenode后，其他节点认为228挂了。  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[admin@fp-cass048160 ~]$ /usr/install/cassandra/bin/nodetool status</span><br><span class="line">--  Address         Load       Tokens  Owns    Host ID                               Rack</span><br><span class="line">UN  192.168.48.227  2.89 TB    256     ?       f6136233-08b3-4cad-bd37-57ab6dc4622b  RAC1</span><br><span class="line">UN  192.168.48.226  2.81 TB    256     ?       6f4416e1-4493-4909-8427-3738ae72fd82  RAC1</span><br><span class="line">UN  192.168.48.176  6.12 TB    256     ?       08491b7a-8e9f-4b5e-b22b-2e73c455fd3f  RAC1</span><br><span class="line">UN  192.168.48.161  4.48 TB    256     ?       54b3a7e0-f778-4087-98c3-ac84e56f77e6  RAC1</span><br><span class="line">UN  192.168.48.160  4.57 TB    256     ?       18a87c56-dcba-4614-adba-804aa7761a06  RAC1</span><br><span class="line">UN  192.168.48.175  3.21 TB    256     ?       5bbd4400-2132-42b6-91c5-389592b75423  RAC1</span><br><span class="line">UN  192.168.48.159  4.69 TB    256     ?       df9a693b-efc1-41bc-9a42-cf868ea75e65  RAC1</span><br><span class="line">DN  192.168.48.228  2.72 TB    256     ?       dbf53446-35b6-4d18-80e2-396bc633924c  RAC1</span><br><span class="line">[admin@fp-cass048160 ~]$ nohup nodetool removenode dbf53446-35b6-4d18-80e2-396bc633924c &amp;</span><br><span class="line">[admin@fp-cass048160 ~]$ nodetool removenode force</span><br><span class="line">[admin@fp-cass048160 ~]$ /usr/install/cassandra/bin/nodetool status</span><br><span class="line">--  Address         Load       Tokens  Owns    Host ID                               Rack</span><br><span class="line">UN  192.168.48.227  2.89 TB    256     ?       f6136233-08b3-4cad-bd37-57ab6dc4622b  RAC1</span><br><span class="line">UN  192.168.48.226  2.81 TB    256     ?       6f4416e1-4493-4909-8427-3738ae72fd82  RAC1</span><br><span class="line">UN  192.168.48.176  6.12 TB    256     ?       08491b7a-8e9f-4b5e-b22b-2e73c455fd3f  RAC1</span><br><span class="line">UN  192.168.48.161  4.48 TB    256     ?       54b3a7e0-f778-4087-98c3-ac84e56f77e6  RAC1</span><br><span class="line">UN  192.168.48.160  4.57 TB    256     ?       18a87c56-dcba-4614-adba-804aa7761a06  RAC1</span><br><span class="line">UN  192.168.48.175  3.21 TB    256     ?       5bbd4400-2132-42b6-91c5-389592b75423  RAC1</span><br><span class="line">UN  192.168.48.159  4.69 TB    256     ?       df9a693b-efc1-41bc-9a42-cf868ea75e65  RAC1</span><br></pre></td></tr></table></figure>
<p>但是228节点认为其他节点都是好的。 如果尝试加入，会说已经在组中了。但是实际上它并不属于组了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[admin@192-168-48-228 ~]$ /usr/install/cassandra/bin/nodetool status</span><br><span class="line">--  Address         Load       Tokens  Owns    Host ID                               Rack</span><br><span class="line">UN  192.168.48.227  2.88 TB    256     ?       f6136233-08b3-4cad-bd37-57ab6dc4622b  RAC1</span><br><span class="line">UN  192.168.48.226  2.79 TB    256     ?       6f4416e1-4493-4909-8427-3738ae72fd82  RAC1</span><br><span class="line">UN  192.168.48.176  6.1 TB     256     ?       08491b7a-8e9f-4b5e-b22b-2e73c455fd3f  RAC1</span><br><span class="line">UN  192.168.48.161  4.47 TB    256     ?       54b3a7e0-f778-4087-98c3-ac84e56f77e6  RAC1</span><br><span class="line">UN  192.168.48.228  2.72 TB    256     ?       dbf53446-35b6-4d18-80e2-396bc633924c  RAC1</span><br><span class="line">UN  192.168.48.160  4.55 TB    256     ?       18a87c56-dcba-4614-adba-804aa7761a06  RAC1</span><br><span class="line">UN  192.168.48.175  3.2 TB     256     ?       5bbd4400-2132-42b6-91c5-389592b75423  RAC1</span><br><span class="line">UN  192.168.48.159  4.67 TB    256     ?       df9a693b-efc1-41bc-9a42-cf868ea75e65  RAC1</span><br><span class="line"></span><br><span class="line">Note: Non-system keyspaces don&apos;t have the same replication settings, effective ownership information is meaningless</span><br><span class="line">[admin@192-168-48-228 ~]$ /usr/install/cassandra/bin/nodetool join</span><br><span class="line">nodetool: This node has already joined the ring.</span><br></pre></td></tr></table></figure>
<h3 id="网络状态netstats:_显示一个节点的Active_Stream">网络状态netstats: 显示一个节点的Active Stream</h3><p>正常没有stream：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[admin@cass047202 ~]$ nodetool netstats</span><br><span class="line">Mode: NORMAL</span><br><span class="line">Not sending any streams.</span><br><span class="line">Read Repair Statistics:</span><br><span class="line">Attempted: 749</span><br><span class="line">Mismatch (Blocking): 4</span><br><span class="line">Mismatch (Background): 13</span><br><span class="line">Pool Name                    Active   Pending      Completed</span><br><span class="line">Commands                        n/a         0      581681910</span><br><span class="line">Responses                       n/a         0      519983825</span><br></pre></td></tr></table></figure>
<p>stream分成几种类型：bulkload(即通过sstableloader)， nodetool repair等</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[admin@cass047202 ~]$ nodetool netstats</span><br><span class="line">Mode: NORMAL</span><br><span class="line">Bulk Load 839a5ef0-44cf-11e6-b6f3-dff3aadcb7ef</span><br><span class="line">    /127.0.0.1 (using /192.168.48.168)</span><br><span class="line">        Receiving 272 files, 4388357561 bytes total. Already received 2 files, 46586511 bytes total</span><br><span class="line">            /home/admin/cassandra/data/md5s/md5_id_0-e842c330440a11e69e5f2bcdca057dae/md5s-md5_id_0-tmp-ka-63-Data.db 16194058/16194058 bytes(100%) received from idx:0/127.0.0.1</span><br><span class="line">            /home/admin/cassandra/data/md5s/md5_id_0-e842c330440a11e69e5f2bcdca057dae/md5s-md5_id_0-tmp-ka-64-Data.db 16202304/16202304 bytes(100%) received from idx:0/127.0.0.1</span><br><span class="line">            /home/admin/cassandra/data/md5s/md5_id_0-e842c330440a11e69e5f2bcdca057dae/md5s-md5_id_0-tmp-ka-65-Data.db 14190149/16008570 bytes(88%) received from idx:0/127.0.0.1</span><br><span class="line">Read Repair Statistics:</span><br><span class="line">Attempted: 749</span><br><span class="line">Mismatch (Blocking): 4</span><br><span class="line">Mismatch (Background): 13</span><br><span class="line">Pool Name                    Active   Pending      Completed</span><br><span class="line">Commands                        n/a         0      581694648</span><br><span class="line">Responses                       n/a         0      520000034</span><br></pre></td></tr></table></figure>
<p>1.正在加入集群的节点JOINING:   </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047224 cassandra]$ /usr/install/cassandra/bin/nodetool netstats</span><br><span class="line">Mode: JOINING</span><br><span class="line">Bootstrap fcca1bf0-4a6e-11e5-8677-6da22c7e072c</span><br><span class="line">    /192.168.47.222</span><br><span class="line">        Receiving 929 files, 259726626064 bytes total</span><br><span class="line">            /home/admin/cassandra/data/forseti_fp/tcp_syn_data/forseti_fp-tcp_syn_data-tmp-jb-198-Data.db 120433605/120433605 bytes(100%) received from /192.168.47.222</span><br><span class="line">    /192.168.47.203</span><br><span class="line">        Receiving 976 files, 214785965744 bytes total</span><br><span class="line">            /home/admin/cassandra/data/forseti/ip_mobilephone/forseti-ip_mobilephone-tmp-jb-16-Data.db 30801577/30801577 bytes(100%) received from /192.168.47.203</span><br></pre></td></tr></table></figure>
<p>2.离开集群的节点LEAVING:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047225 snapshots]$ nodetool netstats | head</span><br><span class="line">Mode: LEAVING</span><br><span class="line">Restore replica count dad915d0-7d6f-11e5-8681-9f6f9f8ad5ca</span><br><span class="line">    /192.168.47.221</span><br><span class="line">        Sending 243 files, 7877174416 bytes total</span><br></pre></td></tr></table></figure>
<p>下线的节点除了发送数据给其他节点, 也会接收数据.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047225 ~]$ nodetool netstats | grep &quot;files&quot;</span><br><span class="line">        Sending 183 files, 2169787693 bytes total</span><br><span class="line">        Sending 223 files, 6492707205 bytes total</span><br><span class="line">        ....</span><br><span class="line">        Receiving 242 files, 10438497913 bytes total</span><br><span class="line">        Receiving 279 files, 12407597530 bytes total</span><br></pre></td></tr></table></figure>
<p>3.正常的节点NORMAL, 会发送文件给其他节点, 并从下线的节点接收文件:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@spark047245 ~]$ /usr/install/cassandra/bin/nodetool netstats | head</span><br><span class="line">Mode: NORMAL</span><br><span class="line">Restore replica count db2a4310-7d6f-11e5-a4ef-8f719a2aece0</span><br><span class="line">    /192.168.47.205</span><br><span class="line">        Sending 309 files, 25090493062 bytes total</span><br><span class="line"></span><br><span class="line">Unbootstrap 00ecfbb0-7ea6-11e5-9266-f38b27f65aa6</span><br><span class="line">    /192.168.47.225</span><br><span class="line">        Receiving 556 files, 58062261421 bytes total</span><br></pre></td></tr></table></figure>
<h3 id="节点信息:_nodetool_info">节点信息: nodetool info</h3><p>主要关注KeyCache, 容量为512M(key_cache_size_in_mb), 用了500M左右, 命中率为65%. 没有开启RowCache(row_cache_size_in_mb:0).<br>堆内存16G, 用了6G(执行命令的这一时刻,并不是说总是占用这么点), 堆外内存off-heap使用了1G. 异常50个.    </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047202 ~]$ nodetool info</span><br><span class="line">Token                  : (invoke with -T/--tokens to see all 256 tokens)</span><br><span class="line">ID                     : abaa0cbc-09d3-4990-8698-ff4d2f2bb4f7</span><br><span class="line">Gossip active          : true</span><br><span class="line">Thrift active          : true</span><br><span class="line">Native Transport active: true</span><br><span class="line">Load                   : 618.81 GB</span><br><span class="line">Generation No          : 1445525962</span><br><span class="line">Uptime (seconds)       : 651191</span><br><span class="line">Heap Memory (MB)       : 6167.96 / 15974.44</span><br><span class="line">Off Heap Memory (MB)   : 1154.13</span><br><span class="line">Data Center            : DC1</span><br><span class="line">Rack                   : RAC1</span><br><span class="line">Exceptions             : 50</span><br><span class="line">Key Cache              : size 520120120 (bytes), capacity 536870912 (bytes), 112077861 hits, 182128983 requests, 0.656 recent hit rate, 14400 save period in seconds</span><br><span class="line">Row Cache              : size 0 (bytes), capacity 0 (bytes), 0 hits, 0 requests, NaN recent hit rate, 0 save period in seconds</span><br></pre></td></tr></table></figure>
<p>仅仅查看每个节点的KeyCache:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./pssh.sh ip_all.txt &quot;/usr/install/cassandra/bin/nodetool info | tail -2 | head -1&quot;</span><br><span class="line">./pssh.sh ip_all.txt &quot;/usr/install/cassandra/bin/nodetool info | sed -n &apos;14p&apos;&quot;</span><br></pre></td></tr></table></figure>
<h3 id="Gossip信息:_nodetool_gossipinfo">Gossip信息: nodetool gossipinfo</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">nodetool gossipinfo</span><br><span class="line">/192.168.47.205</span><br><span class="line">  STATUS:NORMAL,-1027890057681052346</span><br><span class="line">/192.168.47.206</span><br><span class="line">  STATUS:NORMAL,-1004054309250591595</span><br><span class="line">/192.168.47.202</span><br><span class="line">  STATUS:NORMAL,-1062467338696068910</span><br><span class="line">/192.168.47.204</span><br><span class="line">  STATUS:NORMAL,-1130382709140432588</span><br><span class="line">/192.168.47.224</span><br><span class="line">  STATUS:NORMAL,-1137590811836749748</span><br><span class="line">/192.168.47.203</span><br><span class="line">  STATUS:NORMAL,-1024266383569750575</span><br><span class="line">/192.168.47.222</span><br><span class="line">  STATUS:NORMAL,-105769922317262244</span><br><span class="line">/192.168.47.225</span><br><span class="line">  STATUS:NORMAL,-1061781412716791842</span><br><span class="line">/192.168.47.221</span><br><span class="line">  STATUS:NORMAL,-104095308743394398</span><br><span class="line">/192.168.47.229</span><br><span class="line">  STATUS:LEFT,-9088453765955214068,1448966282585</span><br></pre></td></tr></table></figure>
<h3 id="表相关的信息:nodetool_cfstats_forseti-velocity">表相关的信息:nodetool cfstats forseti.velocity</h3><p>1.查看表的信息, 前面四行是当前的读写延迟和读写次数.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047202 cassandra]$ nodetool cfstats forseti.velocity</span><br><span class="line">Keyspace: forseti</span><br><span class="line">    Read Count: 10470099</span><br><span class="line">    Read Latency: 1.3186399419909973 ms.</span><br><span class="line">    Write Count: 146970362</span><br><span class="line">    Write Latency: 0.06062576270989929 ms.</span><br><span class="line">    Pending Tasks: 0</span><br><span class="line">        Table: velocity</span><br><span class="line">        SSTable count: 2144</span><br><span class="line">        SSTables in each level: [1, 10, 96, 723, 1314, 0, 0, 0, 0]</span><br><span class="line">        Space used (live), bytes: 509031385679</span><br><span class="line">        Space used (total), bytes: 523815500936</span><br><span class="line">        Off heap memory used (total), bytes: 558210701</span><br><span class="line">        SSTable Compression Ratio: 0.23635049381008288</span><br><span class="line">        Number of keys (estimate): 269787648</span><br><span class="line">        Memtable cell count: 271431</span><br><span class="line">        Memtable data size, bytes: 141953019</span><br><span class="line">        Memtable switch count: 1713</span><br><span class="line">        Local read count: 10470099</span><br><span class="line">        Local read latency: 1.266 ms</span><br><span class="line">        Local write count: 146970371</span><br><span class="line">        Local write latency: 0.053 ms</span><br><span class="line">        Pending tasks: 0</span><br><span class="line">        Bloom filter false positives: 534721</span><br><span class="line">        Bloom filter false ratio: 0.13542</span><br><span class="line">        Bloom filter space used, bytes: 180529808</span><br><span class="line">        Bloom filter off heap memory used, bytes: 180512656</span><br><span class="line">        Index summary off heap memory used, bytes: 118613037</span><br><span class="line">        Compression metadata off heap memory used, bytes: 259085008</span><br><span class="line">        Compacted partition minimum bytes: 104</span><br><span class="line">        Compacted partition maximum bytes: 190420296972</span><br><span class="line">        Compacted partition mean bytes: 8656</span><br><span class="line">        Average live cells per slice (last five minutes): 0.0</span><br><span class="line">        Average tombstones per slice (last five minutes): 0.0</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@spark047211 ~]$ nodetool -h 192.168.48.159 cfstats forseti_fp.android_device_session</span><br><span class="line">Keyspace: forseti_fp</span><br><span class="line">  Read Count: 3436820</span><br><span class="line">  Read Latency: 0.7271564521854504 ms.</span><br><span class="line">  Write Count: 1242325989</span><br><span class="line">  Write Latency: 0.01608114556074058 ms.</span><br><span class="line">  Pending Flushes: 0</span><br><span class="line">    Table: android_device_session</span><br><span class="line">    SSTable count: 14</span><br><span class="line">    Space used (live): 3315056965329</span><br><span class="line">    Space used (total): 3315312862453</span><br><span class="line">    Space used by snapshots (total): 0</span><br><span class="line">    Off heap memory used (total): 1813094460</span><br><span class="line">    SSTable Compression Ratio: 0.37206192803944754 </span><br><span class="line">    Number of keys (estimate): 954623103             -&gt; 9亿</span><br><span class="line">    Memtable cell count: 92654</span><br><span class="line">    Memtable data size: 104729033</span><br><span class="line">    Memtable off heap memory used: 0</span><br><span class="line">    Memtable switch count: 13386</span><br><span class="line">    Local read count: 3436820</span><br><span class="line">    Local read latency: 0.728 ms</span><br><span class="line">    Local write count: 1242326281</span><br><span class="line">    Local write latency: 0.017 ms</span><br><span class="line">    Pending flushes: 0</span><br><span class="line">    Bloom filter false positives: 15</span><br><span class="line">    Bloom filter false ratio: 0.00000</span><br><span class="line">    Bloom filter space used: 607412928</span><br><span class="line">    Bloom filter off heap memory used: 607412816</span><br><span class="line">    Index summary off heap memory used: 138144620</span><br><span class="line">    Compression metadata off heap memory used: 1067537024</span><br><span class="line">    Compacted partition minimum bytes: 125</span><br><span class="line">    Compacted partition maximum bytes: 4866323</span><br><span class="line">    Compacted partition mean bytes: 10051</span><br><span class="line">    Average live cells per slice (last five minutes): 0.10287086386072478</span><br><span class="line">    Maximum live cells per slice (last five minutes): 7.0</span><br><span class="line">    Average tombstones per slice (last five minutes): 0.14188850295078587</span><br><span class="line">    Maximum tombstones per slice (last five minutes): 2164.0</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@spark047211 ~]$ nodetool -h 192.168.48.162 cfstats forseti.velocity_app</span><br><span class="line">Keyspace: forseti</span><br><span class="line">  Read Count: 120443046</span><br><span class="line">  Read Latency: 1.1013535886995087 ms.</span><br><span class="line">  Write Count: 2058015125</span><br><span class="line">  Write Latency: 0.016679299918653415 ms.</span><br><span class="line">  Pending Tasks: 0</span><br><span class="line">    Table: velocity_app</span><br><span class="line">    SSTable count: 24</span><br><span class="line">    Space used (live), bytes: 2670044515793</span><br><span class="line">    Space used (total), bytes: 2670239936283</span><br><span class="line">    Off heap memory used (total), bytes: 2958340937</span><br><span class="line">    SSTable Compression Ratio: 0.28255581535232427</span><br><span class="line">    Number of keys (estimate): 1976325248   (19亿)</span><br><span class="line">    Memtable cell count: 613404</span><br><span class="line">    Memtable data size, bytes: 233170920</span><br><span class="line">    Memtable switch count: 4214</span><br><span class="line">    Local read count: 120443053</span><br><span class="line">    Local read latency: 0.931 ms</span><br><span class="line">    Local write count: 2058015151</span><br><span class="line">    Local write latency: 0.015 ms</span><br><span class="line">    Pending tasks: 0</span><br><span class="line">    Bloom filter false positives: 45097</span><br><span class="line">    Bloom filter false ratio: 0.00732</span><br><span class="line">    Bloom filter space used, bytes: 1230425688</span><br><span class="line">    Bloom filter off heap memory used, bytes: 1230425496</span><br><span class="line">    Index summary off heap memory used, bytes: 578011001</span><br><span class="line">    Compression metadata off heap memory used, bytes: 1149904440</span><br><span class="line">    Compacted partition minimum bytes: 150</span><br><span class="line">    Compacted partition maximum bytes: 158(GB),683(MB),580(KB),810</span><br><span class="line">    Compacted partition mean bytes: 5225</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@spark047211 ~]$ nodetool -h 192.168.48.162 cfstats forseti.velocity_partner</span><br><span class="line">Keyspace: forseti</span><br><span class="line">  Read Count: 3664048</span><br><span class="line">  Read Latency: 1.265197941730021 ms.</span><br><span class="line">  Write Count: 1963754310</span><br><span class="line">  Write Latency: 0.017543929064120042 ms.</span><br><span class="line">  Pending Tasks: 0</span><br><span class="line">    Table: velocity_partner</span><br><span class="line">    SSTable count: 5798</span><br><span class="line">    SSTables in each level: [1, 11/10, 90, 881, 4813, 0, 0, 0, 0]</span><br><span class="line">    Space used (live), bytes: 1237251258441</span><br><span class="line">    Space used (total), bytes: 1240223108780</span><br><span class="line">    Off heap memory used (total), bytes: 1220821758</span><br><span class="line">    SSTable Compression Ratio: 0.2518164031088747</span><br><span class="line">    Number of keys (estimate): 821395584      8亿</span><br><span class="line">    Memtable cell count: 775752</span><br><span class="line">    Memtable data size, bytes: 265533044</span><br><span class="line">    Memtable switch count: 4217</span><br><span class="line">    Local read count: 3664048</span><br><span class="line">    Local read latency: 1.200 ms</span><br><span class="line">    Local write count: 1963754352</span><br><span class="line">    Local write latency: 0.017 ms</span><br><span class="line">    Pending tasks: 0</span><br><span class="line">    Bloom filter false positives: 599</span><br><span class="line">    Bloom filter false ratio: 0.00000</span><br><span class="line">    Bloom filter space used, bytes: 503778320</span><br><span class="line">    Bloom filter off heap memory used, bytes: 503731936</span><br><span class="line">    Index summary off heap memory used, bytes: 144796454</span><br><span class="line">    Compression metadata off heap memory used, bytes: 572293368</span><br><span class="line">    Compacted partition minimum bytes: 259</span><br><span class="line">    Compacted partition maximum bytes: 91,830,775,932</span><br><span class="line">    Compacted partition mean bytes: 6265</span><br><span class="line">    Average live cells per slice (last five minutes): 1.0</span><br><span class="line">    Average tombstones per slice (last five minutes): 0.0</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@spark047211 ~]$ nodetool -h 192.168.48.162 cfstats forseti.velocity_global</span><br><span class="line">Keyspace: forseti</span><br><span class="line">  Read Count: 27019937</span><br><span class="line">  Read Latency: 0.8387888214173111 ms.</span><br><span class="line">  Write Count: 2057412727</span><br><span class="line">  Write Latency: 0.01946266525841317 ms.</span><br><span class="line">  Pending Tasks: 0</span><br><span class="line">    Table: velocity_global</span><br><span class="line">    SSTable count: 5468</span><br><span class="line">    SSTables in each level: [7/4, 12/10, 77, 703, 4667, 0, 0, 0, 0]</span><br><span class="line">    Space used (live), bytes: 1476150066588</span><br><span class="line">    Space used (total), bytes: 1477238480867</span><br><span class="line">    Off heap memory used (total), bytes: 1092884433</span><br><span class="line">    SSTable Compression Ratio: 0.24933201816062378</span><br><span class="line">    Number of keys (estimate): 558798080     5亿</span><br><span class="line">    Memtable cell count: 120625</span><br><span class="line">    Memtable data size, bytes: 38130612</span><br><span class="line">    Memtable switch count: 4250</span><br><span class="line">    Local read count: 27019937</span><br><span class="line">    Local read latency: 1.128 ms</span><br><span class="line">    Local write count: 2057412797</span><br><span class="line">    Local write latency: 0.016 ms</span><br><span class="line">    Pending tasks: 0</span><br><span class="line">    Bloom filter false positives: 1700</span><br><span class="line">    Bloom filter false ratio: 0.00000</span><br><span class="line">    Bloom filter space used, bytes: 319642480</span><br><span class="line">    Bloom filter off heap memory used, bytes: 319598736</span><br><span class="line">    Index summary off heap memory used, bytes: 100862649</span><br><span class="line">    Compression metadata off heap memory used, bytes: 672423048</span><br><span class="line">    Compacted partition minimum bytes: 311</span><br><span class="line">    Compacted partition maximum bytes: 568G,591M,960K,032</span><br><span class="line">    Compacted partition mean bytes: 10777</span><br><span class="line">    Average live cells per slice (last five minutes): 0.0</span><br><span class="line">    Average tombstones per slice (last five minutes): 0.0</span><br></pre></td></tr></table></figure>
<p>velocity在当前节点的keys有2.6亿. 其中最大的partition有190G! 说明存在一些很宽的行wide rows. 平均每个partition的大小是104Byte.   </p>
<p><a href="http://docs.datastax.com/en/cql/3.1/cql/cql_reference/compactSubprop.html" target="_blank" rel="noopener">http://docs.datastax.com/en/cql/3.1/cql/cql_reference/compactSubprop.html</a>  </p>
<blockquote>
<p>sstable_size_in_mb默认是160MB. The target size for SSTables that use the leveled compaction strategy.<br>Although SSTable sizes should be less or equal to sstable_size_in_mb, 尽管SSTable的大小应该比默认的160M要小或相等.<br>it is possible to have a larger SSTable during compaction. 在Compaction过程中,可能产生更大的SSTable.<br>This occurs when data for a given partition key is exceptionally large. 当某个分区键的数据非常大时,<br>The data is not split into two SSTables. 分区很大的键在compact时不会拆分到两个SSTable文件中(因为partition key只会在一个SSTable中).  </p>
</blockquote>
<p>2.线程池状态: tpstatus可以查看的内容和system.log中打印的StatsLogger差不多.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047202 cassandra]$ nodetool tpstats</span><br><span class="line">Pool Name                    Active   Pending      Completed   Blocked  All time blocked</span><br><span class="line">ReadStage                         2         0       10960442         0                 0</span><br><span class="line">RequestResponseStage              0         0      447942623         0                 0</span><br><span class="line">MutationStage                     0         0      239315421         0                 0</span><br><span class="line">ReadRepairStage                   0         0        1124868         0                 0</span><br><span class="line">ReplicateOnWriteStage             0         0              0         0                 0</span><br><span class="line">GossipStage                       0         0        1477282         0                 0</span><br><span class="line">CacheCleanupExecutor              0         0              0         0                 0</span><br><span class="line">MigrationStage                    0         0             46         0                 0</span><br><span class="line">MemoryMeter                       0         0          10694         0                 0</span><br><span class="line">FlushWriter                       0         0          11360         0               511</span><br><span class="line">ValidationExecutor                0         0              0         0                 0</span><br><span class="line">InternalResponseStage             0         0              0         0                 0</span><br><span class="line">AntiEntropyStage                  0         0              0         0                 0</span><br><span class="line">MemtablePostFlusher               0         0          16487         0                 0</span><br><span class="line">MiscStage                         0         0              0         0                 0</span><br><span class="line">PendingRangeCalculator            0         0             39         0                 0</span><br><span class="line">CompactionExecutor                3         3          47113         0                 0</span><br><span class="line">commitlog_archiver                0         0              0         0                 0</span><br><span class="line">HintedHandoff                     0         1            867         0                 0</span><br><span class="line"></span><br><span class="line">Message type           Dropped</span><br><span class="line">RANGE_SLICE                  0</span><br><span class="line">READ_REPAIR                  0</span><br><span class="line">PAGED_RANGE                  0</span><br><span class="line">BINARY                       0</span><br><span class="line">READ                         0</span><br><span class="line">MUTATION                     0</span><br><span class="line">_TRACE                       0</span><br><span class="line">REQUEST_RESPONSE             2</span><br><span class="line">COUNTER_MUTATION             0</span><br></pre></td></tr></table></figure>
<p>比如正在运行的CompactionExecutor有3个, 用compactionstats可以查看正在运行Compaction的表:   </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass047202 cassandra]$ nodetool compactionstats</span><br><span class="line">pending tasks: 4</span><br><span class="line">          compaction type        keyspace           table       completed           total      unit  progress</span><br><span class="line">               Compaction         forseti        velocity      9600330302     12886138624     bytes    74.50%</span><br><span class="line">               Compaction         forseti  device_account        64712962      1923986398     bytes     3.36%</span><br><span class="line">     Tombstone Compaction         forseti        velocity        95382333    170991248015     bytes     0.06%</span><br><span class="line">Active compaction remaining time :   0h00m38s</span><br></pre></td></tr></table></figure>
<h3 id="compactionhistory">compactionhistory</h3><p><a href="https://docs.datastax.com/en/cassandra/2.1/cassandra/tools/toolsCompactionHistory.html" target="_blank" rel="noopener">https://docs.datastax.com/en/cassandra/2.1/cassandra/tools/toolsCompactionHistory.html</a></p>
<p>最后一列表示rows_merged：{tables:rows}. For example: {1:3, 3:1} means 3 rows were taken from one SSTable (1:3)<br>and 1 row taken from 3 SSTables (3:1) to make the one SSTable in that compaction operation.  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">nodetool compactionhistory | grep velocity | sort -r -k 4 &gt; compactionhistory.log</span><br><span class="line">nodetool compactionhistory | grep velocity | sort -r -k 4 | awk &apos;&#123;for(i=4;i&lt;=NF;i++) printf&quot;%s\t&quot;,$i&#125; &#123;print &quot;&quot;&#125;&apos; | head </span><br><span class="line">nodetool compactionhistory | grep velocity | sort -r -k 4 | awk &apos;&#123;if(NF&gt;9) print $0&#125;&apos;</span><br><span class="line"></span><br><span class="line">3cb01450-e5d7-11e5-8fe9-2bcdca057dae     forseti            velocity                     1457514830357             985256393      869306399      &#123;1:325289, 2:11651&#125;</span><br><span class="line">ff100470-e5d6-11e5-8fe9-2bcdca057dae     forseti            velocity                     1457514726967             161269131      159732166      &#123;1:207378, 2:9918&#125;</span><br><span class="line">bafef020-e5d6-11e5-8fe9-2bcdca057dae     forseti            velocity                     1457514612770             1171434739     1167942768     &#123;1:811453, 2:28598&#125;</span><br><span class="line">b7c08e00-e5d6-11e5-8fe9-2bcdca057dae     forseti            velocity                     1457514607328             144946713      143529681      &#123;1:187320, 2:10070&#125;</span><br><span class="line">6f66d380-e5d6-11e5-8fe9-2bcdca057dae     forseti            velocity                     1457514485944             128493647      127148807      &#123;1:167405, 2:9312&#125;</span><br><span class="line">2be5ca30-e5d6-11e5-8fe9-2bcdca057dae     forseti            velocity                     1457514372691             112061194      111124311      &#123;1:151315, 2:6405&#125;</span><br><span class="line">2a335f40-e5d6-11e5-8fe9-2bcdca057dae     forseti            velocity                     1457514369844             2078394794     2073816751     &#123;1:1298699, 2:39956&#125;</span><br><span class="line">04070880-e5d6-11e5-8fe9-2bcdca057dae     forseti            velocity                     1457514305799             103532684      102206816      &#123;1:137231, 2:9020&#125;</span><br><span class="line">bb648530-e5d5-11e5-8fe9-2bcdca057dae     forseti            velocity                     1457514183938             86832984       85571719       &#123;1:115214, 2:8749&#125;</span><br><span class="line">750254f0-e5d5-11e5-8fe9-2bcdca057dae     forseti            velocity                     1457514065855             69678994       68516377       &#123;1:93817, 2:7968&#125;</span><br><span class="line">3b9a2260-e5d5-11e5-8fe9-2bcdca057dae     forseti            velocity                     1457513969542             53715409       51918781       &#123;1:69930, 2:6969, 3:2522&#125;</span><br></pre></td></tr></table></figure>
<p>history的信息解释</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">id                                     ks           cf                  compactedAt       bytes_in        bytes_out       rows_compacted</span><br><span class="line">3cb01450-e5d7-11e5-8fe9-2bcdca057dae   forseti      velocity            1457514830357     985,256,393     869,306,399     &#123;1:325289, 2:11651&#125;</span><br><span class="line"></span><br><span class="line">985MB，一个文件的有325289条， 读取两个文件的有11651</span><br><span class="line"></span><br><span class="line">xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx    model_result credit_id_labels    xxxxxxxxxxxxx     7,166,010         7,166,549     &#123;1:8954&#125;</span><br><span class="line"></span><br><span class="line">7MB，一个文件的有8954条，平均每条数据的大小是7,166/8964=0.8KB</span><br><span class="line"></span><br><span class="line">xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx    model_result credit_id_labels_v2 xxxxxxxxxxxxx     65,738,206        65,799,090    &#123;1:113483&#125;</span><br><span class="line"></span><br><span class="line">65MB，一个文件的有113483条，每条大小=65738206/113483=579Bytes</span><br><span class="line"></span><br><span class="line">这两张表的不同点是：credit_id_labels有多个字段，而credit_id_labels_v2将所有字段用json表示</span><br></pre></td></tr></table></figure>
<p>system.log中对于每次Compaction操作都有记录本次合并了多少个文件：  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">INFO [CompactionExecutor:48884] 2016-03-11 08:08:34,162 CompactionTask.java (line 120) Compacting [</span><br><span class="line">  SSTableReader(path=&apos;/home/admin/cassandra/data/system/compactions_in_progress/system-compactions_in_progress-jb-947338-Data.db&apos;), </span><br><span class="line">  SSTableReader(path=&apos;/home/admin/cassandra/data/system/compactions_in_progress/system-compactions_in_progress-jb-947335-Data.db&apos;), </span><br><span class="line">  SSTableReader(path=&apos;/home/admin/cassandra/data/system/compactions_in_progress/system-compactions_in_progress-jb-947334-Data.db&apos;), </span><br><span class="line">  SSTableReader(path=&apos;/home/admin/cassandra/data/system/compactions_in_progress/system-compactions_in_progress-jb-947336-Data.db&apos;), </span><br><span class="line">  SSTableReader(path=&apos;/home/admin/cassandra/data/system/compactions_in_progress/system-compactions_in_progress-jb-947337-Data.db&apos;)]</span><br><span class="line">INFO [CompactionExecutor:48884] 2016-03-11 08:08:34,181 CompactionTask.java (line 299) Compacted 5 sstables to [</span><br><span class="line">/home/admin/cassandra/data/system/compactions_in_progress/system-compactions_in_progress-jb-947339,].  </span><br><span class="line">1,803 bytes to 1,044 (~57% of original) in 18ms = 0.055313MB/s.  </span><br><span class="line">12 total partitions merged to 8.  Partition merge counts were &#123;1:8, 2:2, &#125;</span><br></pre></td></tr></table></figure>
<p>1:8表示：有8行从一个sstables中获取<br>2:2表示：有2行从两个sstables中获取</p>
<p>疑问：partitions数量从12个被合并为8个，为什么partition会减少呢？<br>totalSourceRows=12, totalkeysWritten=8<br>rows和keys的概念是不同的。 相同key可以有多个rows。<br>所以12条记录中，会有4条记录的row-key和8条中的相同。最后的keys数量也就只有4个。  </p>
<h3 id="节点sstable数量异常">节点sstable数量异常</h3><p>某个节点读延迟异常高，700ms</p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160317181038372" alt="fp_readrt_high"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@fp-cass048160 ~]$ nodetool cfstats forseti_fp.android_device_session</span><br><span class="line">Keyspace: forseti_fp</span><br><span class="line">    Read Count: 608718</span><br><span class="line">    Read Latency: 414.3243900525366 ms.</span><br><span class="line">    Write Count: 594753618</span><br><span class="line">    Write Latency: 0.025195973536725928 ms.</span><br><span class="line">    Pending Tasks: 0</span><br><span class="line">        Table: android_device_session</span><br><span class="line">        SSTable count: 32459</span><br><span class="line">        Space used (live), bytes: 2788804636549</span><br><span class="line">        Space used (total), bytes: 2795041174866</span><br><span class="line">        Off heap memory used (total), bytes: 2909029224</span><br><span class="line">        SSTable Compression Ratio: 0.3635126499232498</span><br><span class="line">        Number of keys (estimate): 1299672448</span><br><span class="line">        Memtable cell count: 30494</span><br><span class="line">        Memtable data size, bytes: 109313490</span><br><span class="line">        Memtable switch count: 19297</span><br><span class="line">        Local read count: 608718</span><br><span class="line">        Local read latency: 866.253 ms</span><br><span class="line">        Local write count: 594753660</span><br><span class="line">        Local write latency: 0.024 ms</span><br></pre></td></tr></table></figure>
<p>同一个集群其他节点的读延迟很少，sstable数量不超过20个。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@fp-cass048159 ~]$ nodetool cfstats forseti_fp.android_device_session</span><br><span class="line">Keyspace: forseti_fp</span><br><span class="line">    Read Count: 266951</span><br><span class="line">    Read Latency: 0.9562793471461055 ms.</span><br><span class="line">    Write Count: 799860155</span><br><span class="line">    Write Latency: 0.024167126153446163 ms.</span><br><span class="line">    Pending Tasks: 0</span><br><span class="line">        Table: android_device_session</span><br><span class="line">        SSTable count: 16</span><br><span class="line">        Space used (live), bytes: 4644725077858</span><br><span class="line">        Space used (total), bytes: 4659648681740</span><br><span class="line">        Off heap memory used (total), bytes: 2942472988</span><br><span class="line">        SSTable Compression Ratio: 0.3659509172064071</span><br><span class="line">        Number of keys (estimate): 1344413568</span><br><span class="line">        Memtable cell count: 30468</span><br><span class="line">        Memtable data size, bytes: 107505453</span><br><span class="line">        Memtable switch count: 25428</span><br><span class="line">        Local read count: 266951</span><br><span class="line">        Local read latency: 0.774 ms</span><br><span class="line">        Local write count: 799860178</span><br><span class="line">        Local write latency: 0.022 ms</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass048169 ~]$ nodetool status |grep RAC|awk &apos;&#123;print $2&#125;&apos; | while read ip; do echo $ip; nodetool -h $ip cfstats forseti.velocity_app | grep &quot;SSTable count&quot;; done</span><br><span class="line">192.168.48.163</span><br><span class="line">        SSTable count: 42</span><br><span class="line">192.168.48.162</span><br><span class="line">        SSTable count: 34</span><br><span class="line">192.168.48.174</span><br><span class="line">        SSTable count: 26</span><br><span class="line">192.168.48.173</span><br><span class="line">        SSTable count: 26</span><br><span class="line">192.168.48.171</span><br><span class="line">        SSTable count: 30</span><br><span class="line">192.168.48.169</span><br><span class="line">        SSTable count: 2620</span><br></pre></td></tr></table></figure>
<p>磁盘空间和status的负载不同，差距不是一般大：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass048169 ~]$ df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3       271G  8.3G  249G   4% /</span><br><span class="line">tmpfs            16G     0   16G   0% /dev/shm</span><br><span class="line">/dev/sda1       190M   30M  151M  17% /boot</span><br><span class="line">/dev/sdb1        11T  8.3T  1.6T  85% /home</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@cass048169 ~]$ nodetool status</span><br><span class="line">Note: Ownership information does not include topology; for complete information, specify a keyspace</span><br><span class="line">--  Address         Load       Tokens  Owns   Host ID                               Rack</span><br><span class="line">UN  192.168.48.163  2.34 TB    256     15.9%  003a7621-a62b-4c29-83ac-6724d2d749ab  RAC1</span><br><span class="line">UN  192.168.48.162  2.11 TB    256     15.3%  9d507979-f309-4a8b-98e2-92385701dcfe  RAC1</span><br><span class="line">UN  192.168.48.174  2.35 TB    256     17.9%  bc66ae3b-d694-4286-9c89-09ea46ea740d  RAC1</span><br><span class="line">UN  192.168.48.173  2.39 TB    256     17.4%  6de0bf8b-620b-4b47-b47b-1d8ecb82f20d  RAC1</span><br><span class="line">UN  192.168.48.171  2.24 TB    256     15.6%  d9b4f2e3-54a4-47d6-95e1-55a6f9734e79  RAC1</span><br><span class="line">UN  192.168.48.169  2.63 TB    256     17.9%  2a80470e-1dc4-4734-a268-946886fe25b7  RAC1</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@cass048169 ~]$ du -sh /home/admin/cassandra/data/forseti/*</span><br><span class="line">3.4T    /home/admin/cassandra/data/forseti/velocity_app</span><br><span class="line">2.5T    /home/admin/cassandra/data/forseti/velocity_global</span><br><span class="line">2.5T    /home/admin/cassandra/data/forseti/velocity_partner</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@cass048169 ~]$ nodetool compactionstats</span><br><span class="line">pending tasks: 4117</span><br><span class="line">          compaction type        keyspace           table       completed           total      unit  progress</span><br><span class="line">               Compaction         forsetivelocity_partner       454792709       608062664     bytes    74.79%</span><br><span class="line">               Compaction         forseti    velocity_app   5711586451164   6322585431145     bytes    90.34%</span><br><span class="line">               Compaction         forseti velocity_global     11137129414     79062862183     bytes    14.09%</span><br><span class="line">               Compaction         forsetivelocity_partner      3724946719      3887650106     bytes    95.81%</span><br><span class="line">               Compaction         forseti    velocity_app       145281458       167205065     bytes    86.89%</span><br><span class="line">               Compaction         forsetivelocity_partner    112338305659    774832769029     bytes    14.50%</span><br><span class="line">               Compaction         forseti velocity_global     24832092819     41353336206     bytes    60.05%</span><br><span class="line">               Compaction         forseti velocity_global      4981924282      6189383778     bytes    80.49%</span><br><span class="line">Active compaction remaining time :   2h48m48s</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@fp-cass048162 velocity_app]$ nodetool compactionstats</span><br><span class="line">pending tasks: 3082</span><br><span class="line">          compaction type        keyspace           table       completed           total      unit  progress</span><br><span class="line">               Compaction         forseti velocity_global     11519537972     58891073447     bytes    19.56%</span><br><span class="line">               Compaction         forsetivelocity_partner       519435163       900884457     bytes    57.66%</span><br><span class="line">               Compaction         forsetivelocity_partner    218779482632    268314967832     bytes    81.54%</span><br><span class="line">               Compaction         forsetivelocity_partner     53136709412     77669440754     bytes    68.41%</span><br><span class="line">               Compaction         forsetivelocity_partner        96402475       225578061     bytes    42.74%</span><br><span class="line">               Compaction         forsetivelocity_partner        13945308       205008051     bytes     6.80%</span><br><span class="line">               Compaction         forseti    velocity_app     92188611730    284042451190     bytes    32.46%</span><br><span class="line">               Compaction         forsetivelocity_partner       205665564       700947805     bytes    29.34%</span><br><span class="line">Active compaction remaining time :   0h39m03s</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@cass047202 ~]$ nodetool compactionstats</span><br><span class="line">pending tasks: 1</span><br><span class="line">          compaction type        keyspace           table       completed           total      unit  progress</span><br><span class="line">               Compaction         forseti        velocity      4094787925      6749331650     bytes    60.67%</span><br><span class="line">Active compaction remaining time :   0h00m19s</span><br></pre></td></tr></table></figure>
<h2 id="tpstats">tpstats</h2><p>正常情况下不应该出现有Dropped的，但是在Driver报错：All host(s) tried for query failed,… connection has been closed.<br>是不是连接数过多，直接拒绝？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">[admin@mysql047012 ~]$ /usr/install/cassandra/bin/nodetool tpstats</span><br><span class="line">Pool Name                    Active   Pending      Completed   Blocked  All time blocked</span><br><span class="line">CounterMutationStage              0         0              0         0                 0</span><br><span class="line">ReadStage                         0         0        4302492         0                 0</span><br><span class="line">RequestResponseStage              0         0              0         0                 0</span><br><span class="line">MutationStage                    15         0       44176401         0                 0</span><br><span class="line">ReadRepairStage                   0         0              0         0                 0</span><br><span class="line">GossipStage                       0         0              0         0                 0</span><br><span class="line">CacheCleanupExecutor              0         0              0         0                 0</span><br><span class="line">AntiEntropyStage                  0         0              0         0                 0</span><br><span class="line">MigrationStage                    0         0              0         0                 0</span><br><span class="line">Sampler                           0         0              0         0                 0</span><br><span class="line">ValidationExecutor                0         0              0         0                 0</span><br><span class="line">CommitLogArchiver                 0         0              0         0                 0</span><br><span class="line">MiscStage                         0         0              0         0                 0</span><br><span class="line">MemtableFlushWriter               0         0            920         0                 0</span><br><span class="line">MemtableReclaimMemory             0         0            925         0                 0</span><br><span class="line">PendingRangeCalculator            0         0              1         0                 0</span><br><span class="line">MemtablePostFlush                 0         0           5245         0                 0</span><br><span class="line">CompactionExecutor                1         1         328827         0                 0</span><br><span class="line">InternalResponseStage             0         0              0         0                 0</span><br><span class="line">HintedHandoff                     0         0              0         0                 0</span><br><span class="line">Native-Transport-Requests        19         0       13670768         0              6885</span><br><span class="line"></span><br><span class="line">Message type           Dropped</span><br><span class="line">RANGE_SLICE                  0</span><br><span class="line">READ_REPAIR                  0</span><br><span class="line">PAGED_RANGE                  0</span><br><span class="line">BINARY                       0</span><br><span class="line">READ                         0</span><br><span class="line">MUTATION                  1808</span><br><span class="line">_TRACE                       0</span><br><span class="line">REQUEST_RESPONSE             0</span><br><span class="line">COUNTER_MUTATION             0</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">INFO  [SharedPool-Worker-40] 2016-06-23 17:38:19,848 Message.java:532 - Unexpected exception during request; channel = [id: 0x04539b0a, /192.168.47.34:64733 :&gt; /192.168.47.12:9042]</span><br><span class="line">java.io.IOException: Error while read(...): Connection reset by peer</span><br><span class="line">        at io.netty.channel.epoll.Native.readAddress(Native Method) ~[netty-all-4.0.23.Final.jar:4.0.23.Final]</span><br><span class="line">        at io.netty.channel.epoll.EpollSocketChannel$EpollSocketUnsafe.doReadBytes(EpollSocketChannel.java:675) ~[netty-all-4.0.23.Final.jar:4.0.23.Final]</span><br><span class="line">        at io.netty.channel.epoll.EpollSocketChannel$EpollSocketUnsafe.epollInReady(EpollSocketChannel.java:714) ~[netty-all-4.0.23.Final.jar:4.0.23.Final]</span><br><span class="line">        at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:326) ~[netty-all-4.0.23.Final.jar:4.0.23.Final]</span><br><span class="line">        at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:264) ~[netty-all-4.0.23.Final.jar:4.0.23.Final]</span><br><span class="line">        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116) ~[netty-all-4.0.23.Final.jar:4.0.23.Final]</span><br><span class="line">        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137) ~[netty-all-4.0.23.Final.jar:4.0.23.Final]</span><br><span class="line">        at java.lang.Thread.run(Thread.java:745) [na:1.7.0_71]</span><br></pre></td></tr></table></figure>
<h2 id="sstable_writer">sstable writer</h2><blockquote>
<p>Loads newly placed SSTables onto the system without a restart.</p>
</blockquote>
<p><a href="http://www.planetcassandra.org/blog/bulk-loading-options-for-cassandra/" target="_blank" rel="noopener">http://www.planetcassandra.org/blog/bulk-loading-options-for-cassandra/</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">小批量测试</span><br><span class="line">cp /home/admin/md5id_20160601/data/md5_id/data-md5_id-ka-2165* </span><br><span class="line">cd ~/cassandra/data/md5/md5_id-f88d3930345811e694a62bcdca057dae/ </span><br><span class="line">rename data md5 *</span><br><span class="line">nodetool -h 192.168.47.202 refresh md5 md5_id</span><br><span class="line"></span><br><span class="line">#重命名所有文件</span><br><span class="line">cd /home/admin/md5id_20160601/data/md5_id/</span><br><span class="line">rename data md5 * </span><br><span class="line"></span><br><span class="line">#找出所有不同编号</span><br><span class="line">for f in $( ls | cut -d&apos;-&apos; -f-4 | uniq | head -5 ); do</span><br><span class="line">  echo $f</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">#一次多个，但是如何循环所有，直到文件夹都处理完毕？ --》使用while循环判断文件夹下存在文件时处理</span><br><span class="line">ls | cut -d&apos;-&apos; -f-4 | uniq | head -5 | while read f; do   #分组，一次可以多个数据文件，而一个数据文件总共包含8个相关组件</span><br><span class="line">  mv $f-* ~/cassandra/data/md5/md5_id-f88d3930345811e694a62bcdca057dae/   #移动到cassandra的目标位置</span><br><span class="line">done</span><br><span class="line">nodetool -h 192.168.47.202 refresh md5 md5_id         #刷新sstable</span><br><span class="line"></span><br><span class="line">#模拟把分多次把一个文件夹test的文件搬到另一个文件夹test1</span><br><span class="line">rm -rf test test1 &amp;&amp; mkdir test &amp;&amp; cd test &amp;&amp; touch 10 11 12 13 14 15 20 21 22 23 30 31 32 &amp;&amp; cd ~/ &amp;&amp; mkdir test1 </span><br><span class="line"></span><br><span class="line">cd test</span><br><span class="line">flag=&quot;BEGIN&quot;</span><br><span class="line">while [ ! -d test ]; do</span><br><span class="line">  ls | head -2 | while read f; do </span><br><span class="line">    mv $f ~/test1</span><br><span class="line">  done</span><br><span class="line">  #确保只需要执行一次, test的文件都被移动到test1后，test下没有文件，判断依据是：ls -A为空</span><br><span class="line">  #但是如果没有加任何条件，while循环会无条件判断，因为while中是判断存在文件夹</span><br><span class="line">  if [[ &quot;`ls -A ~/test`&quot; = &quot;&quot; &amp;&amp; $flag != &quot;OVER&quot; ]]; then</span><br><span class="line">    flag=&quot;OVER&quot;</span><br><span class="line">    echo &quot;DONE&quot;</span><br><span class="line">  fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">#可以把判断放在while循环里！--GOOD</span><br><span class="line">cd test</span><br><span class="line">flag=&quot;BEGIN&quot;</span><br><span class="line">while [[ ! -d test &amp;&amp; $flag != &quot;OVER&quot; ]]; do</span><br><span class="line">  ls | head -2 | while read f; do </span><br><span class="line">    mv $f ~/test1</span><br><span class="line">  done</span><br><span class="line">  if [ &quot;`ls -A ~/test`&quot; = &quot;&quot; ]; then</span><br><span class="line">    flag=&quot;OVER&quot;</span><br><span class="line">  fi</span><br><span class="line">done</span><br><span class="line">echo &quot;OVER...&quot;</span><br><span class="line"></span><br><span class="line">#当然可以把if的所有条件都放到while里</span><br><span class="line">cd test</span><br><span class="line">while [[ ! -d test &amp;&amp; &quot;`ls -A ~/test`&quot; != &quot;&quot; ]]; do</span><br><span class="line">  ls | head -2 | while read f; do </span><br><span class="line">    mv $f ~/test1</span><br><span class="line">  done</span><br><span class="line">done</span><br><span class="line">echo &quot;OVER...&quot;</span><br><span class="line"></span><br><span class="line">##最终脚本</span><br><span class="line">startT=$(date +%s)</span><br><span class="line">cd /home/admin/md5id_20160601/data/md5_id</span><br><span class="line">while [[ ! -d /home/admin/md5id_20160601/data/md5_id &amp;&amp;  &quot;`ls -A /home/admin/md5id_20160601/data/md5_id`&quot; != &quot;&quot; ]]; do</span><br><span class="line">  echo &quot;......&quot;</span><br><span class="line">  start=$(date +%s)</span><br><span class="line">  ls | cut -d&apos;-&apos; -f-4 | uniq | head -5 | while read f; do</span><br><span class="line">    cfile=&quot;$f-*&quot;</span><br><span class="line">    echo $cfile</span><br><span class="line">    mv $cfile /home/admin/cassandra/data/md5/md5_id-f88d3930345811e694a62bcdca057dae/</span><br><span class="line">  done</span><br><span class="line">  nodetool -h 192.168.47.202 refresh md5 md5_id</span><br><span class="line">  end=$(date +%s)</span><br><span class="line">  time=$(( $end - $start ))</span><br><span class="line">  echo &quot;耗时:$time&quot;</span><br><span class="line">done</span><br><span class="line">echo &quot;OVER...&quot;</span><br><span class="line">endT=$(date +%s)</span><br><span class="line">timeT=$(( $endT - $startT ))</span><br><span class="line">echo &quot;Total耗时:$timeT&quot;</span><br></pre></td></tr></table></figure>
<p>ONLY ONE SHELL: IF RUN TOO LONG, JUST <code>CTRL+z, bg, jobs</code>:  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /home/admin/md5id_20160601/data/md5_id</span><br><span class="line">ls | cut -d&apos;-&apos; -f-4 | uniq | while read f; do echo &quot;batch $f&quot;; mv $f-* /home/admin/cassandra/data/md5/md5_id-f88d3930345811e694a62bcdca057dae/; nodetool -h 192.168.47.202 refresh md5 md5_id; done</span><br></pre></td></tr></table></figure>
<h3 id="文件数过多">文件数过多</h3><p>大批量同时进行，报错生成hs_err_pid9998.log</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line"># There is insufficient memory for the Java Runtime Environment to continue.</span><br><span class="line"># Native memory allocation (malloc) failed to allocate 350224384 bytes for committing reserved memory.</span><br><span class="line"># Possible reasons:</span><br><span class="line">#   The system is out of physical RAM or swap space</span><br><span class="line">#   In 32 bit mode, the process size limit was hit</span><br><span class="line"># Possible solutions:</span><br><span class="line">#   Reduce memory load on the system</span><br><span class="line">#   Increase physical memory or swap space</span><br><span class="line">#   Check if swap backing store is full</span><br><span class="line">#   Use 64 bit Java on a 64 bit OS</span><br><span class="line">#   Decrease Java heap size (-Xmx/-Xms)</span><br><span class="line">#   Decrease number of Java threads</span><br><span class="line">#   Decrease Java thread stack sizes (-Xss)</span><br><span class="line">#   Set larger code cache with -XX:ReservedCodeCacheSize=</span><br><span class="line"># This output file may be truncated or incomplete.</span><br><span class="line">#</span><br><span class="line">#  Out of Memory Error (os_linux.cpp:2726), pid=9998, tid=140593796617984</span><br><span class="line">#</span><br><span class="line"># JRE version:  (7.0_51-b13) (build )</span><br><span class="line"># Java VM: Java HotSpot(TM) 64-Bit Server VM (24.51-b03 mixed mode linux-amd64 compressed oops)</span><br><span class="line"># Failed to write core dump. Core dumps have been disabled. To enable core dumping, try &quot;ulimit -c unlimited&quot; before starting Java again</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line">---------------  T H R E A D  ---------------</span><br><span class="line"></span><br><span class="line">Current thread (0x00007fde84009800):  JavaThread &quot;Unknown thread&quot; [_thread_in_vm, id=10000, stack(0x00007fde8b3e1000,0x00007fde8b4e2000)]</span><br><span class="line"></span><br><span class="line">Stack: [0x00007fde8b3e1000,0x00007fde8b4e2000],  sp=0x00007fde8b4e01a0,  free space=1020k</span><br><span class="line">Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)</span><br><span class="line">V  [libjvm.so+0x992f4a]  VMError::report_and_die()+0x2ea</span><br><span class="line">V  [libjvm.so+0x4931ab]  report_vm_out_of_memory(char const*, int, unsigned long, char const*)+0x9b</span><br><span class="line">V  [libjvm.so+0x81338e]  os::Linux::commit_memory_impl(char*, unsigned long, bool)+0xfe</span><br><span class="line">V  [libjvm.so+0x81383f]  os::Linux::commit_memory_impl(char*, unsigned long, unsigned long, bool)+0x4f</span><br><span class="line">V  [libjvm.so+0x813a2c]  os::pd_commit_memory(char*, unsigned long, unsigned long, bool)+0xc</span><br><span class="line">V  [libjvm.so+0x80daea]  os::commit_memory(char*, unsigned long, unsigned long, bool)+0x2a</span><br><span class="line">V  [libjvm.so+0x87fcd3]  PSVirtualSpace::expand_by(unsigned long)+0x53</span><br><span class="line">V  [libjvm.so+0x86eaf3]  PSOldGen::initialize(ReservedSpace, unsigned long, char const*, int)+0x103</span><br><span class="line">V  [libjvm.so+0x299043]  AdjoiningGenerations::AdjoiningGenerations(ReservedSpace, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long)+0x3e3</span><br><span class="line">V  [libjvm.so+0x8341e0]  ParallelScavengeHeap::initialize()+0x550</span><br><span class="line">V  [libjvm.so+0x9664ca]  Universe::initialize_heap()+0xca</span><br><span class="line">V  [libjvm.so+0x967699]  universe_init()+0x79</span><br><span class="line">V  [libjvm.so+0x5a9625]  init_globals()+0x65</span><br><span class="line">V  [libjvm.so+0x94ef8d]  Threads::create_vm(JavaVMInitArgs*, bool*)+0x1ed</span><br><span class="line">V  [libjvm.so+0x6307e4]  JNI_CreateJavaVM+0x74</span><br><span class="line">C  [libjli.so+0x2f8e]  JavaMain+0x9e</span><br></pre></td></tr></table></figure>
<p>因为内存不足，直接挂掉，日志文件中并不会有报错信息！</p>
<p>节点挂掉后，重启报错：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">ERROR 01:47:33 Exception encountered during startup</span><br><span class="line">org.apache.cassandra.io.FSReadError: java.lang.NullPointerException</span><br><span class="line">  at org.apache.cassandra.db.ColumnFamilyStore.removeUnfinishedCompactionLeftovers(ColumnFamilyStore.java:668) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:308) [apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:564) [apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:653) [apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">Caused by: java.lang.NullPointerException: null</span><br><span class="line">  at org.apache.cassandra.db.ColumnFamilyStore.removeUnfinishedCompactionLeftovers(ColumnFamilyStore.java:660) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  ... 3 common frames omitted</span><br><span class="line">FSReadError in Failed to remove unfinished compaction leftovers (file: /home/admin/cassandra/data/md5/md5_id-f88d3930345811e694a62bcdca057dae/md5-md5_id-ka-1051-Statistics.db).  See log for details.</span><br><span class="line">  at org.apache.cassandra.db.ColumnFamilyStore.removeUnfinishedCompactionLeftovers(ColumnFamilyStore.java:668)</span><br><span class="line">  at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:308)</span><br><span class="line">  at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:564)</span><br><span class="line">  at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:653)</span><br><span class="line">Caused by: java.lang.NullPointerException</span><br><span class="line">  at org.apache.cassandra.db.ColumnFamilyStore.removeUnfinishedCompactionLeftovers(ColumnFamilyStore.java:660)</span><br><span class="line">  ... 3 more</span><br><span class="line">Exception encountered during startup: java.lang.NullPointerException</span><br><span class="line"></span><br><span class="line">Polling page always armed</span><br><span class="line">Deoptimize                         4</span><br><span class="line">GenCollectForAllocation            1</span><br><span class="line">CMS_Initial_Mark                   1</span><br><span class="line">CMS_Final_Remark                   1</span><br><span class="line">EnableBiasedLocking                1</span><br><span class="line">RevokeBias                        77</span><br><span class="line">BulkRevokeBias                     5</span><br><span class="line">Exit                               1</span><br><span class="line">   15 VM operations coalesced during safepoint</span><br><span class="line">Maximum sync time   6133 ms</span><br><span class="line">Maximum vm operation time (except for Exit VM operation)    521 ms</span><br></pre></td></tr></table></figure>
<p>正常来说，一个Data文件附属多个其他组件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">正常的文件</span><br><span class="line">[admin@cass047202 md5_id-f88d3930345811e694a62bcdca057dae]$ ll md5-md5_id-ka-996-*</span><br><span class="line">-rw-rw-r--. 1 admin admin     66859 6月   2 23:06 md5-md5_id-ka-996-CompressionInfo.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 298635289 6月   2 23:06 md5-md5_id-ka-996-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin        10 6月   2 23:06 md5-md5_id-ka-996-Digest.sha1</span><br><span class="line">-rw-rw-r--. 1 admin admin        16 6月   2 23:06 md5-md5_id-ka-996-Filter.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 242118240 6月   2 23:06 md5-md5_id-ka-996-Index.db</span><br><span class="line">-rw-rw-r--. 1 admin admin      9895 6月  17 17:53 md5-md5_id-ka-996-Statistics.db</span><br><span class="line">-rw-r--r--. 1 admin admin    113248 6月  16 16:23 md5-md5_id-ka-996-Summary.db</span><br><span class="line">-rw-rw-r--. 1 admin admin        91 6月   2 23:06 md5-md5_id-ka-996-TOC.txt</span><br><span class="line"></span><br><span class="line">但是报错的这个文件只有三个，没有statics等。。。</span><br><span class="line">[admin@cass047202 md5_id-f88d3930345811e694a62bcdca057dae]$ ll md5-md5_id-ka-1051*</span><br><span class="line">-rw-rw-r--. 1 admin admin 282M 6月   1 17:56 /home/admin/cassandra/data/md5/md5_id-f88d3930345811e694a62bcdca057dae/md5-md5_id-ka-1051-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 231M 6月   1 17:56 /home/admin/cassandra/data/md5/md5_id-f88d3930345811e694a62bcdca057dae/md5-md5_id-ka-1051-Index.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 1.8M 6月  17 17:55 /home/admin/cassandra/data/md5/md5_id-f88d3930345811e694a62bcdca057dae/md5-md5_id-ka-1051-Summary.db</span><br><span class="line"></span><br><span class="line">tmp临时文件中也没有</span><br><span class="line">[admin@cass047202 md5_id-f88d3930345811e694a62bcdca057dae]$ ll | grep tmp</span><br><span class="line">-rw-rw-r--. 2 admin admin 9967157248 6月  17 18:54 md5-md5_id-tmp-ka-354-Data.db</span><br><span class="line">-rw-rw-r--. 2 admin admin 7710769152 6月  17 18:54 md5-md5_id-tmp-ka-354-Index.db</span><br><span class="line">-rw-rw-r--. 2 admin admin 1224817304 6月  17 10:01 md5-md5_id-tmp-ka-4329-Data.db</span><br><span class="line">-rw-rw-r--. 2 admin admin  950730752 6月  17 10:01 md5-md5_id-tmp-ka-4329-Index.db</span><br><span class="line">-rw-rw-r--. 1 admin admin          0 6月  17 18:54 md5-md5_id-tmp-ka-48053-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin          0 6月  17 18:54 md5-md5_id-tmp-ka-48053-Index.db</span><br><span class="line">-rw-rw-r--. 2 admin admin 9049241296 6月  17 18:54 md5-md5_id-tmp-ka-526-Data.db</span><br><span class="line">-rw-rw-r--. 2 admin admin 6999441408 6月  17 18:54 md5-md5_id-tmp-ka-526-Index.db</span><br><span class="line">-rw-rw-r--. 2 admin admin 9967157248 6月  17 18:54 md5-md5_id-tmplink-ka-354-Data.db</span><br><span class="line">-rw-rw-r--. 2 admin admin 7710769152 6月  17 18:54 md5-md5_id-tmplink-ka-354-Index.db</span><br><span class="line">-rw-rw-r--. 2 admin admin 1224817304 6月  17 10:01 md5-md5_id-tmplink-ka-4329-Data.db</span><br><span class="line">-rw-rw-r--. 2 admin admin  950730752 6月  17 10:01 md5-md5_id-tmplink-ka-4329-Index.db</span><br><span class="line">-rw-rw-r--. 2 admin admin 9049241296 6月  17 18:54 md5-md5_id-tmplink-ka-526-Data.db</span><br><span class="line">-rw-rw-r--. 2 admin admin 6999441408 6月  17 18:54 md5-md5_id-tmplink-ka-526-Index.db</span><br></pre></td></tr></table></figure>
<p>删除这些文件后， 重启没有问题，但是查询时报错：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">WARN  [SharedPool-Worker-52] 2016-06-19 10:23:30,376 AbstractTracingAwareExecutorService.java:169 - Uncaught exception on thread Thread[SharedPool-Worker-52,5,main]: &#123;&#125;</span><br><span class="line">java.lang.RuntimeException: java.lang.RuntimeException: java.io.FileNotFoundException: /home/admin/cassandra/data/md5/md5_id-f88d3930345811e694a62bcdca057dae/md5-md5_id-ka-139-Data.db (打开的文件过&gt;多)</span><br><span class="line">        at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2244) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_51]</span><br><span class="line">        at org.apache.cassandra.concurrent.AbstractTracingAwareExecutorService$FutureTask.run(AbstractTracingAwareExecutorService.java:164) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) [apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]</span><br><span class="line">Caused by: java.lang.RuntimeException: java.io.FileNotFoundException: /home/admin/cassandra/data/md5/md5_id-f88d3930345811e694a62bcdca057dae/md5-md5_id-ka-139-Data.db (打开的文件过多)</span><br><span class="line">        at org.apache.cassandra.io.compress.CompressedRandomAccessReader.open(CompressedRandomAccessReader.java:52) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.util.CompressedPoolingSegmentedFile.createReader(CompressedPoolingSegmentedFile.java:85) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.sstable.SSTableReader.openDataReader(SSTableReader.java:2075) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.sstable.SSTableScanner.&lt;init&gt;(SSTableScanner.java:84) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.sstable.SSTableScanner.getScanner(SSTableScanner.java:63) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.sstable.SSTableReader.getScanner(SSTableReader.java:1859) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.db.RowIteratorFactory.getIterator(RowIteratorFactory.java:67) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.db.ColumnFamilyStore.getSequentialIterator(ColumnFamilyStore.java:2074) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.db.ColumnFamilyStore.getRangeSlice(ColumnFamilyStore.java:2191) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.db.RangeSliceCommand.executeLocally(RangeSliceCommand.java:132) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.service.StorageProxy$LocalRangeSliceRunnable.runMayThrow(StorageProxy.java:1567) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2241) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        ... 4 common frames omitted</span><br><span class="line">Caused by: java.io.FileNotFoundException: /home/admin/cassandra/data/md5/md5_id-f88d3930345811e694a62bcdca057dae/md5-md5_id-ka-139-Data.db (打开的文件过多)</span><br><span class="line">        at java.io.RandomAccessFile.open(Native Method) ~[na:1.7.0_51]</span><br><span class="line">        at java.io.RandomAccessFile.&lt;init&gt;(RandomAccessFile.java:241) ~[na:1.7.0_51]</span><br><span class="line">        at org.apache.cassandra.io.util.RandomAccessReader.&lt;init&gt;(RandomAccessReader.java:65) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.compress.CompressedRandomAccessReader.&lt;init&gt;(CompressedRandomAccessReader.java:70) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        at org.apache.cassandra.io.compress.CompressedRandomAccessReader.open(CompressedRandomAccessReader.java:48) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">        ... 15 common frames omitted</span><br><span class="line"></span><br><span class="line">WARN  [epollEventLoopGroup-2-1] 2016-06-19 10:23:54,839 Slf4JLogger.java:151 - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.</span><br><span class="line">java.io.IOException: Error during accept(...): 打开的文件过多</span><br><span class="line">  at io.netty.channel.epoll.Native.accept(Native Method) ~[netty-all-4.0.23.Final.jar:4.0.23.Final]</span><br><span class="line">  at io.netty.channel.epoll.EpollServerSocketChannel$EpollServerSocketUnsafe.epollInReady(EpollServerSocketChannel.java:102) ~[netty-all-4.0.23.Final.jar:4.0.23.Final]</span><br><span class="line">  at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:326) [netty-all-4.0.23.Final.jar:4.0.23.Final]</span><br><span class="line">  at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:264) [netty-all-4.0.23.Final.jar:4.0.23.Final]</span><br><span class="line">  at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116) [netty-all-4.0.23.Final.jar:4.0.23.Final]</span><br><span class="line">  at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137) [netty-all-4.0.23.Final.jar:4.0.23.Final]</span><br><span class="line">  at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]</span><br></pre></td></tr></table></figure>
<p>文件夹数过多：–&gt;生成时确保每个文件大点，比如1G</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[admin@cass047202 md5_id-f88d3930345811e694a62bcdca057dae]$ ll -rth | grep Data | wc -l</span><br><span class="line">2127</span><br><span class="line">[admin@cass047202 md5_id-f88d3930345811e694a62bcdca057dae]$ ll -rth | grep Data | head</span><br><span class="line">-rw-rw-r--. 1 admin admin 281M 6月   1 11:20 md5-md5_id-ka-4225-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 282M 6月   1 11:21 md5-md5_id-ka-46880-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 285M 6月   1 11:22 md5-md5_id-ka-632-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 284M 6月   1 11:23 md5-md5_id-ka-47652-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 281M 6月   1 11:25 md5-md5_id-ka-3954-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 287M 6月   1 11:26 md5-md5_id-ka-47131-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 281M 6月   1 11:27 md5-md5_id-ka-1002-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 281M 6月   1 11:28 md5-md5_id-ka-491-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 286M 6月   1 11:29 md5-md5_id-ka-210-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 281M 6月   1 11:30 md5-md5_id-ka-43627-Data.db</span><br></pre></td></tr></table></figure>
<h3 id="导入数据后，用refresh">导入数据后，用refresh</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">[admin@cass047202 cassandra]$ cqlsh 192.168.47.202</span><br><span class="line">Connected to forseti_cluster at 192.168.47.202:9042.</span><br><span class="line">[cqlsh 5.0.1 | Cassandra 2.1.13 | CQL spec 3.2.1 | Native protocol v3]</span><br><span class="line">Use HELP for help.</span><br><span class="line">cqlsh&gt; use data;</span><br><span class="line">cqlsh:data&gt; select * from md5_id limit 1;</span><br><span class="line">Warning: schema version mismatch detected, which might be caused by DOWN nodes; if this is not the case, check the schema versions of your nodes in system.local and system.peers.</span><br><span class="line">Schema metadata was not refreshed. See log for details.</span><br><span class="line">cqlsh:data&gt; quit</span><br><span class="line">[admin@cass047202 cassandra]$ cqlsh 192.168.47.202</span><br><span class="line">Connection error: (&apos;Unable to connect to any servers&apos;, &#123;&apos;192.168.47.202&apos;: OperationTimedOut(&apos;errors=None, last_host=None&apos;,)&#125;)</span><br><span class="line">[admin@cass047202 cassandra]$ nodetool status</span><br><span class="line">--  Address         Load       Tokens  Owns    Host ID                               Rack</span><br><span class="line">UN  192.168.47.206  802.88 GB  256     ?       75f42842-e3ac-4bbe-947d-6b7537a521da  RAC1</span><br><span class="line">UN  192.168.47.222  670.08 GB  256     ?       1cc2c236-8def-4f2b-8149-28d591fc6b05  RAC1</span><br><span class="line">UN  192.168.47.204  627.63 GB  256     ?       91ad3d42-4207-46fe-8188-34c3f0b2dbd2  RAC1</span><br><span class="line">UN  192.168.47.221  677.56 GB  256     ?       87e100ed-85c4-44cb-9d9f-2d602d016038  RAC1</span><br><span class="line">UN  192.168.47.205  724.58 GB  256     ?       ac6313c8-e0b5-463b-8f90-55dc0f59e476  RAC1</span><br><span class="line">UN  192.168.47.202  1.72 TB    256     ?       abaa0cbc-09d3-4990-8698-ff4d2f2bb4f7  RAC1</span><br><span class="line">UN  192.168.47.203  1.01 TB    256     ?       19b0b9cc-cad2-4b61-8da6-95423fe94af8  RAC1</span><br><span class="line">UN  192.168.47.224  739.47 GB  256     ?       27e84abe-fb06-47ff-8861-130767ee006b  RAC1</span><br><span class="line">UN  192.168.47.225  677.46 GB  256     ?       216c67cf-de7d-4190-9d0d-441fc16a7f71  RAC1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">select key,bootstrapped,broadcast_address,cluster_name,cql_version,data_center,gossip_generation,host_id,listen_address,native_protocol_version,partitioner,</span><br><span class="line">    rack,release_version,rpc_address,schema_version,thrift_version from system.local;</span><br><span class="line"></span><br><span class="line"> key   | bootstrapped | broadcast_address | cluster_name    | cql_version | data_center | gossip_generation | host_id                              | listen_address | native_protocol_version |  rack | release_version | rpc_address    | schema_version                       | thrift_version</span><br><span class="line">-------+--------------+-------------------+-----------------+-------------+-------------+-------------------+--------------------------------------+----------------+-------------------------+-------+-----------------+----------------+--------------------------------------+----------------</span><br><span class="line"> local |    COMPLETED |    192.168.47.203 | forseti_cluster |       3.2.1 |         DC1 |        1464055043 | 19b0b9cc-cad2-4b61-8da6-95423fe94af8 | 192.168.47.203 |                       3 |  RAC1 |          2.1.13 | 192.168.47.203 | 73e0e7c4-03b1-3db6-8967-d7c0144faa5c |        19.39.0</span><br><span class="line"></span><br><span class="line">    select peer,data_center,host_id,preferred_ip,rack,release_version,rpc_address,schema_version from system.peers;</span><br><span class="line"> peer           | data_center | host_id                              | preferred_ip | rack | release_version | rpc_address    | schema_version</span><br><span class="line">----------------+-------------+--------------------------------------+--------------+------+-----------------+----------------+--------------------------------------</span><br><span class="line"> 192.168.47.205 |         DC1 | ac6313c8-e0b5-463b-8f90-55dc0f59e476 |         null | RAC1 |          2.1.13 | 192.168.47.205 | 73e0e7c4-03b1-3db6-8967-d7c0144faa5c</span><br><span class="line"> 192.168.47.221 |         DC1 | 87e100ed-85c4-44cb-9d9f-2d602d016038 |         null | RAC1 |          2.1.13 | 192.168.47.221 | 73e0e7c4-03b1-3db6-8967-d7c0144faa5c</span><br><span class="line"> 192.168.47.202 |         DC1 | abaa0cbc-09d3-4990-8698-ff4d2f2bb4f7 |         null | RAC1 |          2.1.13 | 192.168.47.202 | 73e0e7c4-03b1-3db6-8967-d7c0144faa5c</span><br><span class="line"> 192.168.47.225 |         DC1 | 216c67cf-de7d-4190-9d0d-441fc16a7f71 |         null | RAC1 |          2.1.13 | 192.168.47.225 | 73e0e7c4-03b1-3db6-8967-d7c0144faa5c</span><br><span class="line"> 192.168.47.224 |         DC1 | 27e84abe-fb06-47ff-8861-130767ee006b |         null | RAC1 |          2.1.13 | 192.168.47.224 | 73e0e7c4-03b1-3db6-8967-d7c0144faa5c</span><br><span class="line"> 192.168.47.204 |         DC1 | 91ad3d42-4207-46fe-8188-34c3f0b2dbd2 |         null | RAC1 |          2.1.13 | 192.168.47.204 | 73e0e7c4-03b1-3db6-8967-d7c0144faa5c</span><br><span class="line"> 192.168.47.206 |         DC1 | 75f42842-e3ac-4bbe-947d-6b7537a521da |         null | RAC1 |          2.1.13 | 192.168.47.206 | 73e0e7c4-03b1-3db6-8967-d7c0144faa5c</span><br><span class="line"> 192.168.47.222 |         DC1 | 1cc2c236-8def-4f2b-8149-28d591fc6b05 |         null | RAC1 |          2.1.13 | 192.168.47.222 | 73e0e7c4-03b1-3db6-8967-d7c0144faa5c</span><br><span class="line"></span><br><span class="line">[admin@cass047202 cassandra]$ nodetool describecluster</span><br><span class="line">Cluster Information:</span><br><span class="line">  Name: forseti_cluster</span><br><span class="line">  Snitch: org.apache.cassandra.locator.DynamicEndpointSnitch</span><br><span class="line">  Partitioner: org.apache.cassandra.dht.Murmur3Partitioner</span><br><span class="line">  Schema versions:</span><br><span class="line">    73e0e7c4-03b1-3db6-8967-d7c0144faa5c: [192.168.47.206, 192.168.47.222, 192.168.47.221, 192.168.47.204, 192.168.47.205, 192.168.47.202, 192.168.47.203, 192.168.47.224, 192.168.47.225]</span><br><span class="line"></span><br><span class="line">[admin@cass047202 cassandra]$ nodetool -h 192.168.47.203 describecluster</span><br><span class="line">Cluster Information:</span><br><span class="line">  Name: forseti_cluster</span><br><span class="line">  Snitch: org.apache.cassandra.locator.DynamicEndpointSnitch</span><br><span class="line">  Partitioner: org.apache.cassandra.dht.Murmur3Partitioner</span><br><span class="line">  Schema versions:</span><br><span class="line">    73e0e7c4-03b1-3db6-8967-d7c0144faa5c: [192.168.47.206, 192.168.47.222, 192.168.47.221, 192.168.47.204, 192.168.47.205, 192.168.47.203, 192.168.47.224, 192.168.47.225]</span><br><span class="line">    UNREACHABLE: [192.168.47.202] </span><br><span class="line"></span><br><span class="line">[admin@cass047203 ~]$ nodetool status</span><br><span class="line">--  Address         Load       Tokens  Owns    Host ID                               Rack</span><br><span class="line">UN  192.168.47.205  724.58 GB  256     ?       ac6313c8-e0b5-463b-8f90-55dc0f59e476  RAC1</span><br><span class="line">DN  192.168.47.202  1.72 TB    256     ?       abaa0cbc-09d3-4990-8698-ff4d2f2bb4f7  RAC1</span><br><span class="line">UN  192.168.47.203  1.01 TB    256     ?       19b0b9cc-cad2-4b61-8da6-95423fe94af8  RAC1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">INFO  01:50:05 Harmless error reading saved cache /home/admin/cassandra/saved_caches/KeyCache-ba.db</span><br><span class="line">java.lang.RuntimeException: Cache schema version b48bf712-fad2-3951-bb18-aa178e738b30 does not match current schema version 73e0e7c4-03b1-3db6-8967-d7c0144faa5c</span><br><span class="line">  at org.apache.cassandra.cache.AutoSavingCache.loadSaved(AutoSavingCache.java:188) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.cache.AutoSavingCache$3.call(AutoSavingCache.java:148) [apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.cache.AutoSavingCache$3.call(AutoSavingCache.java:144) [apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_51]</span><br><span class="line">  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_51]</span><br><span class="line">  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_51]</span><br><span class="line">  at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">只要不操作：select * from md5_id limit 1;  其他节点就不会认为202DN掉了。</span><br></pre></td></tr></table></figure>
<h3 id="通过增大内存来增大sstable大小（内存不足）">通过增大内存来增大sstable大小（内存不足）</h3><p>内存为512M，每个数据文件和索引文件的大小都差不多（281M，231M）。能不能减少Index文件的占用？？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[admin@cass047203 md5_id]$ ll -rth|grep Data | wc -l</span><br><span class="line">2576</span><br><span class="line">[admin@cass047203 md5_id]$ cd ..</span><br><span class="line">[admin@cass047203 data]$ du -sh *</span><br><span class="line">1.3T    md5_id</span><br><span class="line">[admin@cass047204 md5_id]$ ll data-md5_id-ka-2010-* -h</span><br><span class="line">-rw-rw-r--. 1 admin admin  66K 6月   2 22:26 data-md5_id-ka-2010-CompressionInfo.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 281M 6月   2 22:26 data-md5_id-ka-2010-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin   10 6月   2 22:26 data-md5_id-ka-2010-Digest.sha1</span><br><span class="line">-rw-rw-r--. 1 admin admin   16 6月   2 22:26 data-md5_id-ka-2010-Filter.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 231M 6月   2 22:26 data-md5_id-ka-2010-Index.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 9.7K 6月   2 22:26 data-md5_id-ka-2010-Statistics.db</span><br><span class="line">-rw-rw-r--. 1 admin admin   91 6月   2 22:26 data-md5_id-ka-2010-TOC.txt</span><br></pre></td></tr></table></figure>
<p>内存为2048，直接在运行Cassnadra的线上跑</p>
<p>nohup java -cp guava-19.0.jar:rainbow-table-1.0.0-SNAPSHOT-jar-with-dependencies.jar \<br>cn.fraudmetrix.vulcan.rainbowtable.sstable.BulkLoadIdCard -table md5_id -partition 13 -memory 1024 &gt; rainbow-table-idcard.log.1 2&gt;&amp;1 &amp;</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: GC overhead limit exceeded</span><br><span class="line">    at java.util.Arrays.copyOfRange(Arrays.java:2694)</span><br><span class="line">    at java.lang.String.&lt;init&gt;(String.java:203)</span><br><span class="line">    at java.lang.StringBuilder.toString(StringBuilder.java:405)</span><br><span class="line">    at cn.fraudmetrix.vulcan.rainbowtable.util.AbstractGenData.last1(AbstractGenData.java:220)</span><br><span class="line">    at cn.fraudmetrix.vulcan.rainbowtable.util.AbstractGenData.genIdCardOneProvince(AbstractGenData.java:82)</span><br><span class="line">    at cn.fraudmetrix.vulcan.rainbowtable.util.AbstractGenData.genIdCard(AbstractGenData.java:63)</span><br><span class="line">    at cn.fraudmetrix.vulcan.rainbowtable.util.AbstractGenData.genData(AbstractGenData.java:55)</span><br><span class="line">    at cn.fraudmetrix.vulcan.rainbowtable.sstable.BulkLoadIdCard.main(BulkLoadIdCard.java:116)</span><br><span class="line"></span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000632f80000, 436731904, 0) failed; error=&apos;无法分配内存&apos; (errno=12)</span><br><span class="line">#</span><br><span class="line"># There is insufficient memory for the Java Runtime Environment to continue.</span><br><span class="line"># Native memory allocation (malloc) failed to allocate 436731904 bytes for committing reserved memory.</span><br><span class="line"># An error report file with more information is saved as:</span><br><span class="line"># /home/admin/hs_err_pid33681.log</span><br></pre></td></tr></table></figure>
<p>因为Cassandra本身占用了很大内存，运行sstable的程序内存不足，可以先停掉Cassandra。为了不影响线上，只能停掉一个节点，生成完数据，再停另一个节点。。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[admin@cass047225 ~]$ free -h</span><br><span class="line">             total       used       free     shared    buffers     cached</span><br><span class="line">Mem:           31G        30G       470M       716K        30M       3.8G</span><br><span class="line">-/+ buffers/cache:        27G       4.3G</span><br><span class="line">Swap:           0B         0B         0B</span><br></pre></td></tr></table></figure>
<p>设置内存大小，并使用G1，刚开始还好，过了一段时间，控制台打印的WriteCount几乎不动了，查看GC，这个时候会发现OC=OU。只能等FGC完成后，才有可能继续打印，<br>不过没过多久，这种情况会继续下去。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">nohup java -Xmx16g -Xms16g -XX:+UseG1GC -XX:MaxGCPauseMillis=1000 -cp guava-19.0.jar:rainbow-table-1.0.0-SNAPSHOT-jar-with-dependencies.jar \</span><br><span class="line">cn.fraudmetrix.vulcan.rainbowtable.sstable.BulkLoadIdCard -table md5_id -partition $myRange -memory 4096 &gt; rainbow-table-idcard.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line">jstat -gc -h 10 `jps | grep BulkLoadIdCard |awk &apos;&#123;print $1&#125;&apos;` 1000 | \</span><br><span class="line">awk &apos;&#123;printf(&quot;%10s\t%10s\t%10s\t%10s\t%10s\t%10s\t%10s\t%10s\t%10s\t%10s\t\n&quot;,$1,$5,$3,$4,$6,$8,$11,$12,$13,$14)&#125;&apos;</span><br><span class="line"></span><br><span class="line">[admin@cass047225 ~]$ jstat -gc -h 10 `jps | grep BulkLoadIdCard |awk &apos;&#123;print $1&#125;&apos;` 1000</span><br><span class="line"> S0C    S1C      S0U   S1U      EC        EU       OC         OU         PC       PU         YGC  YGCT    FGC     FGCT     GCT</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 4603904.0 507904.0 12066816.0 10133504.0 16384.0 12784.5     52   30.335   0      0.000   30.335</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 4603904.0 1138688.0 12066816.0 10133504.0 16384.0 12784.5     52   30.335   0      0.000   30.335</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 4603904.0 2007040.0 12066816.0 10133504.0 16384.0 12784.5     52   30.335   0      0.000   30.335</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 4603904.0 2883584.0 12066816.0 10133504.0 16384.0 12784.5     52   30.335   0      0.000   30.335</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 4603904.0 3702784.0 12066816.0 10133504.0 16384.0 12784.5     52   30.335   0      0.000   30.335</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 4603904.0 4333568.0 12066816.0 10133504.0 16384.0 12784.5     52   30.335   0      0.000   30.335</span><br><span class="line"> 0.0   425984.0  0.0   425984.0 4333568.0 229376.0 12017664.0 10129408.0 16384.0 12784.5     53   30.975   0      0.000   30.975</span><br><span class="line"> 0.0   425984.0  0.0   425984.0 4333568.0 942080.0 12017664.0 10129408.0 16384.0 12784.5     53   30.975   0      0.000   30.975</span><br><span class="line"> 0.0   425984.0  0.0   425984.0 4333568.0 1433600.0 12017664.0 10129408.0 16384.0 12784.5     53   30.975   0      0.000   30.975</span><br><span class="line"> 0.0   425984.0  0.0   425984.0 4333568.0 1785856.0 12017664.0 10129408.0 16384.0 12784.5     54   30.975   0      0.000   30.975</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 4128768.0 245760.0 12541952.0 10579968.0 16384.0 12784.5     54   32.056   0      0.000   32.056</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 4128768.0 1064960.0 12541952.0 10579968.0 16384.0 12784.5     54   32.056   0      0.000   32.056</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 4128768.0 1671168.0 12541952.0 10579968.0 16384.0 12784.5     54   32.056   0      0.000   32.056</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 4128768.0 2433024.0 12541952.0 10579968.0 16384.0 12784.5     54   32.056   0      0.000   32.056</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 4128768.0 3170304.0 12541952.0 10579968.0 16384.0 12784.5     54   32.056   0      0.000   32.056</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 4128768.0 3833856.0 12541952.0 10579968.0 16384.0 12784.5     54   32.056   0      0.000   32.056</span><br><span class="line"> 0.0   409600.0  0.0   409600.0 3457024.0 147456.0 12910592.0 10575872.0 16384.0 12784.5     55   32.641   0      0.000   32.641</span><br><span class="line"> 0.0   409600.0  0.0   409600.0 3457024.0 655360.0 12910592.0 10575872.0 16384.0 12784.5     55   32.641   0      0.000   32.641</span><br><span class="line"> 0.0   409600.0  0.0   409600.0 3457024.0 1269760.0 12910592.0 10575872.0 16384.0 12784.5     55   32.641   0      0.000   32.641</span><br><span class="line"> 0.0   409600.0  0.0   409600.0 3457024.0 1900544.0 12910592.0 10575872.0 16384.0 12784.5     55   32.641   0      0.000   32.641</span><br><span class="line"></span><br><span class="line">0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770048.5 16384.0 12784.5    133   65.236   2     61.382  126.618</span><br><span class="line"> S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770048.5 16384.0 12784.5    133   65.236   2     61.382  126.618</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770048.5 16384.0 12784.5    133   65.236   2     61.382  126.618</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770048.5 16384.0 12784.5    133   65.236   2     61.382  126.618</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770048.5 16384.0 12784.5    133   65.236   2     61.382  126.618</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770048.5 16384.0 12784.5    133   65.236   2     61.382  126.618</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770048.5 16384.0 12784.5    133   65.236   2     61.382  126.618</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770048.5 16384.0 12784.5    133   65.236   2     61.382  126.618</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770048.5 16384.0 12784.5    133   65.236   2     61.382  126.618</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770048.5 16384.0 12784.5    133   65.236   2     61.382  126.618</span><br><span class="line"> 0.0    0.0    0.0    0.0   884736.0 450560.0 15892480.0 15681440.2 16384.0 12784.5    133   65.236   2    122.783  188.019</span><br><span class="line"> S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT</span><br><span class="line"> 0.0   57344.0  0.0   57344.0 827392.0 376832.0 15892480.0 15680244.2 16384.0 12784.5    134   65.394   2    122.783  188.177</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 778240.0 163840.0 15892480.0 15701920.2 16384.0 12784.5    135   65.691   2    122.783  188.474</span><br><span class="line"> 0.0   106496.0  0.0   106496.0 778240.0 729088.0 15892480.0 15701920.2 16384.0 12784.5    136   65.691   2    122.783  188.474</span><br><span class="line"> 0.0   73728.0  0.0   73728.0 811008.0 606208.0 15892480.0 15796935.3 16384.0 12784.5    136   66.004   2    122.783  188.786</span><br><span class="line"> 0.0   65536.0  0.0   65536.0 819200.0 532480.0 15892480.0 15869856.2 16384.0 12784.5    137   66.209   2    122.783  188.992</span><br><span class="line"> 0.0   65536.0  0.0   65536.0 819200.0 770048.0 15892480.0 15869856.2 16384.0 12784.5    138   66.209   2    122.783  188.992</span><br><span class="line"> 0.0   65536.0  0.0   65536.0 819200.0 770048.0 15892480.0 15869856.2 16384.0 12784.5    138   66.209   2    122.783  188.992</span><br><span class="line"> 0.0   65536.0  0.0   65536.0 352256.0 352256.0 16359424.0 16353184.2 16384.0 12784.5    139   67.845   2    122.783  190.628</span><br><span class="line"> 0.0   65536.0  0.0   65536.0 352256.0 352256.0 16359424.0 16353184.2 16384.0 12784.5    139   67.845   2    122.783  190.628</span><br><span class="line"> 0.0   65536.0  0.0   65536.0 352256.0 352256.0 16359424.0 16353184.2 16384.0 12784.5    139   67.845   2    122.783  190.628</span><br><span class="line"> S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT</span><br><span class="line"> 0.0   65536.0  0.0   65536.0 352256.0 352256.0 16359424.0 16353184.2 16384.0 12784.5    139   67.845   2    122.783  190.628</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770976.2 16384.0 12784.5    140   71.751   3    122.783  194.533</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770976.2 16384.0 12784.5    140   71.751   3    122.783  194.533</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770976.2 16384.0 12784.5    140   71.751   3    122.783  194.533</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770976.2 16384.0 12784.5    140   71.751   3    122.783  194.533</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770976.2 16384.0 12784.5    140   71.751   3    122.783  194.533</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770976.2 16384.0 12784.5    140   71.751   3    122.783  194.533</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770976.2 16384.0 12784.5    140   71.751   3    122.783  194.533</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770976.2 16384.0 12784.5    140   71.751   3    122.783  194.533</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770976.2 16384.0 12784.5    140   71.751   3    122.783  194.533</span><br><span class="line"> S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770976.2 16384.0 12784.5    140   71.751   3    122.783  194.533</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770976.2 16384.0 12784.5    140   71.751   3    122.783  194.533</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16770976.2 16384.0 12784.5    140   71.751   3    122.783  194.533</span><br><span class="line"> 0.0    0.0    0.0    0.0   811008.0 385024.0 15966208.0 15960817.7 16384.0 12784.5    140   71.751   3    173.703  245.454</span><br><span class="line"> 0.0    0.0    0.0    0.0   811008.0 811008.0 15966208.0 15960817.7 16384.0 12784.5    141   71.751   3    173.703  245.454</span><br><span class="line"> 0.0    0.0    0.0    0.0   811008.0 811008.0 15966208.0 15960817.7 16384.0 12784.5    141   71.751   3    173.703  245.454</span><br><span class="line"> 0.0    0.0    0.0    0.0   286720.0 155648.0 16490496.0 16485105.7 16384.0 12784.5    141   73.666   3    173.703  247.369</span><br><span class="line"> 0.0    0.0    0.0    0.0   286720.0 286720.0 16490496.0 16485105.7 16384.0 12784.5    142   73.666   3    173.703  247.369</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16771825.7 16384.0 12784.5    143   75.252   4    173.703  248.955</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16771825.7 16384.0 12784.5    143   75.252   4    173.703  248.955</span><br><span class="line"> 0.0    0.0    0.0    0.0     0.0      0.0    16777216.0 16771825.7 16384.0 12784.5    143   75.252   4    173.703  248.955</span><br><span class="line"> S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT</span><br></pre></td></tr></table></figure>
<p>为什么FGC之后，几乎马上又重现？实际上内存中的数据还没有刷写到磁盘上，当然这部分内存就不能回收了。这就导致FGC实际上并没有回收多少内存。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[admin@cass047225 ~]$ tail -f rainbow-table-idcard.log</span><br><span class="line">WriteCount:65531,SAMPLE:92FF12AE4A27EC01692DC05F041ECF44,13010219701011217X</span><br><span class="line">[admin@cass047225 ~]$ cat rainbow-table-idcard.log | grep &quot;WriteCount&quot; | wc -l</span><br><span class="line">515</span><br><span class="line">[admin@cass047225 ~]$ du -sh *</span><br><span class="line">12K md5_id20160622</span><br></pre></td></tr></table></figure>
<p>写了将近515<em>65531=3000万，还是没有生成一个sstable文件。 因为buffer size设置为4G，只有Memtable达到4G时，才会刷写一个sstable文件。<br>一条记录”92FF12AE4A27EC01692DC05F041ECF44,13010219701011217X”只有52个字符(52byte)，再加上写sstable还有其他组件比如index，<br>就算一条记录=1KB=1024byte，1万记录=10000kb=10M, 3000万=3000</em>10M=300G  </p>
<p>以buffer=4G为例，总内存=4G=4000M=4000M<em>1000KB=4000000KB=400万KB,如果内存中只以一条记录=52byte计算。<br>总共可以存放最大记录数=`400万</em>1000byte/50byte=400万*20=800万`，但是上面将近3000万，为什么没有结果？  </p>
<p>唯一的办法是减少buffer大小到2G/1G…。通过让内存中的数据尽快刷写到磁盘上！释放掉内存中的数据。<br>否则数据源源不断写到内存中，无法及时释放，即使FGC也无能为力。</p>
<p>运行过程，查看堆栈信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">[admin@cass047225 md5_id]$ jps -lm</span><br><span class="line">7594 cn.fraudmetrix.vulcan.rainbowtable.sstable.BulkLoadIdCard -table md5_id -partition 13,14,15,21 -memory 2048</span><br><span class="line">[admin@cass047225 md5_id]$ top -Hp 7594</span><br><span class="line">top - 10:19:32 up 211 days, 15:36,  3 users,  load average: 2.77, 3.62, 3.68</span><br><span class="line">Tasks:  34 total,   4 running,  30 sleeping,   0 stopped,   0 zombie</span><br><span class="line">Cpu(s):  8.6%us,  3.0%sy, 17.3%ni, 70.6%id,  0.2%wa,  0.0%hi,  0.3%si,  0.0%st</span><br><span class="line">Mem:  32794428k total, 32493800k used,   300628k free,    31944k buffers</span><br><span class="line">Swap:        0k total,        0k used,        0k free, 10400404k cached</span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND</span><br><span class="line"> 7625 admin     20   0 21.8g  19g  16m R 101.7 63.6  17:55.41 java</span><br><span class="line"> 7603 admin     20   0 21.8g  19g  16m R 99.7 63.6  28:13.74 java</span><br><span class="line"> 7627 admin     20   0 21.8g  19g  16m R 99.7 63.6  13:13.43 java</span><br><span class="line"> 7628 admin     20   0 21.8g  19g  16m R 99.7 63.6  13:13.73 java</span><br><span class="line"></span><br><span class="line">[admin@cass047225 ~]$ ./show-busy-javathreads.sh</span><br><span class="line">Busy(73.4%) thread(7603/0x1db3) stack of java process(7594) under user(admin):</span><br><span class="line">&quot;main&quot; prio=10 tid=0x00007f7468009000 nid=0x1db3 runnable [0x00007f7471aa9000]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line">  at java.util.Arrays.copyOf(Arrays.java:2271)</span><br><span class="line">  at java.lang.StringCoding.safeTrim(StringCoding.java:79)</span><br><span class="line">  at java.lang.StringCoding.encode(StringCoding.java:365)</span><br><span class="line">  at java.lang.String.getBytes(String.java:939)</span><br><span class="line">  at org.apache.cassandra.utils.ByteBufferUtil.bytes(ByteBufferUtil.java:225)</span><br><span class="line">  at org.apache.cassandra.serializers.AbstractTextSerializer.serialize(AbstractTextSerializer.java:49)</span><br><span class="line">  at org.apache.cassandra.serializers.AbstractTextSerializer.serialize(AbstractTextSerializer.java:26)</span><br><span class="line">  at org.apache.cassandra.db.marshal.AbstractType.decompose(AbstractType.java:73)</span><br><span class="line">  at org.apache.cassandra.io.sstable.CQLSSTableWriter.addRow(CQLSSTableWriter.java:142)</span><br><span class="line">  at org.apache.cassandra.io.sstable.CQLSSTableWriter.addRow(CQLSSTableWriter.java:118)</span><br><span class="line">  at cn.fraudmetrix.vulcan.rainbowtable.sstable.BulkLoadIdCard.batchWrite(BulkLoadIdCard.java:55)</span><br><span class="line">  at cn.fraudmetrix.vulcan.rainbowtable.util.AbstractGenData.genIdCardOneProvince(AbstractGenData.java:86)</span><br><span class="line">  at cn.fraudmetrix.vulcan.rainbowtable.util.AbstractGenData.genIdCard(AbstractGenData.java:63)</span><br><span class="line">  at cn.fraudmetrix.vulcan.rainbowtable.util.AbstractGenData.genData(AbstractGenData.java:55)</span><br><span class="line">  at cn.fraudmetrix.vulcan.rainbowtable.sstable.BulkLoadIdCard.main(BulkLoadIdCard.java:116)</span><br><span class="line"></span><br><span class="line">Busy(46.8%) thread(7625/0x1dc9) stack of java process(7594) under user(admin):</span><br><span class="line">&quot;G1 Concurrent Refinement Thread#0&quot; prio=10 tid=0x00007f746803c800 nid=0x1dc9 runnable</span><br><span class="line"></span><br><span class="line">Busy(34.5%) thread(7628/0x1dcc) stack of java process(7594) under user(admin):</span><br><span class="line">&quot;Gang worker#1 (G1 Parallel Marking Threads)&quot; prio=10 tid=0x00007f746806b800 nid=0x1dcc runnable</span><br><span class="line"></span><br><span class="line">Busy(34.5%) thread(7627/0x1dcb) stack of java process(7594) under user(admin):</span><br><span class="line">&quot;Gang worker#0 (G1 Parallel Marking Threads)&quot; prio=10 tid=0x00007f7468069800 nid=0x1dcb runnable</span><br><span class="line"></span><br><span class="line">Busy(25.6%) thread(7688/0x1e08) stack of java process(7594) under user(admin):</span><br><span class="line">&quot;Thread-2&quot; prio=10 tid=0x00007f7469e3b000 nid=0x1e08 waiting on condition [0x00007f73f012c000]</span><br><span class="line">   java.lang.Thread.State: WAITING (parking)</span><br><span class="line">  at sun.misc.Unsafe.park(Native Method)</span><br><span class="line">  - parking to wait for  &lt;0x00000003fb131618&gt; (a java.util.concurrent.SynchronousQueue$TransferStack)</span><br><span class="line">  at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)</span><br><span class="line">  at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)</span><br><span class="line">  at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:359)</span><br><span class="line">  at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:925)</span><br><span class="line">  at org.apache.cassandra.io.sstable.SSTableSimpleUnsortedWriter$DiskWriter.run(SSTableSimpleUnsortedWriter.java:240)</span><br></pre></td></tr></table></figure>
<p>打印存活的对象占比</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[admin@cass047225 ~]$ jmap -histo:live 7594</span><br><span class="line"></span><br><span class="line"> num     #instances         #bytes  class name</span><br><span class="line">----------------------------------------------</span><br><span class="line">   1:      48953579     2,349,771,792  java.nio.HeapByteBuffer</span><br><span class="line">   2:      48959365     2,154,707,824  [B</span><br><span class="line">   3:      48953434     1566509888  org.apache.cassandra.db.BufferCell</span><br><span class="line">   4:      24476718     1370696168  [Lorg.apache.cassandra.db.Cell;</span><br><span class="line">   5:      24533905      981356200  java.util.TreeMap$Entry</span><br><span class="line">   6:      24476720      979068800  org.apache.cassandra.io.sstable.CQLSSTableWriter$BufferedWriter$1</span><br><span class="line">   7:      24476718      783254976  org.apache.cassandra.db.composites.CompoundSparseCellName</span><br><span class="line">   8:      24476720      587441280  org.apache.cassandra.dht.LongToken</span><br><span class="line">   9:      24476720      587441280  org.apache.cassandra.db.DeletionInfo</span><br><span class="line">  10:      24476719      587441256  org.apache.cassandra.db.BufferDecoratedKey</span><br><span class="line">  11:         94817        9075720  [C</span><br><span class="line">  12:         27311        3820688  &lt;constMethodKlass&gt;</span><br><span class="line">  13:         27311        3505968  &lt;methodKlass&gt;</span><br><span class="line">  14:          2349        2919216  &lt;constantPoolKlass&gt;</span><br><span class="line">  15:         94761        2274264  java.lang.String</span><br><span class="line">  16:          2349        1619680  &lt;instanceKlassKlass&gt;</span><br><span class="line">  17:          1882        1474880  &lt;constantPoolCacheKlass&gt;</span><br><span class="line">  18:         57261        1374264  java.lang.Long</span><br><span class="line">  19:         28499        1367952  org.apache.cassandra.io.sstable.IndexSummaryBuilder$ReadableBoundary</span><br></pre></td></tr></table></figure>
<p>内存缓冲区设置为2G时，运行省份13花费：69385；内存为512，花费：75597<br>2G时每个SSTable的文件大小为1G多，512M时，每个文件的大小为281M<br>只有一半的原因是Data文件和Index文件都差不多大。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">内存为512M</span><br><span class="line">[admin@cass047221 md5_id]$ ll data-md5_id-ka-1578-* -rth</span><br><span class="line">-rw-rw-r--. 1 admin admin   16 6月  24 06:23 data-md5_id-ka-1578-Filter.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 231M 6月  24 06:23 data-md5_id-ka-1578-Index.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 282M 6月  24 06:23 data-md5_id-ka-1578-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin  66K 6月  24 06:23 data-md5_id-ka-1578-CompressionInfo.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 9.7K 6月  24 06:23 data-md5_id-ka-1578-Statistics.db</span><br><span class="line">-rw-rw-r--. 1 admin admin    8 6月  24 06:23 data-md5_id-ka-1578-Digest.sha1</span><br><span class="line">-rw-rw-r--. 1 admin admin   91 6月  24 06:23 data-md5_id-ka-1578-TOC.txt</span><br><span class="line"></span><br><span class="line">内存为2G</span><br><span class="line">[admin@cass047225 md5_id]$ ll data-md5_id-ka-1-* -rth</span><br><span class="line">-rw-rw-r--. 1 admin admin   16 6月  22 09:47 data-md5_id-ka-1-Filter.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 924M 6月  22 09:47 data-md5_id-ka-1-Index.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 1.2G 6月  22 09:47 data-md5_id-ka-1-Data.db</span><br><span class="line">-rw-rw-r--. 1 admin admin 262K 6月  22 09:47 data-md5_id-ka-1-CompressionInfo.db</span><br><span class="line">-rw-rw-r--. 1 admin admin   10 6月  22 09:47 data-md5_id-ka-1-Digest.sha1</span><br><span class="line">-rw-rw-r--. 1 admin admin 9.7K 6月  22 09:47 data-md5_id-ka-1-Statistics.db</span><br><span class="line">-rw-rw-r--. 1 admin admin   91 6月  22 09:47 data-md5_id-ka-1-TOC.txt</span><br></pre></td></tr></table></figure>
<h3 id="分表？">分表？</h3><p>生成数据按照省份，对应表为md5_id_省份编号，比如md5_id_13。<br>key - value = B566B86D791DB56E4F149B42A2E84B5A,130100196303225584  </p>
<p>最终表有： md5_id_13， md5_id_14，md5_id_15… 总共有30张表<br>每张表数据量大概1000亿/30=30亿  </p>
<p>问题： 给定md5值，怎么知道要查询哪张表？<br>建立md5值和省份的对应关系？ 或者不用建立，查询时所有表依次查询</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">du -sh * | grep md5_id201606</span><br><span class="line">cat rainbow-table-idcard.log.2 | grep seconds</span><br><span class="line">cat rainbow-table-idcard.log.2 | grep WriteCount | wc -l</span><br><span class="line">ll md5_id20160623/data/md5_id | grep Data | wc -l</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>运行节点</th>
<th>省份</th>
<th>数据源个数</th>
<th>耗时(s)</th>
<th>数据占用空间</th>
<th>数据条数</th>
<th>SSTable数量</th>
<th>导入耗时(s)</th>
<th>状态</th>
</tr>
</thead>
<tbody>
<tr>
<td>192.168.47.202</td>
<td>22,23,31,32</td>
<td>156,301,32,289=778</td>
<td>29580,59443,6066,57166</td>
<td>1.1T</td>
<td>173812*65531+16516</td>
<td>2164</td>
<td>✅</td>
</tr>
<tr>
<td>192.168.47.203</td>
<td>33,34,35,36</td>
<td>230,256,201,239=926</td>
<td>38062,41404,32837,41002</td>
<td>1.3T</td>
<td>206875*65531</td>
<td>2576</td>
<td>✅</td>
</tr>
<tr>
<td>192.168.47.204</td>
<td>37,41</td>
<td>383,367</td>
<td>61807,60992</td>
</tr>
<tr>
<td>192.168.47.206</td>
<td>46,50,51</td>
<td>72,51,512=635</td>
<td>13851,10217,95683</td>
<td>885G</td>
<td>141864*65531</td>
<td>1767</td>
<td>✅</td>
</tr>
<tr>
<td>192.168.47.221</td>
<td>52,53,54</td>
<td>161,246,161=</td>
<td>20690,31109,20306</td>
<td>791G</td>
<td>126896*65531+20992=8315642768=83亿</td>
<td>1580</td>
<td>25758</td>
<td>✅✅</td>
</tr>
<tr>
<td>192.168.47.225</td>
<td>13,14,15,21</td>
<td>390,274,210,209=1083</td>
<td>69385,47905,36801,36486</td>
<td>1.5T</td>
<td></td>
<td>784</td>
<td>✅</td>
</tr>
<tr>
<td>192.168.48.168</td>
<td>61,62,63,64,65,11,12</td>
<td>231,199,70,65,172,28,23=788</td>
<td>29579,25761,9046,8602,22679,3699,3040</td>
<td>176047*65531</td>
<td>2192</td>
<td>1.1T</td>
</tr>
<tr>
<td>192.168.48.165</td>
<td>43,44,45</td>
<td>284,383,253=920</td>
<td>36764,49562,32799</td>
</tr>
</tbody>
</table>
<p>,42  ==?259</p>
<h2 id="sstableloader">sstableloader</h2><p>168 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">cd md5_id20160623 &amp;&amp; mv data md5 &amp;&amp; cd md5_id &amp;&amp; rename data md5 *</span><br><span class="line">MAX_HEAP_SIZE=&quot;256M&quot;</span><br><span class="line">MAX_HEAP_SIZE=&quot;3096M&quot;</span><br><span class="line">nohup /usr/install/cassandra/bin/sstableloader -d 192.168.47.202 /home/admin/md5_id20160623/md5/md5_id &amp; </span><br><span class="line">nohup apache-cassandra-2.1.13/bin/sstableloader -d 192.168.47.202 /home/admin/md5_id20160627/md5/md5_id &amp; </span><br><span class="line"></span><br><span class="line">Summary statistics:</span><br><span class="line">   Connections per host:         : 1</span><br><span class="line">   Total files transferred:      : 14220</span><br><span class="line">   Total bytes transferred:      : 579(gb),024(mb),927(kb),946(b)</span><br><span class="line">   Total duration (ms):          : 25758,956 = 7hour</span><br><span class="line">   Average transfer rate (MB/s): : 21</span><br><span class="line">   Peak transfer rate (MB/s):    : 21</span><br><span class="line"></span><br><span class="line">[admin@cass047202 ~]$ nodetool cfstats md5.md5_id | grep keys</span><br><span class="line">    Number of keys (estimate): 5567257543</span><br></pre></td></tr></table></figure>
<p>如果遇到节点挂掉：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[/192.168.47.222, /192.168.47.204, /192.168.47.203, /192.168.47.224]</span><br><span class="line">java.util.concurrent.ExecutionException: org.apache.cassandra.streaming.StreamException: Stream failed</span><br><span class="line">  at com.google.common.util.concurrent.AbstractFuture$Sync.getValue(AbstractFuture.java:299)</span><br><span class="line">  at com.google.common.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:286)</span><br><span class="line">  at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:116)</span><br><span class="line">  at org.apache.cassandra.tools.BulkLoader.main(BulkLoader.java:125)</span><br><span class="line">Caused by: org.apache.cassandra.streaming.StreamException: Stream failed</span><br><span class="line">  at org.apache.cassandra.streaming.management.StreamEventJMXNotifier.onFailure(StreamEventJMXNotifier.java:85)</span><br><span class="line">  at com.google.common.util.concurrent.Futures$4.run(Futures.java:1172)</span><br><span class="line">  at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)</span><br><span class="line">  at com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156)</span><br><span class="line">  at com.google.common.util.concurrent.ExecutionList.execute(ExecutionList.java:145)</span><br><span class="line">  at com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:202)</span><br><span class="line">  at org.apache.cassandra.streaming.StreamResultFuture.maybeComplete(StreamResultFuture.java:208)</span><br><span class="line">  at org.apache.cassandra.streaming.StreamResultFuture.handleSessionComplete(StreamResultFuture.java:184)</span><br><span class="line">  at org.apache.cassandra.streaming.StreamSession.closeSession(StreamSession.java:415)</span><br><span class="line">  at org.apache.cassandra.streaming.StreamSession.complete(StreamSession.java:607)</span><br><span class="line">  at org.apache.cassandra.streaming.StreamSession.messageReceived(StreamSession.java:471)</span><br><span class="line">  at org.apache.cassandra.streaming.ConnectionHandler$IncomingMessageHandler.run(ConnectionHandler.java:256)</span><br><span class="line">  at java.lang.Thread.run(Thread.java:744)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">ERROR [CompactionExecutor:19] 2016-06-29 10:06:19,266 CassandraDaemon.java:229 - Exception in thread Thread[CompactionExecutor:19,1,main]</span><br><span class="line">java.lang.RuntimeException: Not enough space for compaction, estimated sstables = 1, expected write size = 221195610</span><br><span class="line">  at org.apache.cassandra.db.compaction.CompactionTask.checkAvailableDiskSpace(CompactionTask.java:296) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:124) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:73) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:59) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.db.compaction.CompactionManager$8.runMayThrow(CompactionManager.java:626) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_51]</span><br><span class="line">  at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_51]</span><br><span class="line">  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_51]</span><br><span class="line">  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_51]</span><br><span class="line">  at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]</span><br><span class="line">ERROR [HintedHandoffManager:1] 2016-06-29 10:06:19,267 CassandraDaemon.java:229 - Exception in thread Thread[HintedHandoffManager:1,1,main]</span><br><span class="line">java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: Not enough space for compaction, estimated sstables = 1, expected write size = 221195610</span><br><span class="line">  at org.apache.cassandra.db.HintedHandOffManager.compact(HintedHandOffManager.java:282) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.db.HintedHandOffManager.scheduleAllDeliveries(HintedHandOffManager.java:522) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.db.HintedHandOffManager.access$000(HintedHandOffManager.java:93) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.db.HintedHandOffManager$1.run(HintedHandOffManager.java:182) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor$UncomplainingRunnable.run(DebuggableScheduledThreadPoolExecutor.java:118) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_51]</span><br><span class="line">  at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304) [na:1.7.0_51]</span><br><span class="line">  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178) [na:1.7.0_51]</span><br><span class="line">  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [na:1.7.0_51]</span><br><span class="line">  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_51]</span><br><span class="line">  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_51]</span><br><span class="line">  at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]</span><br><span class="line">Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: Not enough space for compaction, estimated sstables = 1, expected write size = 221195610</span><br><span class="line">  at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.7.0_51]</span><br><span class="line">  at java.util.concurrent.FutureTask.get(FutureTask.java:188) [na:1.7.0_51]</span><br><span class="line">  at org.apache.cassandra.db.HintedHandOffManager.compact(HintedHandOffManager.java:278) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  ... 11 common frames omitted</span><br><span class="line">Caused by: java.lang.RuntimeException: Not enough space for compaction, estimated sstables = 1, expected write size = 221195610</span><br><span class="line">  at org.apache.cassandra.db.compaction.CompactionTask.checkAvailableDiskSpace(CompactionTask.java:296) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:124) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:73) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:59) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.db.compaction.CompactionManager$8.runMayThrow(CompactionManager.java:626) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-2.1.13.jar:2.1.13]</span><br><span class="line">  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_51]</span><br><span class="line">  at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_51]</span><br><span class="line">  ... 3 common frames omitted</span><br><span class="line">WARN  [STREAM-IN-/127.0.0.1] 2016-06-29 10:06:29,500 CompressedStreamReader.java:115 - [Stream ab888f50-3d8f-11e6-8b24-dff3aadcb7ef] Error while reading partition DecoratedKey(-677751571849691691, 4435344444443536393133383636353144303931304334383341363032413842) from stream on ks=&apos;md5&apos; and table=&apos;md5_id&apos;./usr</span><br></pre></td></tr></table></figure>
<h2 id="jHiccup">jHiccup</h2><p><a href="http://hao.jobbole.com/jhiccup/" target="_blank" rel="noopener">http://hao.jobbole.com/jhiccup/</a></p>
<ol>
<li>给bin/cassandra启动命令，添加jHiccup：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /usr/install/cassandra/bin/cassandra</span><br><span class="line">exec &quot;/usr/install/jHiccup-2.0.6/jHiccup&quot; $NUMACTL &quot;$JAVA&quot; $JVM_OPTS $cassandra_parms -cp &quot;$CLASSPATH&quot; $props &quot;$class&quot;</span><br></pre></td></tr></table></figure>
<p>注意必须先停止Cassanra，然后再启动（废话，不停止，再次启动肯定有问题）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">HiccupMeter: Failed to open log file.</span><br><span class="line">INFO  06:02:01 Classpath: /usr/install/cassandra/bin/../conf:.../usr/install/jHiccup-2.0.6/jHiccup.jar:/usr/install/cassandra/bin/../lib/jamm-0.3.0.jar</span><br><span class="line">INFO  06:02:01 JVM Arguments: [-javaagent:/usr/install/jHiccup-2.0.6/jHiccup.jar=, -ea, -javaagent:/usr/install/cassandra/bin/../lib/jamm-0.3.0.jar, -XX:</span><br><span class="line">WARN  06:02:01 Unable to lock JVM memory (ENOMEM). This can result in part of the JVM being swapped out, especially with mmapped I/O enabled. Increase RLIMIT_MEMLOCK or run Cassandra as root.</span><br><span class="line">WARN  06:02:01 JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.</span><br><span class="line">ERROR 06:02:01 Error starting local jmx server:</span><br><span class="line">java.rmi.server.ExportException: Port already in use: 7199; nested exception is:</span><br><span class="line">  java.net.BindException: 地址已在使用</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@dp0652 ~]$ export _JAVA_OPTIONS=&apos;-javaagent:/usr/install/jHiccup-2.0.6/jHiccup.jar=&quot;-d 20000 -i 1000&quot;&apos; &amp;&amp; sudo -u admin /usr/install/cassandra/bin/cassandra</span><br><span class="line">[qihuang.zheng@dp0652 ~]$ Picked up _JAVA_OPTIONS: -javaagent:/usr/install/jHiccup-2.0.6/jHiccup.jar=&quot;-d 20000 -i 1000&quot;</span><br><span class="line">HiccupMeter: Failed to open log file.</span><br><span class="line">INFO  06:24:09 JVM Arguments: [-ea, -javaagent:/usr/install/cassandra/bin/../lib/jamm-0.3.0.jar, -Dcassandra.storagedir=/usr/install/cassandra/bin/../data, -javaagent:/usr/install/jHiccup-2.0.6/jHiccup.jar=-d 20000 -i 1000]</span><br><span class="line">WARN  06:24:09 Unable to lock JVM memory (ENOMEM). This can result in part of the JVM being swapped out, especially with mmapped I/O enabled. Increase RLIMIT_MEMLOCK or run Cassandra as root.</span><br><span class="line">WARN  06:24:09 JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.</span><br><span class="line">ERROR 06:24:09 Error starting local jmx server:</span><br><span class="line">java.rmi.server.ExportException: Port already in use: 7199; nested exception is:</span><br><span class="line">  java.net.BindException: 地址已在使用</span><br><span class="line"></span><br><span class="line">[qihuang.zheng@dp0652 ~]$ jps -lm</span><br><span class="line">Picked up _JAVA_OPTIONS: -javaagent:/usr/install/jHiccup-2.0.6/jHiccup.jar=&quot;-d 20000 -i 1000&quot;</span><br><span class="line">35054 sun.tools.jps.Jps -lm  </span><br><span class="line">[qihuang.zheng@dp0652 ~]$ sudo -u admin jps -lm</span><br><span class="line">Picked up _JAVA_OPTIONS: -javaagent:/usr/install/jHiccup-2.0.6/jHiccup.jar=&quot;-d 20000 -i 1000&quot;</span><br><span class="line">HiccupMeter: Failed to open log file.</span><br></pre></td></tr></table></figure>
<p>正常启动Cassandra后，jHiccup.jar会作为agent：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[qihuang.zheng@dp0652 ~]$ ps -ef|grep cassandra</span><br><span class="line">/usr/java/jdk1.7.0_51/bin/java -javaagent:/usr/install/jHiccup-2.0.6/jHiccup.jar= -ea -javaagent:/usr/install/cassandra/bin/../lib/jamm-0.3.0.jar -XX:...</span><br></pre></td></tr></table></figure>
<p>正常生成的文件格式：hiccup.160505.1429.34233.hlog<br>会生成到pid指定的目录下，比如pid是cassandra的进程，则生成到/usr/install/cassandra下</p>
<p>但是在生产环境测试时，无法生产日志文件：</p>
<p>ps: the problem of jHiccup tool not working:  </p>
<p>We use jHiccup -p $pid to attach jHiccup to Cassandra Service,<br>but unfortunately, there are non hlog file generated which should be in Cassandra install home.<br>Last week I had demonstration to Daniel, and Daniel say he will checkout.<br>Here is our steps on production environment</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[admin@192-168-48-47 ~]$ ps -ef|grep cassandra</span><br><span class="line">admin    27021     1 10 Apr29 ?        1-22:50:40 /usr/java/jdk1.7.0_51/bin/java ... org.apache.cassandra.service.CassandraDaemon</span><br><span class="line"></span><br><span class="line">[admin@192-168-48-47 ~]$ /usr/install/jHiccup-2.0.6/jHiccup -p 27021 -v</span><br><span class="line">jHiccup version 2.0.5</span><br><span class="line">jHiccup executing: /usr/java/jdk1.7.0_51/bin/java -cp /usr/java/jdk1.7.0_51/lib/tools.jar:/usr/install/jHiccup-2.0.6/jHiccup.jar </span><br><span class="line">org.jhiccup.HiccupMeterAttacher -v -j /usr/install/jHiccup-2.0.6/jHiccup.jar -p 27021</span><br><span class="line">Attaching to process 27021 and launching jHiccup agent from jar 27021 with args: -d 0 -i 5000 -s 2 -r 1.0 -v</span><br><span class="line"></span><br><span class="line">[admin@192-168-48-47 ~]$ ll /usr/install/cassandra/</span><br><span class="line">drwxr-xr-x. 2 admin admin   4096 4月  25 11:08 bin</span><br><span class="line">-rw-r--r--. 1 admin admin 263216 1月  26 22:21 CHANGES.txt</span><br><span class="line">drwxr-xr-x. 3 admin admin   4096 4月  29 10:35 conf</span><br><span class="line">drwxr-xr-x. 2 admin admin   4096 4月  25 11:08 interface</span><br><span class="line">drwxr-xr-x. 3 admin admin   4096 4月  25 11:08 javadoc</span><br><span class="line">drwxr-xr-x. 3 admin admin   4096 4月  25 11:08 lib</span><br><span class="line">-rw-r--r--. 1 admin admin  11609 1月  26 22:21 LICENSE.txt</span><br><span class="line">drwxr-xr-x. 2 admin admin   4096 5月  13 12:43 logs</span><br><span class="line">-rw-r--r--. 1 admin admin  67603 1月  26 22:21 NEWS.txt</span><br><span class="line">-rw-r--r--. 1 admin admin   2117 1月  26 22:21 NOTICE.txt</span><br><span class="line">drwxr-xr-x. 3 admin admin   4096 4月  25 11:08 pylib</span><br><span class="line">drwxr-xr-x. 4 admin admin   4096 4月  25 11:08 tools</span><br></pre></td></tr></table></figure>
<p>原因是启动Cassandra用普通用户，然后通过sudo -u admin方式启动，但是/home/admin用户却无法访问普通用户的权限。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[admin@fp-cass048162 ~]$ pwdx 19649</span><br><span class="line">19649: /home/qihuang.zheng</span><br><span class="line"></span><br><span class="line">[admin@fp-cass048162 ~]$ lsof -p 19649 | grep cwd</span><br><span class="line">java    19649 admin  cwd    DIR               8,17         4096  490733569 /home/qihuang.zheng</span><br><span class="line"></span><br><span class="line">[admin@fp-cass048162 ~]$ readlink -e /proc/19649/cwd</span><br></pre></td></tr></table></figure>
<p>解决方法：停止Cassandra，用admin用户登陆， 用admin用户启动，不需要sudo -u admin。<br>最后会生成文件到/home/admin下。正常的日志如下：  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Executing: HiccupMeter -d 0 -i 5000 -s 2 -r 1.0 -v</span><br><span class="line">#[Logged with jHiccup version 2.0.6]</span><br><span class="line">#[Histogram log format version 1.1]</span><br><span class="line">#[StartTime: 1463708353.327 (seconds since epoch), Fri May 20 09:39:13 CST 2016]</span><br><span class="line">&quot;StartTimestamp&quot;,&quot;Interval_Length&quot;,&quot;Interval_Max&quot;,&quot;Interval_Compressed_Histogram&quot;</span><br><span class="line">1166.248,5.002,570.425,HISTIgAAAKp42pNpmazIwMApwAABTBDKT4GBgdnNYMcCBvsPUJlfDO8Yt3GfY1jCwM3AzsDIwAIUYwRCJjCJCZiwimITIx4w0kAlpW4amTYzUmAqI0UuGiibGfHqYCTaPEaK4oVxgGTR5RkpkB08qkkxi5EompEGqgfOTEweAjNiiGDDxKkaCiqxQyacMuSqpL6J1LGbCQyZoTQyxCZGvErq66aNe1igkBVMMgMAUHALXQ==</span><br><span class="line">1171.250,5.000,42.729,HISTIgAAAHt42pNpmazIwMDqxgABTBDKT4GBgdnNYMcCBvsPUJk/jDwMf/huM8gzcDOwglWyMjDC1EMBIwN2gEscP2AkWjcjmSaT77aRaTP++GWkoe6BsxlTDyMBmxjJlCVs9mCxmRCfiWaqGQnELCMJsqSpZsRKM+KVxVAFADZ8CIQ=</span><br><span class="line">1176.250,5.000,406.847,HISTIgAAAJt42pNpmazIwMDRwgABTBDKT4GBgdnNYMcCBvsPUJlnDJ8YhXjDGOoYBBnYgOpYGBiBJEg9IxgzMjCDSUYG8gAjDeQoN2PgbGagui5KzWCksbsYB0gv6boZaSY7VMxmJKCXdqoHymZGkmhqqqKFmeTYzIiCGTFEcOGBU0lN83BBJjxy5KijhUpqmMgEhsxQGhUyUyBGgm4AXGIJ5w==</span><br><span class="line">1181.250,5.000,125.829,HISTIgAAAG942pNpmazIwMD2gAECmCCUnwIDA7ObwY4FDPYfoDK/Gf4wcvFlMnQzcABVsTEwAiEDFEPY2AAu8cEFGEdtHgRmMg4ZmxlpJjtUzGYkoJd2qgfKZkaSaGqqooWZ5NjMiIIZMURw4YFTSYJ5AGq7CUM=</span><br><span class="line">1186.250,5.000,444.596,HISTIgAAAIR42pNpmazIwMCxggECmCCUnwIDA7ObwY4FDPYfoDIXGVkZvvGaMBxm4GBgAapjBGJmoDgjFA9mwEgnPSPNZka6u3BgbWakmSwtzaa2zYwk8SmRHTyqGUmi6a+K9mYyEsSMRKkaKiqxicAgEwoPH2SisrqBsxtU2zNhQErEaKIbAEcEChs=</span><br></pre></td></tr></table></figure>

      
    </div>
    
  </div>
  
    
<div class="copyright">
  <p><span>本文标题:</span><a href="/2015/10/15/Cassandra-Operation/">Cassandra操作</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 任何忧伤,都抵不过世界的美丽 的个人博客">任何忧伤,都抵不过世界的美丽</a></p>
  <p><span>发布时间:</span>2015年10月15日 - 00时00分</p>
  <p><span>最后更新:</span>2019年02月14日 - 21时42分</p>
  <p>
    <span>原始链接:</span><a href="/2015/10/15/Cassandra-Operation/" title="Cassandra操作">http://github.com/zqhxuyuan/2015/10/15/Cassandra-Operation/</a>
    <span class="btn" data-clipboard-text="原文: http://github.com/zqhxuyuan/2015/10/15/Cassandra-Operation/　　作者: 任何忧伤,都抵不过世界的美丽" title="点击复制文章链接">
        <i class="fa fa-clipboard"></i>
    </span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" title="中国大陆 (CC BY-NC-SA 3.0 CN)">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。</p>
  <script src="/js/clipboard.min.js"></script>
  <script> var clipboard = new Clipboard('.btn'); </script>
</div>
<style type="text/css">
  .copyright p .btn {
    margin-left: 1em;
  }
  .copyright:hover p .btn::after {
    content: "复制"
  }
  .copyright p .btn:hover {
      color: gray;
      cursor: pointer;
    };
</style>



<nav id="article-nav">
  
    <div id="article-nav-newer" class="article-nav-title">
      <a href="/2015/10/15/Cassandra-exception/">
        Cassandra常见异常
      </a>
    </div>
  
  
    <div id="article-nav-older" class="article-nav-title">
      <a href="/2015/09/10/2015-09-10-Storm-Window/">
        Storm的滑动窗口
      </a>
    </div>
  
</nav>

  
  
    <div class="post-donate">
	<br>
	<p>
    <div id="donate_board" class="donate_bar center">
        <a id="btn_donate" class="btn_donate" href="javascript:;" title="打赏"></a>
        <span class="donate_txt">
           &uarr;<br>
		   招人广告：对蚂蚁金服中间件感兴趣的可以发邮件到：qihuang.zqh at antfin.com
        </span>
        <br>
    </div>  
	<div id="donate_guide" class="donate_bar center hidden">
		<img src="/img/zhifubao.png" alt="支付宝打赏"> 
		<img src="/img/weixin.png" alt="微信打赏">  
    </div>
	<script type="text/javascript">
		document.getElementById('btn_donate').onclick = function(){
			$('#donate_board').addClass('hidden');
			$('#donate_guide').removeClass('hidden');
		}
	</script>
</p></div>
  
</article>

<!-- 默认显示文章目录，在文章---前输入toc: false关闭目录 -->
<!-- Show TOC and tocButton in default, Hide TOC via putting "toc: false" before "---" at [post].md -->
<div id="toc" class="toc-article">
<strong class="toc-title">文章目录</strong>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#优雅关闭节点"><span class="toc-number">1.</span> <span class="toc-text">优雅关闭节点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#不同集群数据同步"><span class="toc-number">2.</span> <span class="toc-text">不同集群数据同步</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#增量备份"><span class="toc-number">2.1.</span> <span class="toc-text">增量备份</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#准备工作：新集群搭建和建表"><span class="toc-number">2.2.</span> <span class="toc-text">准备工作：新集群搭建和建表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#开始：先测试一张表的迁移"><span class="toc-number">2.3.</span> <span class="toc-text">开始：先测试一张表的迁移</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#整个集群做一次完整的快照迁移"><span class="toc-number">2.4.</span> <span class="toc-text">整个集群做一次完整的快照迁移</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#增量备份（需要多次执行）"><span class="toc-number">2.5.</span> <span class="toc-text">增量备份（需要多次执行）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#机房迁移"><span class="toc-number">2.6.</span> <span class="toc-text">机房迁移</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#直接从当前集群同步到上海集群"><span class="toc-number">2.6.1.</span> <span class="toc-text">直接从当前集群同步到上海集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#新集群安装"><span class="toc-number">2.6.2.</span> <span class="toc-text">新集群安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-_表结构"><span class="toc-number">2.6.3.</span> <span class="toc-text">1. 表结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-_数据迁移"><span class="toc-number">2.6.4.</span> <span class="toc-text">2. 数据迁移</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-_增量数据迁移"><span class="toc-number">2.6.5.</span> <span class="toc-text">3. 增量数据迁移</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-_数据验证"><span class="toc-number">2.6.6.</span> <span class="toc-text">4. 数据验证</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#nodetool工具"><span class="toc-number">3.</span> <span class="toc-text">nodetool工具</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#集群状态:_nodetool_decribecluster"><span class="toc-number">3.1.</span> <span class="toc-text">集群状态: nodetool decribecluster</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#删除节点:_removenode"><span class="toc-number">3.2.</span> <span class="toc-text">删除节点: removenode</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#替换节点:_replace_address"><span class="toc-number">3.3.</span> <span class="toc-text">替换节点: replace_address</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#重新加入"><span class="toc-number">3.4.</span> <span class="toc-text">重新加入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#网络状态netstats:_显示一个节点的Active_Stream"><span class="toc-number">3.5.</span> <span class="toc-text">网络状态netstats: 显示一个节点的Active Stream</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#节点信息:_nodetool_info"><span class="toc-number">3.6.</span> <span class="toc-text">节点信息: nodetool info</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Gossip信息:_nodetool_gossipinfo"><span class="toc-number">3.7.</span> <span class="toc-text">Gossip信息: nodetool gossipinfo</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#表相关的信息:nodetool_cfstats_forseti-velocity"><span class="toc-number">3.8.</span> <span class="toc-text">表相关的信息:nodetool cfstats forseti.velocity</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#compactionhistory"><span class="toc-number">3.9.</span> <span class="toc-text">compactionhistory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#节点sstable数量异常"><span class="toc-number">3.10.</span> <span class="toc-text">节点sstable数量异常</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#tpstats"><span class="toc-number">4.</span> <span class="toc-text">tpstats</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sstable_writer"><span class="toc-number">5.</span> <span class="toc-text">sstable writer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#文件数过多"><span class="toc-number">5.1.</span> <span class="toc-text">文件数过多</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#导入数据后，用refresh"><span class="toc-number">5.2.</span> <span class="toc-text">导入数据后，用refresh</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#通过增大内存来增大sstable大小（内存不足）"><span class="toc-number">5.3.</span> <span class="toc-text">通过增大内存来增大sstable大小（内存不足）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分表？"><span class="toc-number">5.4.</span> <span class="toc-text">分表？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sstableloader"><span class="toc-number">6.</span> <span class="toc-text">sstableloader</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#jHiccup"><span class="toc-number">7.</span> <span class="toc-text">jHiccup</span></a></li></ol>
</div>
<style type="text/css">
  .left-col .switch-btn {
    display: none;
  }
  .left-col .switch-area {
    display: none;
  }
</style>

<input type="button" id="tocButton" value="隐藏目录" title="点击按钮隐藏或者显示文章目录">
<script type="text/javascript">
  var toc_button= document.getElementById("tocButton");
  var toc_div= document.getElementById("toc");
  /* Show or hide toc when click on tocButton.
  通过点击设置的按钮显示或者隐藏文章目录.*/
  toc_button.onclick=function(){
  if(toc_div.style.display=="none"){
  toc_div.style.display="block";
  toc_button.value="隐藏目录";
  document.getElementById("switch-btn").style.display="none";
  document.getElementById("switch-area").style.display="none";
  }
  else{
  toc_div.style.display="none";
  toc_button.value="显示目录";
  document.getElementById("switch-btn").style.display="block";
  document.getElementById("switch-area").style.display="block";
  }
  }
    if ($(".toc").length < 1) {
        $("#toc").css("display","none");
        $("#tocButton").css("display","none");
        $(".switch-btn").css("display","block");
        $(".switch-area").css("display","block");
    }
</script>


    <style>
        .toc {
            white-space: nowrap;
            overflow-x: hidden;
        }
    </style>

    <script>
        $(document).ready(function() {
            $(".toc li a").mouseover(function() {
                var title = $(this).attr('href');
                $(this).attr("title", title);
            });
        })
    </script>




<div class="share">
	<div class="bdsharebuttonbox">
	<a href="#" class="bds_more" data-cmd="more"></a>
	<a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
	<a href="#" class="bds_copy" data-cmd="copy" title="复制网址"></a>
	<a href="#" class="bds_mail" data-cmd="mail" title="通过邮件分享"></a>
	<a href="#" class="bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
	</div>
	<script>
	window._bd_share_config={
		"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
	</script>
</div>



<div class="duoshuo" id="comments">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="2015/10/15/Cassandra-Operation/" data-title="Cassandra操作" data-url="http://github.com/zqhxuyuan/2015/10/15/Cassandra-Operation/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"zqhxuyuan"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>






    <style type="text/css">
    #scroll {
      display: none;
    }
    </style>
    <div class="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
    </div>


  
  
    
    <div class="post-nav-button">
    <a href="/2015/10/15/Cassandra-exception/" title="上一篇: Cassandra常见异常">
    <i class="fa fa-angle-left"></i>
    </a>
    <a href="/2015/09/10/2015-09-10-Storm-Window/" title="下一篇: Storm的滑动窗口">
    <i class="fa fa-angle-right"></i>
    </a>
    </div>
  



    
        <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
        <script>
        var yiliaConfig = {
        fancybox: true,
        mathjax: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        open_in_new: false
        }
        </script>
        
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2019 任何忧伤,都抵不过世界的美丽
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的静态博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减双栏 Hexo 博客主题">Yelee</a> by MOxFIVE
        </div>
    </div>
    <div class="visit">
      <span id="busuanzi_container_site_pv" style="display:none">
        <span id="site-visit">本站到访数: 
        <span id="busuanzi_value_site_uv"></span>
        </span>
      </span>
      <span id="busuanzi_container_page_pv" style="display:none">
        <span id="page-visit">, 本页阅读量: 
        <span id="busuanzi_value_page_pv"></span>
        </span>
      </span>
    </div>
  </div>
</footer>
    </div>
    

<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>

<script>
  var backgroundnum = 5;
  var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));

  $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
</script>


<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-80646710-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
<a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
<a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>