<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>Kafka源码分析 Producer客户端 | zqhxuyuan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Kafka的Producer新客户端API实现(JAVA)">
<meta name="keywords" content="kafka">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka源码分析 Producer客户端">
<meta property="og:url" content="http://github.com/zqhxuyuan/2016/01/06/2016-01-06-Kafka_Producer/index.html">
<meta property="og:site_name" content="zqhxuyuan">
<meta property="og:description" content="Kafka的Producer新客户端API实现(JAVA)">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160119164949035">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160119170630760">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160119225630114">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160119231458355">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160119232024826">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120093720907">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120101250639">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120111819367">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120115614118">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120150249827">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120120921467">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120155619789">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160121082905460">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120162602972">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120174334217">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160122090034616">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160121082923585">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160121082943445">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160121093500704">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160121082955867">
<meta property="og:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160121083009101">
<meta property="og:image" content="http://kafka.apache.org/images/producer_consumer.png">
<meta property="og:updated_time" content="2019-02-14T13:42:29.226Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kafka源码分析 Producer客户端">
<meta name="twitter:description" content="Kafka的Producer新客户端API实现(JAVA)">
<meta name="twitter:image" content="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160119164949035">
  
    <link rel="alternative" href="/atom.xml" title="zqhxuyuan" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">任何忧伤,都抵不过世界的美丽</a></h1>
		</hgroup>

		
				


		
			<div id="switch-btn" class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div id="switch-area" class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives/">归档</a></li>
				        
							<li><a href="/tags/">标签</a></li>
				        
							<li><a href="/about/">关于</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
								<li id="RSS"><a class="RSS" target="_blank" href="/atom.xml" title="RSS"></a></li>
					        
						</ul>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/apex/" style="font-size: 10px;">apex</a> <a href="/tags/bigdata/" style="font-size: 10px;">bigdata</a> <a href="/tags/book/" style="font-size: 10px;">book</a> <a href="/tags/cassandra/" style="font-size: 18.89px;">cassandra</a> <a href="/tags/clojure/" style="font-size: 10px;">clojure</a> <a href="/tags/drill/" style="font-size: 16.67px;">drill</a> <a href="/tags/druid/" style="font-size: 13.33px;">druid</a> <a href="/tags/dubbo/" style="font-size: 10px;">dubbo</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/etl/" style="font-size: 10px;">etl</a> <a href="/tags/geode/" style="font-size: 10px;">geode</a> <a href="/tags/graph/" style="font-size: 12.22px;">graph</a> <a href="/tags/hadoop/" style="font-size: 11.11px;">hadoop</a> <a href="/tags/hbase/" style="font-size: 15.56px;">hbase</a> <a href="/tags/ignite/" style="font-size: 10px;">ignite</a> <a href="/tags/java/" style="font-size: 10px;">java</a> <a href="/tags/jvm/" style="font-size: 10px;">jvm</a> <a href="/tags/kafka/" style="font-size: 20px;">kafka</a> <a href="/tags/midd/" style="font-size: 10px;">midd</a> <a href="/tags/ops/" style="font-size: 12.22px;">ops</a> <a href="/tags/redis/" style="font-size: 11.11px;">redis</a> <a href="/tags/rocketmq/" style="font-size: 10px;">rocketmq</a> <a href="/tags/scala/" style="font-size: 13.33px;">scala</a> <a href="/tags/spark/" style="font-size: 17.78px;">spark</a> <a href="/tags/storm/" style="font-size: 17.78px;">storm</a> <a href="/tags/tcc/" style="font-size: 10px;">tcc</a> <a href="/tags/timeseries/" style="font-size: 12.22px;">timeseries</a> <a href="/tags/work/" style="font-size: 14.44px;">work</a> <a href="/tags/流处理/" style="font-size: 11.11px;">流处理</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">BIG(DATA)</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<a href="/" class="profilepic">
				<img lazy-src="https://avatars1.githubusercontent.com/u/1088525?v=3&amp;s=180" class="js-avatar">
			</a>
			<hgroup>
			  <h1 class="header-author"><a href="/" title="回到主页">任何忧伤,都抵不过世界的美丽</a></h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives/">归档</a></li>
		        
					<li><a href="/tags/">标签</a></li>
		        
					<li><a href="/about/">关于</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
						<ul class="social">
							
								<li id="新浪微博"><a class="新浪微博" target="_blank" href="http://weibo.com/xuyuantree" title="新浪微博"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="http://github.com/zqhxuyuan" title="GitHub"></a></li>
					        
								<li id="RSS"><a class="RSS" target="_blank" href="/atom.xml" title="RSS"></a></li>
					        
						</ul>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-2016-01-06-Kafka_Producer" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/01/06/2016-01-06-Kafka_Producer/" class="article-date">
  	<time datetime="2016-01-05T16:00:00.000Z" itemprop="datePublished">2016-01-06</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Kafka源码分析 Producer客户端
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Source/">Source</a>
	</div>


        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kafka/">kafka</a></li></ul>
	</div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <p>Kafka的Producer新客户端API实现(JAVA)<br><a id="more"></a></p>
<h2 id="导读">导读</h2><p>本节从新的Producer API示例开始，</p>
<h2 id="Producer">Producer</h2><p>生产者线程：异步发送消息，提供一个Callback；同步发送消息，则调用Future.get()会Block住直到结果返回。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> KafkaProducer&lt;Integer, String&gt; producer;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Boolean isAsync;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Producer</span><span class="params">(String topic, Boolean isAsync)</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</span><br><span class="line">        props.put(<span class="string">"client.id"</span>, <span class="string">"DemoProducer"</span>);</span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.IntegerSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        producer = <span class="keyword">new</span> KafkaProducer&lt;Integer, String&gt;(props);</span><br><span class="line">        <span class="keyword">this</span>.topic = topic;</span><br><span class="line">        <span class="keyword">this</span>.isAsync = isAsync;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> messageNo = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            String messageStr = <span class="string">"Message_"</span> + messageNo;</span><br><span class="line">            <span class="keyword">if</span> (isAsync) &#123;  <span class="comment">// Send asynchronously</span></span><br><span class="line">                producer.send(<span class="keyword">new</span> ProducerRecord&lt;Integer, String&gt;(topic, messageNo, messageStr), </span><br><span class="line">                    <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">                        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception e)</span> </span>&#123;</span><br><span class="line">                            System.out.println(<span class="string">"The offset of the record we just sent is: "</span> + metadata.offset());</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                );</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;        <span class="comment">// Send synchronously</span></span><br><span class="line">                producer.send(<span class="keyword">new</span> ProducerRecord&lt;Integer, String&gt;(topic, messageNo, messageStr)).get();</span><br><span class="line">            &#125;</span><br><span class="line">            ++messageNo;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>KafkaProducer需要指定消息Key，Value的类型&lt;Integer,String&gt;，ProducerRecord还需要指定topic</li>
<li>根据配置文件创建KafkaProducer，指定了Broker地址，Key，Value的序列化方式，消息必须要指定topic</li>
<li>发送消息的返回结果RecordMetadata记录元数据包括了消息的offset（在哪个partition的哪里offset）</li>
</ul>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160119164949035" alt="k_producer_client"></p>
<h3 id="blocking_vs_non-blocking">blocking vs non-blocking</h3><p>KafkaProducer.send方法返回的是一个Future，那么它如何同时实现blocking方式和non-blocking方式。  </p>
<ul>
<li>blocking：在调用send返回Future时，立即调用get，因为Future.get在没有返回结果时会一直阻塞</li>
<li>non-block：提供一个callback,调用send后，可以继续发送消息而不用等待。当有结果返回时，callback会被自动通知执行</li>
</ul>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160119170630760" alt="k_future"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// first make sure the metadata for the topic is available</span></span><br><span class="line">    <span class="keyword">long</span> waitedOnMetadataMs = waitOnMetadata(record.topic(), <span class="keyword">this</span>.maxBlockTimeMs);</span><br><span class="line">    <span class="keyword">long</span> remainingWaitMs = Math.max(<span class="number">0</span>, <span class="keyword">this</span>.maxBlockTimeMs - waitedOnMetadataMs);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 序列化key和value</span></span><br><span class="line">    <span class="keyword">byte</span>[] serializedKey= keySerializer.serialize(record.topic(), record.key());</span><br><span class="line">    <span class="keyword">byte</span>[] serializedValue = valueSerializer.serialize(record.topic(), record.value());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 选择这条消息的Partition</span></span><br><span class="line">    <span class="keyword">int</span> partition = partition(record, serializedKey, serializedValue, metadata.fetch());</span><br><span class="line">    TopicPartition tp = <span class="keyword">new</span> TopicPartition(record.topic(), partition);</span><br><span class="line">    RecordAccumulator.RecordAppendResult result = accumulator.append(tp, serializedKey, serializedValue, callback, remainingWaitMs);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在每次追加一条消息到收集器之后,都要判断是否满了.如果满了,就执行一次Sender操作,通知Sender将这批数据发送到Kafka</span></span><br><span class="line">    <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) <span class="keyword">this</span>.sender.wakeup();</span><br><span class="line">    <span class="keyword">return</span> result.future;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160119225630114" alt="k_send"></p>
<p>在发送消息前，消息所属的topic必须已经建好，并且也指定这个topic的partition数量（没有指定则默认是server.properties的<code>num.partitions</code>）。  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 10 --topic test</span><br></pre></td></tr></table></figure>
<p>所以<code>Topic</code>，<code>Partition</code>，<code>Key</code>，<code>Value</code>组合起来就能表示<code>消息</code>发送到哪个<code>topic</code>的哪个<code>partition</code>上。  </p>
<h3 id="partition">partition</h3><p>一个Partition的主要组成部分是topic名称，partition编号，所在的Leader，所有的副本，isr列表。表示这个Partition的分布情况。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PartitionInfo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> partition;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Node leader;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Node[] replicas;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Node[] inSyncReplicas;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下图是kafka-manager中某个topic的PartitionInfo信息（副本数=4，Broker数量刚好也是4，导致每个Partition都分布在所有Broker上）。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160119231458355" alt="k_partitioninfo"></p>
<p>在Cluster的构造函数中，会根据所有节点和所有partitions构建集群状态信息。availablePartitions只保存有Leader的Partition。  </p>
<blockquote>
<p>正常来说每个Partition都是有Leader Partition的。如果Partition没有Leader的话，说明这个Partition就是有问题的。  </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">List&lt;PartitionInfo&gt; availablePartitions = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"><span class="keyword">for</span> (PartitionInfo part : partitionList) &#123;</span><br><span class="line">    <span class="keyword">if</span> (part.leader() != <span class="keyword">null</span>)</span><br><span class="line">        availablePartitions.add(part);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">this</span>.availablePartitionsByTopic.put(topic, Collections.unmodifiableList(availablePartitions));</span><br></pre></td></tr></table></figure>
<p>要选择消息所属的partition，首先需要知道topic一共有多少个partition（numPartitions），所以metadata.fetch获得的Cluster信息中有topic-&gt;partitions的映射关系（partitionsByTopic）.  </p>
<p>消息有key的话，对key进行hash，然后和partitions数量取模，类似于round-robin的方式来确定key所在的partition达到负载均衡。如果消息没有key， 会根据递增的counter的值确定partition，count不断递增，确保消息不会都发到同一个partition里。  </p>
<blockquote>
<p>问题：写入消息时是写到Leader Partition的话，下面的代码如何体现Leader？<br>答案：实际上为消息选择Partition，只是为了负载均衡，跟Leader没有多大关系。因为一个PartitionInfo一定能确定一个唯一的Leader（一个Partition只有一个Leader）<br>如果一个topic只有一个Partition的话，在集群环境下就不能水平扩展：这个topic的消息只能写到一个节点。而为一个topic设置多个Partition，可以同时往多个节点的多个Partition写数据。注意：多个Partition都是同一个topic的，每个Partition的逻辑意义都是相同的，只是物理位置不同而已。   </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 这个topic所有的partitions. 用来负载均衡, 即Leader Partition不要都分布在同一台机器上</span></span><br><span class="line">    List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">    <span class="keyword">int</span> numPartitions = partitions.size();</span><br><span class="line">    <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> nextValue = counter.getAndIncrement();</span><br><span class="line">        <span class="comment">// 这个topic可以使用的partitions: availablePartitionsByTopic</span></span><br><span class="line">        List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">        <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">int</span> part = DefaultPartitioner.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">            <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// no partitions are available, give a non-available partition</span></span><br><span class="line">            <span class="keyword">return</span> DefaultPartitioner.toPositive(nextValue) % numPartitions;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// hash the keyBytes to choose a partition</span></span><br><span class="line">        <span class="keyword">return</span> DefaultPartitioner.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下图是partition的分布算法。topic1有4个partition。则总共有4个对应的PartitionInfo对象。每个PartitionInfo（比如topic1-part1）都有唯一的Partition编号（1），replicas（1，2，3）。  </p>
<blockquote>
<p>注意：replicas并不是一个PartitionInfo对象，它们仅仅是某个Partition编号对应的PartitionInfo的replicas信息。即partitionsForTopic和availablePartitionsForTopic里面其实是没有follower replics的。因为如果Replicas都算作PartitionInfo的话，则Partition编号就不好表示了(4个Partition,每个Partition由3个副本)。 </p>
</blockquote>
<blockquote>
<p>实际上在选择Partition的时候，根本就先不要考虑replicas的存在，就只有Partition编号。每个Partition是分布在不同的节点上的（可以把这个Partition就认为是Leader Partition）。然后在写消息的时候采用round-robin方式将消息平均负载到每一个Partition上。假设第一条消息写到了topic1-part1，则下一条消息就写到topic1-part2，以此类推。  </p>
</blockquote>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160119232024826" alt="k_partition_algs"></p>
<h3 id="RecordAccumulator">RecordAccumulator</h3><p>由于生产者发送消息是异步地，所以可以将多条消息缓存起来，等到一定时机批量地写入到Kafka集群中，RecordAccumulator就扮演了缓冲者的角色。生产者每生产一条消息，就向accumulator中追加一条消息，并且要返回本次追加是否导致batch满了，如果batch满了，则开始发送这一批数据。最开始以为<code>Deque&lt;RecordBatch&gt;</code>就是一个消息队列，实际上<code>一批消息</code>会首先放在<code>RecordBatch</code>中，然后Batch又放在<code>双端队列</code>中。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120093720907" alt="k_batches"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> RecordAppendResult <span class="title">append</span><span class="params">(TopicPartition tp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Callback callback, <span class="keyword">long</span> maxTimeToBlock)</span> </span>&#123;</span><br><span class="line">    Deque&lt;RecordBatch&gt; dq = dequeFor(tp);</span><br><span class="line">    <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">        RecordBatch last = dq.peekLast();</span><br><span class="line">        <span class="keyword">if</span> (last != <span class="keyword">null</span>) &#123;</span><br><span class="line">            FutureRecordMetadata future = last.tryAppend(key, value, callback, time.milliseconds());</span><br><span class="line">            <span class="comment">// 有旧的batch, 并且能往这个batch继续追加消息</span></span><br><span class="line">            <span class="keyword">if</span> (future != <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, dq.size() &gt; <span class="number">1</span> || last.records.isFull(), <span class="keyword">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 队列为空(没有一个RecordBatch,last=null), 或者新的RecordBatch为空(旧的Batch没有空间了,future=null), 则新分配一个Batch</span></span><br><span class="line">    <span class="keyword">int</span> size = Math.max(<span class="keyword">this</span>.batchSize, Records.LOG_OVERHEAD + Record.recordSize(key, value));</span><br><span class="line">    ByteBuffer buffer = free.allocate(size, maxTimeToBlock);</span><br><span class="line">    <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">        <span class="comment">// 内存的ByteBuffer, 追加新消息时,会最终写到这个ByteBuffer中</span></span><br><span class="line">        MemoryRecords records = MemoryRecords.emptyRecords(buffer, compression, <span class="keyword">this</span>.batchSize);</span><br><span class="line">        RecordBatch batch = <span class="keyword">new</span> RecordBatch(tp, records, time.milliseconds());</span><br><span class="line">        FutureRecordMetadata future = Utils.notNull(batch.tryAppend(key, value, callback, time.milliseconds()));</span><br><span class="line">        dq.addLast(batch);</span><br><span class="line">        incomplete.add(batch);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, dq.size() &gt; <span class="number">1</span> || batch.records.isFull(), <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>batches是一个并发安全的，但是每个TopicPartition里的ArrayDeque并不是线程安全的，所以在修改Deque时都需要同步块操作。队列中只要有一个以上的batch（dq.size），或者追加了这条消息后，当前Batch中的记录满了（batch.records），就可以发送消息了。   </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120101250639" alt="k_deque"></p>
<p>RecordBatch的tryAppend判断MemoryRecords是否能容纳下新的消息，如果可以就追加，如果没有空间返回null，让调用者自己新建一个Batch。所以一个RecordBatch只对应了一个MemoryRecords。而一个MemoryRecords可以存放至多maxRecordSize大小的消息。  </p>
<blockquote>
<p>注意：客户端传递的Callback是在这里和消息一起被加入的。但是因为生产者是批量地写数据，所以回调函数是在一批数据完成后才被调用。  </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> FutureRecordMetadata <span class="title">tryAppend</span><span class="params">(<span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Callback callback, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> roomEnough = <span class="keyword">this</span>.records.hasRoomFor(key, value)</span><br><span class="line">    <span class="keyword">if</span>(!roomEnough) <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">this</span>.records.append(<span class="number">0L</span>, key, value);</span><br><span class="line">    <span class="keyword">this</span>.maxRecordSize = Math.max(<span class="keyword">this</span>.maxRecordSize, Record.recordSize(key, value));</span><br><span class="line">    FutureRecordMetadata future = <span class="keyword">new</span> FutureRecordMetadata(<span class="keyword">this</span>.produceFuture, <span class="keyword">this</span>.recordCount);</span><br><span class="line">    <span class="keyword">if</span> (callback != <span class="keyword">null</span>) thunks.add(<span class="keyword">new</span> Thunk(callback, future));</span><br><span class="line">    <span class="keyword">this</span>.recordCount++;</span><br><span class="line">    <span class="keyword">return</span> future;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考：为什么追加数据的offset固定是0？实际上由于消息之间都是独立的，一条消息自己是无法确定自己的offset的。那么offset是怎么管理的？  </p>
</blockquote>
<p>在Sender线程开始运行之前，首先要找到<code>每个PartitionInfo的Leader节点</code>，由RecordAccumulator统一收集已经准备好的节点。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ReadyCheckResult <span class="title">ready</span><span class="params">(Cluster cluster, <span class="keyword">long</span> nowMs)</span> </span>&#123;</span><br><span class="line">    Set&lt;Node&gt; readyNodes = <span class="keyword">new</span> HashSet&lt;Node&gt;();</span><br><span class="line">    <span class="comment">// batches: 每个TopicPartition都对应了一个双端队列</span></span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, Deque&lt;RecordBatch&gt;&gt; entry : <span class="keyword">this</span>.batches.entrySet()) &#123;</span><br><span class="line">        TopicPartition part = entry.getKey();</span><br><span class="line">        Deque&lt;RecordBatch&gt; deque = entry.getValue();</span><br><span class="line">        <span class="comment">// 找出这个TopicPartition的Leader节点, 在正式开始发送消息时, 会先建立到这些节点的连接</span></span><br><span class="line">        Node leader = cluster.leaderFor(part);</span><br><span class="line">        <span class="keyword">if</span> (leader == <span class="keyword">null</span>) &#123;</span><br><span class="line">            unknownLeadersExist = <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!readyNodes.contains(leader)) &#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (deque) &#123;</span><br><span class="line">                RecordBatch batch = deque.peekFirst();</span><br><span class="line">                <span class="keyword">if</span> (batch != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">boolean</span> sendable = full || expired || exhausted || closed || flushInProgress();</span><br><span class="line">                    <span class="keyword">if</span> (sendable &amp;&amp; !backingOff) &#123;</span><br><span class="line">                        <span class="comment">// 加入到等待连接的节点中. </span></span><br><span class="line">                        readyNodes.add(leader);</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        nextReadyCheckDelayMs = Math.min(timeLeftMs, nextReadyCheckDelayMs);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ReadyCheckResult(readyNodes, nextReadyCheckDelayMs, unknownLeadersExist);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>数据有生产就会有被消费的地方，对应Deque队列的话，将RecordBatch加入，就有对应的pollFirst获取并删除第一个batch。由于在生产数据的时候，每个TopicPartition都有自己的队列，并且都统一被收集到了RecordAccumulator的batches中。在消费数据的时候，最好对batches中的每个TopicPartition重新整理成以Node节点为级别，对后面的发送流程是有很大帮助的。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120111819367" alt="k_ready_drain"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Map&lt;Integer, List&lt;RecordBatch&gt;&gt; drain(Cluster cluster, Set&lt;Node&gt; nodes, <span class="keyword">int</span> maxSize, <span class="keyword">long</span> now) &#123;</span><br><span class="line">    Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = <span class="keyword">new</span> HashMap&lt;Integer, List&lt;RecordBatch&gt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (Node node : nodes) &#123;</span><br><span class="line">        <span class="keyword">int</span> size = <span class="number">0</span>;</span><br><span class="line">        List&lt;PartitionInfo&gt; parts = cluster.partitionsForNode(node.id());  <span class="comment">// 节点上所有的Partition</span></span><br><span class="line">        List&lt;RecordBatch&gt; ready = <span class="keyword">new</span> ArrayList&lt;RecordBatch&gt;(); <span class="comment">// 用来保存这个节点的Batch</span></span><br><span class="line">        <span class="keyword">int</span> start = drainIndex = drainIndex % parts.size();     <span class="comment">// 为了不被饿死,start并不是从0开始. 初始时,start=drainIndex</span></span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            PartitionInfo part = parts.get(drainIndex);</span><br><span class="line">            Deque&lt;RecordBatch&gt; deque = dequeFor(<span class="keyword">new</span> TopicPartition(part.topic(), part.partition()));</span><br><span class="line">            <span class="keyword">if</span> (deque != <span class="keyword">null</span>) &#123;                                <span class="comment">// 并不是所有的Partition都有队列的             </span></span><br><span class="line">                <span class="keyword">synchronized</span> (deque) &#123;                          <span class="comment">// 队列不是线程安全的,需要同步块</span></span><br><span class="line">                    RecordBatch first = deque.peekFirst();      <span class="comment">// Batch加入到队列的时候是加到尾部, 拉取Batch时则从头部, 所以叫做双端队列嘛</span></span><br><span class="line">                    <span class="keyword">if</span> (first != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        RecordBatch batch = deque.pollFirst();  <span class="comment">// 上面并没有把Batch从队列中删除, 如果这个Batch真的可以被消费,才真正删除(在first后做了一些判断,这里省略了)</span></span><br><span class="line">                        batch.records.close();                  <span class="comment">// 释放内存</span></span><br><span class="line">                        ready.add(batch);                       <span class="comment">// 添加到待发送列表中</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">this</span>.drainIndex = (<span class="keyword">this</span>.drainIndex + <span class="number">1</span>) % parts.size();</span><br><span class="line">        &#125; <span class="keyword">while</span> (start != drainIndex);                          <span class="comment">// 直到遍历完这个节点所有的Partition,说明这个节点不会有其他的Partition了,可以放心地退出循环</span></span><br><span class="line"></span><br><span class="line">        batches.put(node.id(), ready);                          <span class="comment">// Batch是以Node为级别的.表示这个Node可以接受一批的RecordBatch. 因为每个RecordBatch的Partition都是无序的.</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> batches;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Sender">Sender</h3><p>RecordAccumulator.RecordAppendResult的batch满了，唤醒Sender线程。Sender线程的启动在创建KafkaProducer时。Sender再唤醒NetworkClient（不是线程，相当于通知客户端开始服务了），client也唤醒Selector，最终唤醒NIO的Selector。  </p>
<blockquote>
<p>为什么需要有wakeup动作：因为可能有线程在select等待事件被阻塞了（没有事件），通过wakeup唤醒那个线程开始工作（有事件进来了）  </p>
</blockquote>
<p>Sender不仅承载了RecordAccumulator记录的收集器，也要通知客户端服务：把Accumulator收集的批记录通过客户端发送出去。Sender作为一个线程，是在后台不断运行的，如果线程被停止，可能RecordAccumulator中还有数据没有发送出去，所以要优雅地停止。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (running) &#123;</span><br><span class="line">        run(time.milliseconds());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (!forceClose &amp;&amp; (<span class="keyword">this</span>.accumulator.hasUnsent() || <span class="keyword">this</span>.client.inFlightRequestCount() &gt; <span class="number">0</span>)) &#123;</span><br><span class="line">        run(time.milliseconds());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.client.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>发送消息的工作统一由Sender来控制。之前的wakeup只是一个通知，实际的工作还是由线程的run方法来控制的。同样调用client.send也只是把请求先放到队列中，client.poll才是会将读写真正发送到socket链路上。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    Cluster cluster = metadata.fetch();</span><br><span class="line">    <span class="comment">// ① get the list of partitions with data ready to send</span></span><br><span class="line">    RecordAccumulator.ReadyCheckResult result = <span class="keyword">this</span>.accumulator.ready(cluster, now);</span><br><span class="line">    <span class="comment">// ② remove any nodes we aren't ready to send to  建立到Leader的Socket连接</span></span><br><span class="line">    Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</span><br><span class="line">    <span class="keyword">long</span> notReadyTimeout = Long.MAX_VALUE;</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">        Node node = iter.next();</span><br><span class="line">        <span class="keyword">if</span> (!<span class="keyword">this</span>.client.ready(node, now)) &#123;  </span><br><span class="line">            iter.remove();</span><br><span class="line">            notReadyTimeout = Math.min(notReadyTimeout, <span class="keyword">this</span>.client.connectionDelay(node, now));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ③ create produce requests 之前加入到了accumulator收集器中, 现在从收集器获取出最开始放入的消息</span></span><br><span class="line">    Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = <span class="keyword">this</span>.accumulator.drain(cluster, result.readyNodes, <span class="keyword">this</span>.maxRequestSize, now);</span><br><span class="line">    <span class="comment">// ④ Transfer the record batches into a list of produce requests on a per-node basis 以节点为级别的生产请求列表. 即每个节点只有一个ClientRequest</span></span><br><span class="line">    List&lt;ClientRequest&gt; requests = createProduceRequests(batches, now);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);</span><br><span class="line">    <span class="comment">// ⑤ Queue up the given request for sending. Requests can only be sent out to ready nodes. 从注释中可以看出这是一个入队列的操作</span></span><br><span class="line">    <span class="keyword">for</span> (ClientRequest request : requests) client.send(request, now);</span><br><span class="line">    <span class="comment">// ⑥ Do actual reads and writes to sockets. 这里才是真正的读写操作</span></span><br><span class="line">    <span class="keyword">this</span>.client.poll(pollTimeout, now);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>accumulator在之前一直append数据，到真正要发送一批数据时，先①准备（ready）需要发送的partitions到哪些Nodes上，②并建立到节点的连接，然后③构造每个Node需要的RecordBatch列表（一个节点同时可以接受多批数据），④并转换为客户端的请求ClientRequest。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120115614118" alt="k_sender_run"></p>
<p>由于batches已经是按照节点划分好的了，所以创建的客户端请求也是按照节点划分好了。不过虽然produceRequest方法中的batches是某个节点所有的batches，但是客户端请求面向的还是Partition级别！所以要对batches重新按照Partition的粒度整理。不过注意的是一个节点只有一个ClientRequest，它本身并不关心包含了多少个Partition，你只要需要发送的对象包装成RequestSend即可。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120150249827" alt="k_client_request"></p>
<blockquote>
<p>问题：batches中会不会有相同的Partition？不会的！如果那样的话，两个Map的key因为都是Partition，会导致value被覆盖。但是怎么保证？  </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> ClientRequest <span class="title">produceRequest</span><span class="params">(<span class="keyword">long</span> now, <span class="keyword">int</span> destination, <span class="keyword">short</span> acks, <span class="keyword">int</span> timeout, List&lt;RecordBatch&gt; batches)</span> </span>&#123;</span><br><span class="line">    Map&lt;TopicPartition, ByteBuffer&gt; produceRecordsByPartition = <span class="keyword">new</span> HashMap&lt;TopicPartition, ByteBuffer&gt;(batches.size());</span><br><span class="line">    <span class="keyword">final</span> Map&lt;TopicPartition, RecordBatch&gt; recordsByPartition = <span class="keyword">new</span> HashMap&lt;TopicPartition, RecordBatch&gt;(batches.size());</span><br><span class="line">    <span class="keyword">for</span> (RecordBatch batch : batches) &#123;</span><br><span class="line">        TopicPartition tp = batch.topicPartition;                   <span class="comment">// 每个RecordBatch都有唯一的TopicPartition</span></span><br><span class="line">        produceRecordsByPartition.put(tp, batch.records.buffer());  <span class="comment">// RecordBatch的records是MemoryRecords,底层是ByteBuffer</span></span><br><span class="line">        recordsByPartition.put(tp, batch);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 构造生产者的请求(每个Partition都有生产记录), 并指定目标节点,请求头和请求内容, 转换为发送请求对象</span></span><br><span class="line">    ProduceRequest request = <span class="keyword">new</span> ProduceRequest(acks, timeout, produceRecordsByPartition);</span><br><span class="line">    RequestSend send = <span class="keyword">new</span> RequestSend(Integer.toString(destination), <span class="keyword">this</span>.client.nextRequestHeader(ApiKeys.PRODUCE), request.toStruct());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 回调函数会作为客户端请求的一个成员变量, 当客户端请求完成后, 会触发回调函数的执行!</span></span><br><span class="line">    RequestCompletionHandler callback = <span class="keyword">new</span> RequestCompletionHandler() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(ClientResponse response)</span> </span>&#123;</span><br><span class="line">            handleProduceResponse(response, recordsByPartition, time.milliseconds());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ClientRequest(now, acks != <span class="number">0</span>, send, callback);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ProduceRequest是Producer的生产请求，需要acks和timeout这两个参数，在后面的DelayedOperation中会用到。  </p>
</blockquote>
<h4 id="ClientRequest_&amp;_ClientResponse_&amp;_Callback">ClientRequest &amp; ClientResponse &amp; Callback</h4><p>ClientRequest是客户端的请求，这个请求会被发送(Send)到服务器上，所以它包装的是RequestSend。ClientResponse是客户端的响应，也需要ClientRequest是因为请求有返回值时响应要和请求对的上。由于Callback是附加在Request里的，为了让Response能够触发Callback回调，将Request设置到Response。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A request being sent to the server. This holds both the network send as well as the client-level metadata.</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">ClientRequest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> createdTimeMs;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> expectResponse;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> RequestSend request;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> RequestCompletionHandler callback;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> isInitiatedByNetworkClient;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> sendTimeMs;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// A response from the server. Contains both the body of the response as well as the correlated request that was originally sent.</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClientResponse</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> receivedTimeMs;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> disconnected;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ClientRequest request;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Struct responseBody;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>回调函数传给了ClientRequest客户端请求，当客户端真正发生读写后（poll），会产生ClientResponse对象，触发回调函数的执行。因为回调对象RequestCompletionHandler的回调方法onComplete的参数是ClientResponse。NetworkClient.poll是真正发生读写的地方，所以它也会负责生成客户端的响应信息。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120120921467" alt="k_req_callback"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> List&lt;ClientResponse&gt; <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// .....真正的读写操作, 会生成responses</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// invoke callbacks</span></span><br><span class="line">    <span class="keyword">for</span> (ClientResponse response : responses) &#123;</span><br><span class="line">        <span class="keyword">if</span> (response.request().hasCallback()) &#123;</span><br><span class="line">            response.request().callback().onComplete(response);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> responses;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>到poll出来的responses是一个列表（客户端请求也是一个列表）。每个ClientRequest和ClientResponse都是针对一个节点的。再次强调下，发生在Client级别的动作都是针对每个节点而言，至于底层每个节点分成多个Partition则需要自己把内容封装进去。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (ClientRequest request : requests) </span><br><span class="line">    client.send(request, now);</span><br></pre></td></tr></table></figure>
<h4 id="handleProduceResponse">handleProduceResponse</h4><p>每个ClientResponse代表的是一个节点的响应，要从中解析出ProduceResponse中所有Partition的PartitionResponse。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120155619789" alt="k_handle_response"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleProduceResponse</span><span class="params">(ClientResponse response, Map&lt;TopicPartition, RecordBatch&gt; batches, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (response.hasResponse()) &#123;                       <span class="comment">// if we have a response, parse it</span></span><br><span class="line">        ProduceResponse produceResponse = <span class="keyword">new</span> ProduceResponse(response.responseBody());</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, ProduceResponse.PartitionResponse&gt; entry : produceResponse.responses().entrySet()) &#123;</span><br><span class="line">            TopicPartition tp = entry.getKey();         <span class="comment">// 每一个TopicPartition都对应一个PartitionResponse</span></span><br><span class="line">            ProduceResponse.PartitionResponse partResp = entry.getValue();</span><br><span class="line">            Errors error = Errors.forCode(partResp.errorCode);</span><br><span class="line">            RecordBatch batch = batches.get(tp);        <span class="comment">// 因为batches中对一个Partition只会有一个RecordBatch</span></span><br><span class="line">            completeBatch(batch, error, partResp.baseOffset, correlationId, now);   <span class="comment">// 完成这个RecordBatch, 调用RecordBatch.done    </span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  <span class="comment">// this is the acks = 0 case, just complete all requests</span></span><br><span class="line">        <span class="keyword">for</span> (RecordBatch batch : batches.values()) completeBatch(batch, Errors.NONE, -<span class="number">1L</span>, correlationId, now);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">completeBatch</span><span class="params">(RecordBatch batch, Errors error, <span class="keyword">long</span> baseOffset, <span class="keyword">long</span> correlationId, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    batch.done(baseOffset, error.exception());  <span class="comment">// tell the user the result of their request</span></span><br><span class="line">    <span class="keyword">this</span>.accumulator.deallocate(batch);         <span class="comment">// release resource include remove from incomplete and deallocate batch's records memory</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里的ClientRequest和ClientResponse分别由ProduceRequest和ProduceResponse组成，两者有一定的共同点。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160121082905460" alt="k_prod_req_resp"></p>
<p>客户端组织生成的每一批Batch记录都属于一个Partition，所以每个Batch都要complete（调用RecordBatch.done）。每次Batch中，如果客户端不需要响应，则baseOffset=-1，否则从response中解析出baseOffset用来表示消息的offset。由于RecordBatch记录的是每一条消息，每条消息都有Callback的话，一个Batch里就有和消息数量相等的thunks（callback）。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">done</span><span class="params">(<span class="keyword">long</span> baseOffset, RuntimeException exception)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// execute callbacks</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>.thunks.size(); i++) &#123;</span><br><span class="line">        Thunk thunk = <span class="keyword">this</span>.thunks.get(i);</span><br><span class="line">        <span class="keyword">if</span> (exception == <span class="keyword">null</span>) &#123;</span><br><span class="line">            RecordMetadata metadata = <span class="keyword">new</span> RecordMetadata(<span class="keyword">this</span>.topicPartition,  baseOffset, thunk.future.relativeOffset());</span><br><span class="line">            thunk.callback.onCompletion(metadata, <span class="keyword">null</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            thunk.callback.onCompletion(<span class="keyword">null</span>, exception);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.produceFuture.done(topicPartition, baseOffset, exception);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>客户端追加消息时附属的Callback终于在这里出现了。我们看到了很熟悉的RecordMetadata对象作为onCompletion的回调参数。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> Callback() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception e)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"The offset of the record we just sent is: "</span> + metadata.offset());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Selector">Selector</h3><p>NetworkClient的请求一般都是交给Selector去完成的。Selector使用NIO异步非阻塞模式管理连接，读写请求。Selector用一个单独的线程就可以管理多个网络连接的channel，并能够知晓通道是否为读写事件做好准备。  </p>
<h4 id="connect连接">connect连接</h4><p>客户端在和节点连接的时候，会创建和服务端的SocketChannel连接通道。Selector维护了每个目标节点对应的KafkaChannel。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120162602972" alt="k_channels"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">(String id, InetSocketAddress address, <span class="keyword">int</span> sendBufferSize, <span class="keyword">int</span> receiveBufferSize)</span> </span>&#123;</span><br><span class="line">    SocketChannel socketChannel = SocketChannel.open();</span><br><span class="line">    socketChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">    Socket socket = socketChannel.socket();     <span class="comment">// 这是客户端,所以返回的是Socket</span></span><br><span class="line">    socketChannel.connect(address);             <span class="comment">// 连接服务端, 注意这里并没有开始真正连接, 或者说因为是非阻塞方式, 是发起一个连接</span></span><br><span class="line">    SelectionKey key = socketChannel.register(nioSelector, SelectionKey.OP_CONNECT);    <span class="comment">// 连接事件</span></span><br><span class="line">    KafkaChannel channel = channelBuilder.buildChannel(id, key, maxReceiveSize);        <span class="comment">// 会创建包括底层的transportLayer等.</span></span><br><span class="line">    key.attach(channel);                        <span class="comment">// 将KafkaChannel注册到SelectionKey</span></span><br><span class="line">    <span class="keyword">this</span>.channels.put(id, channel);             <span class="comment">// Selector维护了每个nodeConnectionId以及KafkaChannel</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因为是非阻塞模式，此时调用connect()可能在连接建立之前就返回了。为了确定连接是否建立，需要再调用finishConnect()确认完全连接上了。  </p>
<p><strong>KafkaChannel finishConnect</strong></p>
<p>finishConnect会作为key.isConnectable的处理方法，在确认连接后可以取消Connect事件，并添加READ事件。  </p>
<blockquote>
<p>为什么在成功连接之后就注册了READ，首先只有成功连接，才可以进行读写操作。对于客户端的读一般都是读取响应结果。而什么时候响应结果返回给客户端是不确定的，所以不能在发送请求的时候注册读,因为有些发送请求并不需要读取结果的。  </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">finishConnect</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    socketChannel.finishConnect();</span><br><span class="line">    key.interestOps(key.interestOps() &amp; ~SelectionKey.OP_CONNECT | SelectionKey.OP_READ);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="send发送">send发送</h4><p>客户端发送的每个Send请求会被用到一个KafkaChannel中。如果一个KafkaChannel上还有未发送成功的Send请求，则后面的请求不允许发送。也就是说客户端发送请求给服务端，在一个KafkaChannel中，一次只能发送一个Send请求。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">(Send send)</span> </span>&#123;                   <span class="comment">// NetworkClient的send方法发送的是ClientRequest的RequestSend</span></span><br><span class="line">    KafkaChannel channel = channelOrFail(send.destination());</span><br><span class="line">    channel.setSend(send);                      <span class="comment">// 设置当前发送的Send请求是KafkaChannel要处理的请求</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> KafkaChannel <span class="title">channelOrFail</span><span class="params">(String id)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.channels.get(id);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>KafkaChannel.setSend</strong></p>
<p>客户端的请求Send设置到KafkaChannel中，KafkaChannel的TransportLayer会为SelectionKey注册WRITE事件。Channel的SelectionKey有了Connect和Write事件，在Selector的轮询过程中当发现这些事件到来，就开始执行真正的操作。  </p>
<blockquote>
<p>虽然一个KafkaChannel一次只能处理一个Send请求，每次Send时都要添加WRITE事件，当Send发送成功后，就要取消掉WRITE。下一个Send请求事件进来时，继续添加WRITE，然后在请求发送成功后，又取消WRITE。因为KafkaChannel是由请求事件驱动的，如果没有请求就不需要监听WRITE，KafkaChannel就不需要做写操作。基本流程就是：开始发送一个Send请求-&gt;注册OP_WRITE-&gt; 发送请求… -&gt;Send请求发送完成-&gt;取消OP_WRITE</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSend</span><span class="params">(Send send)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 如果存在send请求,说明之前的Send请求还没有发送完毕,新的请求不能进来! 什么时候send=null: 请求发送完毕时</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.send != <span class="keyword">null</span>) <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Attempt to begin a send operation with prior send operation still in progress."</span>);</span><br><span class="line">    <span class="keyword">this</span>.send = send;</span><br><span class="line">    <span class="keyword">this</span>.transportLayer.addInterestOps(SelectionKey.OP_WRITE);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 这是KafkaChannel的transportLayer的方法, transportLayer的key来自于buildChannel的SelectionKey</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addInterestOps</span><span class="params">(<span class="keyword">int</span> ops)</span> </span>&#123;</span><br><span class="line">    key.interestOps(key.interestOps() | ops);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>现在对于客户端而言，连接、读、写事件都有了（CONNECT、READ、WRITE）。在selector的轮询中可以操作读写事件。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160120174334217" alt="k_kafkaChannel"></p>
<h4 id="poll轮询">poll轮询</h4><p>轮询的策略是如果有数据（timeout=0）直接调用nioSelector.selectNow，否则每隔一定时间触发一次select调用。绑定到SelectionKey上的是KafkaChannel，基于Kafka的传输层TransportLayer包含了IO层的SocketChannel。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160122090034616" alt="k_key_channel_transport"></p>
<blockquote>
<p>poll轮询。一次轮询调用是不断地while循环。当然它的条件是能够选择到感兴趣的SelectionKey集合。在得到SelectionKey后，获取其中的KafkaChannel，因为Channel上有事件发生，然后选择对应的操作。  </p>
</blockquote>
<blockquote>
<p>在一开始时，我们为SocketChannel注册了某类SelectionKey，并绑定KafkaChannel到key上。当SocketChannel上有读写事件时，SelectionKey会被触发，就能取到绑定时的KafkaChannel。  </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    clear();</span><br><span class="line">    <span class="keyword">if</span> (hasStagedReceives()) timeout = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> readyKeys = select(timeout);                <span class="comment">//选择器,触发立即调用,或者定时调用</span></span><br><span class="line">    <span class="keyword">if</span> (readyKeys &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        Set&lt;SelectionKey&gt; keys = <span class="keyword">this</span>.nioSelector.selectedKeys();</span><br><span class="line">        Iterator&lt;SelectionKey&gt; iter = keys.iterator();</span><br><span class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">            SelectionKey key = iter.next();</span><br><span class="line">            iter.remove();</span><br><span class="line">            KafkaChannel channel = channel(key);    <span class="comment">//获得绑定到SelectionKey的通道</span></span><br><span class="line">            <span class="comment">/* complete any connections that have finished their handshake */</span></span><br><span class="line">            <span class="keyword">if</span> (key.isConnectable()) channel.finishConnect();</span><br><span class="line">            <span class="comment">/* if channel is not ready finish prepare */</span></span><br><span class="line">            <span class="keyword">if</span> (channel.isConnected() &amp;&amp; !channel.ready()) channel.prepare();</span><br><span class="line"></span><br><span class="line">            <span class="comment">/* if channel is ready read from any connections that have readable data */</span></span><br><span class="line">            <span class="keyword">if</span> (channel.ready() &amp;&amp; key.isReadable() &amp;&amp; !hasStagedReceive(channel)) &#123;</span><br><span class="line">                NetworkReceive networkReceive;</span><br><span class="line">                <span class="keyword">while</span> ((networkReceive = channel.read()) != <span class="keyword">null</span>)</span><br><span class="line">                    addToStagedReceives(channel, networkReceive);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/* if channel is ready write to any sockets that have space in their buffer and for which we have data */</span></span><br><span class="line">            <span class="keyword">if</span> (channel.ready() &amp;&amp; key.isWritable()) &#123;</span><br><span class="line">                Send send = channel.write();</span><br><span class="line">                <span class="keyword">if</span> (send != <span class="keyword">null</span>) <span class="keyword">this</span>.completedSends.add(send);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/* cancel any defunct sockets */</span></span><br><span class="line">            <span class="keyword">if</span> (!key.isValid()) close(channel);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    addToCompletedReceives();  <span class="comment">// 没有新的SelectionKey了! 说明要读取的已经都读取完了.  </span></span><br><span class="line">    <span class="comment">//不过Selector.poll&lt;-NetworkClient.poll&lt;-Sender.run是在这里循环的,每隔一段时间就会poll一次!</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>KafkaChannel write</strong></p>
<p><code>写操作</code>的事件没有使用while循环来控制，而是在完成发送时取消掉Write事件。如果Send在一次write调用时没有写完，SelectionKey的OP_WRITE事件没有取消，下次isWritable事件会继续触发，直到整个Send请求发送完毕才取消。所以发送一个完整的Send请求是通过最外层的while(iter.hasNext)，即SelectionKey控制的。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Send <span class="title">write</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Send result = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (send != <span class="keyword">null</span> &amp;&amp; send(send)) &#123;   <span class="comment">//如果send方法返回值为false,表示send.completed=false,即这个请求还没有发送成功</span></span><br><span class="line">        result = send;</span><br><span class="line">        send = <span class="keyword">null</span>;                    <span class="comment">//发送完毕后,设置send=null,这样下一个请求判断到send=null,就可以将新的Send设置为KafkaChannel的当前send</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">send</span><span class="params">(Send send)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    send.writeTo(transportLayer);       <span class="comment">//transportLayer有SocketChannel,所以是真正发生写的地方</span></span><br><span class="line">    <span class="keyword">if</span> (send.completed())               <span class="comment">//只有Send请求全部写出去了,才对transportLayer取消WRITE事件</span></span><br><span class="line">        transportLayer.removeInterestOps(SelectionKey.OP_WRITE);</span><br><span class="line">    <span class="keyword">return</span> send.completed();            <span class="comment">//如果Send只发送了一点点,则SelectionKey还会监听到Writable事件的</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>KafkaChannel read</strong></p>
<p><code>读取操作</code>需要读取一个完整的NetworkReceive。初始时receive=null，创建一个空的NetworkReceive。receive(receive)方法从transportLayer中读取到NetworkReceive对象中。假设读了一次没有读完，即receive.complete=false，read()返回的result=null，导致poll中的while循环继续调用read()。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160121082923585" alt="k_read1"></p>
<p>第二次读取时，receive!=null，继续从transportLayer读取到receive对象中，这次成功地读完了，设置result为读取成功的receive NetworkReceive，这个result不为空，while循环结束，调用addToStagedReceives。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160121082943445" alt="k_read2"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> NetworkReceive <span class="title">read</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    NetworkReceive result = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (receive == <span class="keyword">null</span>) receive = <span class="keyword">new</span> NetworkReceive(maxReceiveSize, id);</span><br><span class="line">    receive(receive);</span><br><span class="line">    <span class="keyword">if</span> (receive.complete()) &#123;</span><br><span class="line">        receive.payload().rewind();</span><br><span class="line">        result = receive;</span><br><span class="line">        receive = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">receive</span><span class="params">(NetworkReceive receive)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> receive.readFrom(transportLayer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>比较读和写在poll中的处理方式。一旦有读操作，就要读取一个完整的NetworkReceive。如果是写，可以分多次写。即读操作会在一次SelectionKey循环读取一个完整的接收动作，而写操作会在多次SelectionKey中完成一个完整的发送动作。写完后（成功地发送了Send请求），会取消掉WRITE事件（本次写已完成）。而读完并没有取消掉READ事件（可能还要读新的数据）。  </p>
</blockquote>
<p><strong>complte sends and receives</strong></p>
<p>写操作会将当前发送成功的Send加入到<code>completedSends</code>。因为每次写请求在每个通道中只会有一个。读操作先加到stagedReceives，最后全部读取完之后才从stagedReceives复制到<code>completedReceives</code>。completedSends和completedReceives分别表示在Selector端已经发送的和接收到的请求。它们会在NetworkClient的poll调用之后被不同的handleCompleteXXX使用。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 一次读操作就会有一个NetworkReceive生成,并加入到channel对应的队列中</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addToStagedReceives</span><span class="params">(KafkaChannel channel, NetworkReceive receive)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!stagedReceives.containsKey(channel))</span><br><span class="line">        stagedReceives.put(channel, <span class="keyword">new</span> ArrayDeque&lt;NetworkReceive&gt;());</span><br><span class="line">    Deque&lt;NetworkReceive&gt; deque = stagedReceives.get(channel);</span><br><span class="line">    deque.add(receive);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 只有在本次轮询中没有读操作了(也没有写了), 在退出轮询时, 将上一步的所有NetworkReceive加到completedReceives</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addToCompletedReceives</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.stagedReceives.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        Iterator&lt;Map.Entry&lt;KafkaChannel, Deque&lt;NetworkReceive&gt;&gt;&gt; iter = <span class="keyword">this</span>.stagedReceives.entrySet().iterator();</span><br><span class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">            Map.Entry&lt;KafkaChannel, Deque&lt;NetworkReceive&gt;&gt; entry = iter.next();</span><br><span class="line">            KafkaChannel channel = entry.getKey();</span><br><span class="line">            <span class="keyword">if</span> (!channel.isMute()) &#123;   <span class="comment">// 当前通道上没有OP_READ事件时</span></span><br><span class="line">                Deque&lt;NetworkReceive&gt; deque = entry.getValue();</span><br><span class="line">                NetworkReceive networkReceive = deque.poll();</span><br><span class="line">                <span class="keyword">this</span>.completedReceives.add(networkReceive);</span><br><span class="line">                <span class="keyword">if</span> (deque.size() == <span class="number">0</span>) iter.remove();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>问题1：最后加入到completedReceives的条件是channel.isMute()=false，即通道上没有OP_READ事件时。但是什么时候会取消READ呢？  </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isMute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> key.isValid() &amp;&amp; (key.interestOps() &amp; SelectionKey.OP_READ) == <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>问题2：deque.poll()是弹出一个元素，对于一个channel有多个元素，在while循环的是channel级别，如何弹出某个channel的所有元素？</p>
</blockquote>
<h3 id="NetworkClient">NetworkClient</h3><p>send动作将ClientRequest添加到队列<code>inFlightRequests</code>用来缓冲请求，然后触发Selector-&gt;KafkaChannel-&gt;transportLayer添加<code>OP_WRITE</code>写事件通知。poll动作也将实际处理交给Selector，客户端服务于读和写，即发送和接收。Selector在每次轮询调用之后，都会触发读写请求的完成handler，并添加到responses，用于回调函数的参数。不管是<code>Send</code>发送请求还是<code>NetworkReceive</code>接收请求，都可以被转换为<code>ClientRequest</code>表示客户端的请求。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">(ClientRequest request, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    String nodeId = request.request().destination();</span><br><span class="line">    <span class="keyword">if</span> (!canSendRequest(nodeId)) <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Attempt to send a request to node "</span> + nodeId + <span class="string">" which is not ready."</span>);</span><br><span class="line">    doSend(request, now);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doSend</span><span class="params">(ClientRequest request, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.inFlightRequests.add(request);             <span class="comment">//还没开始真正发送,先加入到队列中</span></span><br><span class="line">    selector.send(request.request());               <span class="comment">//标记下收到的是Send请求.</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> List&lt;ClientResponse&gt; <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ① Selector轮询, 真正读写发生的地方. 如果客户端请求被完整地处理过了, 会加入到completeSends或complteReceives中</span></span><br><span class="line">    <span class="keyword">this</span>.selector.poll(Utils.min(timeout, metadataTimeout, requestTimeoutMs));</span><br><span class="line">    <span class="comment">// ② process completed actions 处理已经完成的动作,如果没有收到完整的请求,则不会被加入到completeXXX中</span></span><br><span class="line">    List&lt;ClientResponse&gt; responses = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    handleCompletedSends(responses, updatedNow);    <span class="comment">//完成发送的handler</span></span><br><span class="line">    handleCompletedReceives(responses, updatedNow); <span class="comment">//完成接收的handler</span></span><br><span class="line">    handleDisconnections(responses, updatedNow);    <span class="comment">//断开连接的handler</span></span><br><span class="line">    handleConnections();                            <span class="comment">//处理连接的handler</span></span><br><span class="line">    handleTimedOutRequests(responses, updatedNow);  <span class="comment">//超时请求的handler</span></span><br><span class="line">    <span class="comment">// ③ invoke callbacks 将responses用于触发回调函数的调用</span></span><br><span class="line">    <span class="keyword">return</span> responses;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="ready">ready</h4><p>Sender的run中，在drain produce requests前会先判断readyNodes是否已经准备好了，因为不会发送请求给没有准备好的节点。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</span><br><span class="line"><span class="keyword">long</span> notReadyTimeout = Long.MAX_VALUE;</span><br><span class="line"><span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">    Node node = iter.next();</span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">this</span>.client.ready(node, now)) &#123;</span><br><span class="line">        iter.remove();</span><br><span class="line">        notReadyTimeout = Math.min(notReadyTimeout, <span class="keyword">this</span>.client.connectionDelay(node, now));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果isReady返回false，会先初始化连接initiateConnect，这里通过Selector向远程节点发起连接。ready指的是已经建立连接，并且通道也准备好，也允许往inFlightRequests发送更多的请求。如果是之前没有连接，现在刚刚发起连接请求，则不算准备好，因为连接动作肯定需要一定时间。   </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Begin connecting to the given node, return true if we are already connected and ready to send to that node.</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">ready</span><span class="params">(Node node, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (isReady(node, now)) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    <span class="keyword">if</span> (connectionStates.canConnect(node.idString(), now))</span><br><span class="line">        initiateConnect(node, now);  <span class="comment">// if we are interested in sending to a node and we don't have a connection to it, initiate one</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Initiate a connection to the given node</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initiateConnect</span><span class="params">(Node node, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    String nodeConnectionId = node.idString();</span><br><span class="line">    <span class="keyword">this</span>.connectionStates.connecting(nodeConnectionId, now);</span><br><span class="line">    selector.connect(nodeConnectionId, <span class="keyword">new</span> InetSocketAddress(node.host(), node.port()), <span class="keyword">this</span>.socketSendBuffer, <span class="keyword">this</span>.socketReceiveBuffer);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Check if the node with the given id is ready to send more requests.</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isReady</span><span class="params">(Node node, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> !metadataUpdater.isUpdateDue(now) &amp;&amp; canSendRequest(node.idString());</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Are we connected and ready and able to send more requests to the given connection?</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">canSendRequest</span><span class="params">(String node)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> connectionStates.isConnected(node) &amp;&amp; selector.isChannelReady(node) &amp;&amp; inFlightRequests.canSendMore(node);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意可以往某个节点发送请求的最后一个条件：队列为空，或者<code>队列的第一个请求必须已经完成</code>。如果有客户端的上一次请求没有完成，说明这个节点有正在处理的请求，比较忙，则不允许发送给它。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">canSendMore</span><span class="params">(String node)</span> </span>&#123;</span><br><span class="line">    Deque&lt;ClientRequest&gt; queue = requests.get(node);</span><br><span class="line">    <span class="keyword">return</span> queue == <span class="keyword">null</span> || queue.isEmpty() ||</span><br><span class="line">           (queue.peekFirst().request().completed() &amp;&amp; queue.size() &lt; <span class="keyword">this</span>.maxInFlightRequestsPerConnection);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们还要继续看下什么条件才算是completed，对于ByteBufferSend是没有要发送的数据了，也没有正在写的数据。<br><strong>所以这里的请求完成指的是<code>上一个发送请求</code>已经<code>成功发送</code>到服务端了，但并<code>不需要等待那个请求收到响应结果</code>。</strong>  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">completed</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> remaining &lt;= <span class="number">0</span> &amp;&amp; !pending;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="inFlightRequests-add">inFlightRequests.add</h4><p>表示已经发送，或正在发送。并且还没有收到响应的（客户端）请求。请求首先加入到（目标节点对应的）队列中。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160121093500704" alt="k_inflight_requests"></p>
<blockquote>
<p>注意：上面ready的限制条件，则最开始的两个请求一定已经发送成功，否则请求3不会被添加到Deque中。所以如果第一个请求发送到某个节点迟迟不能完成，有可能那个节点网络有问题，则后面的请求不会发送过来。这就避免了因为网络阻塞，请求一直堆积在某个节点上。  </p>
</blockquote>
<p>使用队列虽然可以存储多个请求，但是<code>新的请求</code>能加进来的条件是<code>上一个请求必须已经发送成功</code>！  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(ClientRequest request)</span> </span>&#123;</span><br><span class="line">    Deque&lt;ClientRequest&gt; reqs = <span class="keyword">this</span>.requests.get(request.request().destination());</span><br><span class="line">    <span class="keyword">if</span> (reqs == <span class="keyword">null</span>) &#123;</span><br><span class="line">        reqs = <span class="keyword">new</span> ArrayDeque&lt;&gt;();</span><br><span class="line">        <span class="keyword">this</span>.requests.put(request.request().destination(), reqs);</span><br><span class="line">    &#125;</span><br><span class="line">    reqs.addFirst(request);     <span class="comment">// 新的请求总是加到队列的头部.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>requests Map的key是request.request().destination()，表示这个请求要发送到哪个Broker节点上。所以从这里也可以看出，现在的作用域都只是在客户端，因为只有客户端才有目标节点destination。如果是Kafka作为服务端（目标节点），客户端连接服务端，就可以通过SocketChannel和服务端通信。  </p>
<h4 id="client-server_mode">client-server mode</h4><blockquote>
<p>注意doSend不只是用于Producer发送，也可以用于Consumer消费。参数ClientRequest表示客户端的请求。对于Kafka而言，P和C都是客户端。客户端发送请求给Kafka，从Kafka这方来说，都要Receive读取请求。实际上KafkaProducer和KafkaConsumer都有NetworkClient，说明客户端是嵌入在P和C里面的。  </p>
</blockquote>
<blockquote>
<p>Send请求的destination，NetworkReceive的source都表示远程的Kafka节点。因为在P和C的一亩三分地里，NetworkClient是它们和远程服务器交互的中间介质。  </p>
</blockquote>
<p>客户端和服务端只会有一个通道进行通信，所以客户端和服务端的交互只有两种形式：发送请求和读取响应。Selector以及请求对象都只是NetworkClient和SocketServer之间互相通信上的一些介质。只不过Selector提供了NIO非阻塞IO，而请求对象（Send，NetworkReceive）是通信的数据。不要认为NetworkClient和Selector之间也有一层通道。通道只有跨机器（客户端和服务器）才会建立的连接。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160121082955867" alt="k_cs"></p>
<p>还是以客户端发送请求为例，当NetworkClient把一个完整的请求发送到服务器，静静地等待服务端处理。然后某个时刻服务端对这个请求的处理结果要发送给客户端，NetworkClient看到有响应消息过来了（不等静静了），一点一点地接收响应，直到把响应结果完整地接收下来，发送请求是Send，响应结果就是NetworkReceive。  </p>
<p><img src="https://images.weserv.nl/?url=http://img.blog.csdn.net/20160121083009101" alt="k_cs2"></p>
<p>不过有可能服务端发送完请求之后并不想知道这个请求的结果，那么它发送完就不管了。和有响应结果的不同点是ClientResponse的最后一个参数表示响应内容body，在不期望得到响应时为null，有响应时为receive.payload。  </p>
<blockquote>
<p>比如CS模式中的set和get请求。set更改后并不需要知道响应，而get请求需要服务端返回一批数据给客户端。注意：NetworkClient在发送完set/get请求后，就会调用handleCompletedSends，表示请求已经发送到服务端了。至于请求在服务端被处理，什么时候完成完全取决于服务端，当get请求收到响应时，才调用handleCompletedReceives。  </p>
</blockquote>
<h4 id="complete_handler">complete handler</h4><p>客户端发送请求后，handleCompletedSends中对于有响应的请求，并不会将ClientRequest从inFlightRequests中移除。因为inFlightRequests表示的是还没有收到响应的客户端请求。而现在才发完请求，肯定还没收到响应，所以不会移除。而如果是客户端请求不需要响应，则这时候是可以将ClientRequest从中删除，添加时放到头部，删除时也是从头部删除。  </p>
<blockquote>
<p>问：删除时也是从头部删除，如果第一个请求发送完毕，刚好来了第二个请求，这时候删除头部是删除哪个请求？<br>答1(×)：前面一个请求发送完，如果它还没有完成，则第二个请求是不会进入到这个节点的队列中的。只有前一个请求已经完成，下一个请求才可以进入到队列。确保下面的删除是删除已经完成的，而不是新进来刚开始的请求。  </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Handle any completed request send. In particular if no response is expected, consider the request complete.</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleCompletedSends</span><span class="params">(List&lt;ClientResponse&gt; responses, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// if no response is expected then when the send is completed, return it</span></span><br><span class="line">    <span class="keyword">for</span> (Send send : <span class="keyword">this</span>.selector.completedSends()) &#123;</span><br><span class="line">        <span class="comment">// 这里获取目标节点的队列中第一个请求, 但并没有从队列中删除, 取出之后判断这个请求是否期望得到响应</span></span><br><span class="line">        ClientRequest request = <span class="keyword">this</span>.inFlightRequests.lastSent(send.destination());</span><br><span class="line">        <span class="comment">// 如果不需要响应,当Send请求完成时,就直接返回. 不过还是有ClientResponse对象的, 只不过最后一个参数为null,表示没有响应内容</span></span><br><span class="line">        <span class="keyword">if</span> (!request.expectResponse()) &#123;</span><br><span class="line">            <span class="keyword">this</span>.inFlightRequests.completeLastSent(send.destination());</span><br><span class="line">            responses.add(<span class="keyword">new</span> ClientResponse(request, now, <span class="keyword">false</span>, <span class="keyword">null</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果客户端请求需要有响应, 那么它的响应是在下面的handleCompletedReceives中设置的.  </span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>收到响应是在handleCompletedReceives，这时候才可以调用completeNext删除source对应的ClientRequest，因为我们知道inFlightRequests存的是未收到请求的ClientRequest，现在这个请求已经有响应了，就不需要再其中保存了。  </p>
<blockquote>
<p>问：inFlightRequests在这里的作用是什么？首先每个节点都有一个正在进行中的请求队列，可以防止请求堆积（流控?）。当请求发送成功，还没有收到响应（对于需要响应的客户端请求而言）的这段时间里，ClientRequest是处于in-flight状态的。同时每个节点的队列有个限制条件是：上一个请求没有发送完毕，下一个请求不能进来。或者队列中的未完成的请求数很多时都会限制。  </p>
</blockquote>
<blockquote>
<p>不需要响应的流程：开始发送请求-&gt;添加到inFlightRequests-&gt; 发送请求… -&gt;请求发送成功-&gt;从inFlightRequests删除请求<br>需要响应的流程：开始发送请求-&gt;添加到inFlightRequests-&gt;发送请求…-&gt;请求发送成功-&gt;等待接收响应-&gt;接收到响应-&gt;删除请求</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Handle any completed receives and update the response list with the responses received.</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleCompletedReceives</span><span class="params">(List&lt;ClientResponse&gt; responses, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (NetworkReceive receive : <span class="keyword">this</span>.selector.completedReceives()) &#123;</span><br><span class="line">        String source = receive.source();</span><br><span class="line">        <span class="comment">// 接收到完整的响应了, 现在可以删除inFlightRequests中的ClientRequest了.  </span></span><br><span class="line">        ClientRequest req = inFlightRequests.completeNext(source);</span><br><span class="line"></span><br><span class="line">        ResponseHeader header = ResponseHeader.parse(receive.payload());</span><br><span class="line">        <span class="comment">// Always expect the response version id to be the same as the request version id</span></span><br><span class="line">        <span class="keyword">short</span> apiKey = req.request().header().apiKey();</span><br><span class="line">        <span class="keyword">short</span> apiVer = req.request().header().apiVersion();</span><br><span class="line">        Struct body = ProtoUtils.responseSchema(apiKey, apiVer).read(receive.payload());</span><br><span class="line">        correlate(req.request().header(), header);</span><br><span class="line">        <span class="keyword">if</span> (!metadataUpdater.maybeHandleCompletedReceive(req, now, body))</span><br><span class="line">            responses.add(<span class="keyword">new</span> ClientResponse(req, now, <span class="keyword">false</span>, body));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="InFlightRequests_complete">InFlightRequests complete</h4><p>Deque是个双端队列，可以往头和尾方便地添加/删除/获取ClientRequest（前面Partition的RecordBatch也用过Deque）。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Get the oldest request (the one that that will be completed next) for the given node</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ClientRequest <span class="title">completeNext</span><span class="params">(String node)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> requestQueue(node).pollLast();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Get the last request we sent to the given node (but don't remove it from the queue)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ClientRequest <span class="title">lastSent</span><span class="params">(String node)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> requestQueue(node).peekFirst();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Complete the last request that was sent to a particular node.</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ClientRequest <span class="title">completeLastSent</span><span class="params">(String node)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> requestQueue(node).pollFirst();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Question</strong>  </p>
<p>I’m reading new client design of version 0.9. and I has a question of inFlightRequests in and out.<br>Here is the basic flow :  </p>
<p>When Sender send a ClientRequest to NetworkClient, it add to inFlightRequests indicator in-flight requests </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">private void doSend(ClientRequest request, long now) &#123;</span><br><span class="line">    this.inFlightRequests.add(request);</span><br><span class="line">    selector.send(request.request());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>the inFlightRequests map node to deque. the new request add as first element of deque</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public void add(ClientRequest request) &#123;</span><br><span class="line">    Deque&lt;ClientRequest&gt; reqs = this.requests.get(request.request().destination());</span><br><span class="line">    if (reqs == null) &#123;</span><br><span class="line">        reqs = new ArrayDeque&lt;&gt;();</span><br><span class="line">        this.requests.put(request.request().destination(), reqs);</span><br><span class="line">    &#125;</span><br><span class="line">    reqs.addFirst(request);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>then poll happen on client and then selector, after success send this ClientRequest, the send will add to selector’s completedSends</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">private void handleCompletedSends(List&lt;ClientResponse&gt; responses, long now) &#123;</span><br><span class="line">    // if no response is expected then when the send is completed, return it</span><br><span class="line">    for (Send send : this.selector.completedSends()) &#123;</span><br><span class="line">        ClientRequest request = this.inFlightRequests.lastSent(send.destination());</span><br><span class="line">        if (!request.expectResponse()) &#123;</span><br><span class="line">            this.inFlightRequests.completeLastSent(send.destination());</span><br><span class="line">            responses.add(new ClientResponse(request, now, false, null));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>if this request does’t need response, the ClientRequest will remove from inFlightRequest  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public ClientRequest completeLastSent(String node) &#123;</span><br><span class="line">    return requestQueue(node).pollFirst();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<p>I’m curios why poll First? A scene like this: after the first ClientRequest sended out success,<br>and not yet execute to handleCompletedSends, another ClientRequest coming, and the new request addFirst to deque.<br>then pollFirst execute, as first element of deque now become to the new request, pollFirst will delete the new one, not old one.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CR1-&gt;inFlightRequests  |  CR1 send success  | CR2-&gt;inFlightRequests  | completeSends  |  pollFirst</span><br><span class="line"></span><br><span class="line">first    last                                 first    last</span><br><span class="line">-------------                                 -------------      </span><br><span class="line">CR1                                           CR2 CR1                      CR1           poll CR2, but CR2 is just come in!</span><br><span class="line">-------------                                 -------------</span><br></pre></td></tr></table></figure>
<p>I has also check <code>NetworkClient.send-&gt;canSendRequest -&gt; inFlightRequests.canSendMore(node) -&gt; queue.peekFirst().request().completed()</code><br>only the first element of deque finish, then new request can send to the same node. but the condition of completed<br>by <code>ByteBufferSend</code> is <code>remaining &lt;= 0 &amp;&amp; !pending</code>. which means If Send sended success to server, it’s completed!  </p>
<p>Am I missig something(are there any other limitation)? Can some on point out. Tks.  </p>
<h2 id="KafkaServer">KafkaServer</h2><p>上面的Producer和Consumer都不是作为Kafka的内置服务，而是一种客户端（所以它们都在clients包）。客户端可以独立于Kafka，和Kafka服务所在的节点互相隔离。Producer和Consumer和Kafka集群进行交互。每个Kafka节点都有一些自己内置的服务进程，比如Broker、KafkaController、GroupCoordinator、ReplicaManager等。  </p>
<p><img src="http://kafka.apache.org/images/producer_consumer.png" alt="p_c_k"></p>
<p>接下来我们看下客户端的请求在服务端是怎么被处理的。客户端有发送和接收请求，服务端同样也有接收和发送的逻辑。因为对于I/O来说是双向的：客户端发送请求，就意味着服务端要接收请求，同样服务端也会发送响应，客户端就要接收响应。 </p>
<h2 id="Ref">Ref</h2><ul>
<li><a href="http://blog.csdn.net/lizhitao/article/details/39499283" target="_blank" rel="noopener">http://blog.csdn.net/lizhitao/article/details/39499283</a></li>
<li><a href="http://ifeve.com/socket-channel/" target="_blank" rel="noopener">http://ifeve.com/socket-channel/</a></li>
</ul>

      
    </div>
    
  </div>
  
    
<div class="copyright">
  <p><span>本文标题:</span><a href="/2016/01/06/2016-01-06-Kafka_Producer/">Kafka源码分析 Producer客户端</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 任何忧伤,都抵不过世界的美丽 的个人博客">任何忧伤,都抵不过世界的美丽</a></p>
  <p><span>发布时间:</span>2016年01月06日 - 00时00分</p>
  <p><span>最后更新:</span>2019年02月14日 - 21时42分</p>
  <p>
    <span>原始链接:</span><a href="/2016/01/06/2016-01-06-Kafka_Producer/" title="Kafka源码分析 Producer客户端">http://github.com/zqhxuyuan/2016/01/06/2016-01-06-Kafka_Producer/</a>
    <span class="btn" data-clipboard-text="原文: http://github.com/zqhxuyuan/2016/01/06/2016-01-06-Kafka_Producer/　　作者: 任何忧伤,都抵不过世界的美丽" title="点击复制文章链接">
        <i class="fa fa-clipboard"></i>
    </span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" title="中国大陆 (CC BY-NC-SA 3.0 CN)">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。</p>
  <script src="/js/clipboard.min.js"></script>
  <script> var clipboard = new Clipboard('.btn'); </script>
</div>
<style type="text/css">
  .copyright p .btn {
    margin-left: 1em;
  }
  .copyright:hover p .btn::after {
    content: "复制"
  }
  .copyright p .btn:hover {
      color: gray;
      cursor: pointer;
    };
</style>



<nav id="article-nav">
  
    <div id="article-nav-newer" class="article-nav-title">
      <a href="/2016/01/07/2016-01-07-Kafka-Producer-scala/">
        Kafka源码分析 Producer Scala客户端
      </a>
    </div>
  
  
    <div id="article-nav-older" class="article-nav-title">
      <a href="/2016/01/05/Note_Clojure_macro/">
        Clojure宏剖析
      </a>
    </div>
  
</nav>

  
  
    <div class="post-donate">
	<br>
	<p>
    <div id="donate_board" class="donate_bar center">
        <a id="btn_donate" class="btn_donate" href="javascript:;" title="打赏"></a>
        <span class="donate_txt">
           &uarr;<br>
		   招人广告：对蚂蚁金服中间件感兴趣的可以发邮件到：qihuang.zqh at antfin.com
        </span>
        <br>
    </div>  
	<div id="donate_guide" class="donate_bar center hidden">
		<img src="/img/zhifubao.png" alt="支付宝打赏"> 
		<img src="/img/weixin.png" alt="微信打赏">  
    </div>
	<script type="text/javascript">
		document.getElementById('btn_donate').onclick = function(){
			$('#donate_board').addClass('hidden');
			$('#donate_guide').removeClass('hidden');
		}
	</script>
</p></div>
  
</article>

<!-- 默认显示文章目录，在文章---前输入toc: false关闭目录 -->
<!-- Show TOC and tocButton in default, Hide TOC via putting "toc: false" before "---" at [post].md -->
<div id="toc" class="toc-article">
<strong class="toc-title">文章目录</strong>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#导读"><span class="toc-number">1.</span> <span class="toc-text">导读</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer"><span class="toc-number">2.</span> <span class="toc-text">Producer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#blocking_vs_non-blocking"><span class="toc-number">2.1.</span> <span class="toc-text">blocking vs non-blocking</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#partition"><span class="toc-number">2.2.</span> <span class="toc-text">partition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RecordAccumulator"><span class="toc-number">2.3.</span> <span class="toc-text">RecordAccumulator</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sender"><span class="toc-number">2.4.</span> <span class="toc-text">Sender</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ClientRequest_&_ClientResponse_&_Callback"><span class="toc-number">2.4.1.</span> <span class="toc-text">ClientRequest &amp; ClientResponse &amp; Callback</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#handleProduceResponse"><span class="toc-number">2.4.2.</span> <span class="toc-text">handleProduceResponse</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Selector"><span class="toc-number">2.5.</span> <span class="toc-text">Selector</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#connect连接"><span class="toc-number">2.5.1.</span> <span class="toc-text">connect连接</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#send发送"><span class="toc-number">2.5.2.</span> <span class="toc-text">send发送</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#poll轮询"><span class="toc-number">2.5.3.</span> <span class="toc-text">poll轮询</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NetworkClient"><span class="toc-number">2.6.</span> <span class="toc-text">NetworkClient</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ready"><span class="toc-number">2.6.1.</span> <span class="toc-text">ready</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#inFlightRequests-add"><span class="toc-number">2.6.2.</span> <span class="toc-text">inFlightRequests.add</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#client-server_mode"><span class="toc-number">2.6.3.</span> <span class="toc-text">client-server mode</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#complete_handler"><span class="toc-number">2.6.4.</span> <span class="toc-text">complete handler</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#InFlightRequests_complete"><span class="toc-number">2.6.5.</span> <span class="toc-text">InFlightRequests complete</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KafkaServer"><span class="toc-number">3.</span> <span class="toc-text">KafkaServer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ref"><span class="toc-number">4.</span> <span class="toc-text">Ref</span></a></li></ol>
</div>
<style type="text/css">
  .left-col .switch-btn {
    display: none;
  }
  .left-col .switch-area {
    display: none;
  }
</style>

<input type="button" id="tocButton" value="隐藏目录" title="点击按钮隐藏或者显示文章目录">
<script type="text/javascript">
  var toc_button= document.getElementById("tocButton");
  var toc_div= document.getElementById("toc");
  /* Show or hide toc when click on tocButton.
  通过点击设置的按钮显示或者隐藏文章目录.*/
  toc_button.onclick=function(){
  if(toc_div.style.display=="none"){
  toc_div.style.display="block";
  toc_button.value="隐藏目录";
  document.getElementById("switch-btn").style.display="none";
  document.getElementById("switch-area").style.display="none";
  }
  else{
  toc_div.style.display="none";
  toc_button.value="显示目录";
  document.getElementById("switch-btn").style.display="block";
  document.getElementById("switch-area").style.display="block";
  }
  }
    if ($(".toc").length < 1) {
        $("#toc").css("display","none");
        $("#tocButton").css("display","none");
        $(".switch-btn").css("display","block");
        $(".switch-area").css("display","block");
    }
</script>


    <style>
        .toc {
            white-space: nowrap;
            overflow-x: hidden;
        }
    </style>

    <script>
        $(document).ready(function() {
            $(".toc li a").mouseover(function() {
                var title = $(this).attr('href');
                $(this).attr("title", title);
            });
        })
    </script>




<div class="share">
	<div class="bdsharebuttonbox">
	<a href="#" class="bds_more" data-cmd="more"></a>
	<a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
	<a href="#" class="bds_copy" data-cmd="copy" title="复制网址"></a>
	<a href="#" class="bds_mail" data-cmd="mail" title="通过邮件分享"></a>
	<a href="#" class="bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
	</div>
	<script>
	window._bd_share_config={
		"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
	</script>
</div>



<div class="duoshuo" id="comments">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="2016/01/06/2016-01-06-Kafka_Producer/" data-title="Kafka源码分析 Producer客户端" data-url="http://github.com/zqhxuyuan/2016/01/06/2016-01-06-Kafka_Producer/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"zqhxuyuan"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>






    <style type="text/css">
    #scroll {
      display: none;
    }
    </style>
    <div class="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
    </div>


  
  
    
    <div class="post-nav-button">
    <a href="/2016/01/07/2016-01-07-Kafka-Producer-scala/" title="上一篇: Kafka源码分析 Producer Scala客户端">
    <i class="fa fa-angle-left"></i>
    </a>
    <a href="/2016/01/05/Note_Clojure_macro/" title="下一篇: Clojure宏剖析">
    <i class="fa fa-angle-right"></i>
    </a>
    </div>
  



    
        <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
        <script>
        var yiliaConfig = {
        fancybox: true,
        mathjax: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        open_in_new: false
        }
        </script>
        
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2019 任何忧伤,都抵不过世界的美丽
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的静态博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减双栏 Hexo 博客主题">Yelee</a> by MOxFIVE
        </div>
    </div>
    <div class="visit">
      <span id="busuanzi_container_site_pv" style="display:none">
        <span id="site-visit">本站到访数: 
        <span id="busuanzi_value_site_uv"></span>
        </span>
      </span>
      <span id="busuanzi_container_page_pv" style="display:none">
        <span id="page-visit">, 本页阅读量: 
        <span id="busuanzi_value_page_pv"></span>
        </span>
      </span>
    </div>
  </div>
</footer>
    </div>
    

<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>

<script>
  var backgroundnum = 5;
  var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));

  $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
</script>


<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-80646710-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
<a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
<a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>